{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiEsrafili/pert/blob/master/ezafe_blstm_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk2oqX4CHbHt",
        "outputId": "e65bf0af-b9bb-4ba5-a1ba-36e4e486a5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnebXvZ2HiRB",
        "outputId": "8122be85-14e9-4217-c621-a7f6e25d146d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 40.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 307 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 358 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 368 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 430 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 432 kB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 90.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=26116a30679da1e4eca318ae61d8d18c22fc4d29953ee22e88d467a7fb0d7943\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBMREtQTk2LW",
        "outputId": "5af0d424-e363-4cdf-b306-cef06eee3bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
            "Building wheels for collected packages: parsivar, nltk\n",
            "  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492972 sha256=61eae87656e4516a973d24120dec0a28fb8fc0f5a808a45769b5d5c2f1a9de22\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/67/7a/49cbf08f64d3f76a26eceaf0e481a40e233f05d4356875cbed\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449920 sha256=1d7b87a12502f8cf3e0f213666069ef5e11126ff4ab0e404e22ccd050567085c\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built parsivar nltk\n",
            "Installing collected packages: nltk, parsivar\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.4.5 parsivar-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 install parsivar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "b7cac6af573e46f9a4afefd9046c727f",
            "ca7ceca9a763413bac5ad850f5f04197",
            "e5667e30e15047aeb8300116c97798a7",
            "2b4f18679e814d5180085a59ac0430d7",
            "ef1452346508471ab3a723b03b1aee42",
            "31de5f4e0d45493e8217b9aa16cf5735",
            "4dfe13073a83445980de88613a2177b6",
            "52a8aa4684374ccc9f6f6bdd64443ea4",
            "1b6544ea9d5e4bb3853ad2a8739a64b1",
            "e8a8db1c48304883904ff847950e5fc0",
            "c107bdf56d8a444ca0d274e56bda7381",
            "3a7a96f223574bdbaecbdaad16873c11",
            "3a4682d2da1c451cbec8f0eb89ebfd95",
            "c7ac1fa504c6402c916f59f9692354ff",
            "3220e57ef014462d89988bd775e77bd3",
            "a14ad23ef4c2420993f7b43210dacdc9",
            "d2fe898a2e8a4ad6b98c43c4fbf43f06",
            "d1cb05a876d34f6d858927fd8648a45a",
            "7e9c9d6b7e284b5b84a54ab6258f2bf7",
            "57c03e699890440d86da8f56718f3410",
            "db50f85af09445d7ac7099acf6c1df3f",
            "2e84247a37024f7d8b268880a9d1f3b0"
          ]
        },
        "id": "K67Qbr_4Hs3b",
        "outputId": "2890993b-d178-4b04-e455-e3e122c74c6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7cac6af573e46f9a4afefd9046c727f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-19 13:11:41 INFO: Downloading default packages for language: fa (Persian)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a7a96f223574bdbaecbdaad16873c11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-19 13:11:45 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "stanza.download('fa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY9qy_5sIAw_",
        "outputId": "3f7290a2-024c-41f5-fd1e-e536eabd22e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-19 13:11:47 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-19 13:11:47 INFO: Use device: gpu\n",
            "2022-04-19 13:11:47 INFO: Loading: tokenize\n",
            "2022-04-19 13:11:58 INFO: Loading: mwt\n",
            "2022-04-19 13:11:58 INFO: Loading: pos\n",
            "2022-04-19 13:11:58 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EloiwuwfIB7P",
        "outputId": "ede8b38d-2a09-424c-cd4c-ce05563cc95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3930, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 3930 (delta 28), reused 42 (delta 11), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3930/3930), 8.33 MiB | 14.66 MiB/s, done.\n",
            "Resolving deltas: 100% (2445/2445), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3137697 sha256=6fb5e26c8823a34785400d95f42f6c63d323042faa51f5f66803edcdea606c58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uxybuaic/wheels/22/04/6e/b3aba25c1a5845898b5871a0df37c2126cb0cc9326ad0c08e7\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "% cd fastText\n",
        "!  pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fw2SkiaID03",
        "outputId": "0b7bc385-60d0-4546-8029-f2f2145b70df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastText\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            " (100.00%) [==================================================>]\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "% cd fastText\n",
        "!./download_model.py fa\n",
        "% cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-tdUjcKgz0x",
        "outputId": "142269a8-ff9e-40a3-ed2d-d05c633bd6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastText\n",
            "Loading model\n",
            "tcmalloc: large alloc 4800004096 bytes == 0x561dddff8000 @  0x7f4f63e4f887 0x7f4f61d2c003 0x7f4f61d3e2bf 0x7f4f61d3e8d1 0x7f4f61cf5412 0x7f4f61d1d6bd 0x561dc9489d48 0x561dc94fd522 0x561dc94f7a2e 0x561dc948b13c 0x561dc94cc239 0x561dc94c9184 0x561dc94899f9 0x561dc94fd937 0x561dc948a7aa 0x561dc94fcd30 0x561dc94f7a2e 0x561dc948a88a 0x561dc94f9719 0x561dc948a7aa 0x561dc94f88f6 0x561dc94f7a2e 0x561dc94f7723 0x561dc95c1812 0x561dc95c1b8d 0x561dc95c1a36 0x561dc9599183 0x561dc9598e2c 0x7f4f62c37c87 0x561dc9598d0a\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x561efc19c000 @  0x7f4f63e4f887 0x7f4f61d2c003 0x7f4f61d3e30e 0x7f4f61d3e8d1 0x7f4f61cf5412 0x7f4f61d1d6bd 0x561dc9489d48 0x561dc94fd522 0x561dc94f7a2e 0x561dc948b13c 0x561dc94cc239 0x561dc94c9184 0x561dc94899f9 0x561dc94fd937 0x561dc948a7aa 0x561dc94fcd30 0x561dc94f7a2e 0x561dc948a88a 0x561dc94f9719 0x561dc948a7aa 0x561dc94f88f6 0x561dc94f7a2e 0x561dc94f7723 0x561dc95c1812 0x561dc95c1b8d 0x561dc95c1a36 0x561dc9599183 0x561dc9598e2c 0x7f4f62c37c87 0x561dc9598d0a\n",
            "Reducing matrix dimensions\n",
            "tcmalloc: large alloc 4800004096 bytes == 0x561f92a6e000 @  0x7f4f63e4d1e7 0x7f4f614cd0ce 0x7f4f61527726 0x7f4f61527b09 0x7f4f61529620 0x7f4f61529d1b 0x7f4f615ca333 0x561dc948911c 0x561dc9488ef0 0x561dc94fd123 0x561dc948a7aa 0x561dc94f8b4f 0x561dc948a7aa 0x561dc94fcd30 0x561dc94f7a2e 0x561dc948a88a 0x561dc94f9719 0x561dc948a7aa 0x561dc94f88f6 0x561dc94f7a2e 0x561dc94f7723 0x561dc95c1812 0x561dc95c1b8d 0x561dc95c1a36 0x561dc9599183 0x561dc9598e2c 0x7f4f62c37c87 0x561dc9598d0a\n",
            "tcmalloc: large alloc 1600004096 bytes == 0x5620b7e84000 @  0x7f4f63e4d1e7 0x7f4f614cd0ce 0x7f4f61523cf5 0x7f4f61523e08 0x7f4f615e30f4 0x7f4f615e5f6d 0x7f4f6176a49b 0x7f4f6176c3a3 0x7f4f6176de10 0x561dc9489902 0x561dc94fd522 0x561dc948a7aa 0x561dc94f88f6 0x561dc948a7aa 0x561dc94fcd30 0x561dc94f7a2e 0x561dc948a88a 0x561dc94f9719 0x561dc948a7aa 0x561dc94f88f6 0x561dc94f7a2e 0x561dc94f7723 0x561dc95c1812 0x561dc95c1b8d 0x561dc95c1a36 0x561dc9599183 0x561dc9598e2c 0x7f4f62c37c87 0x561dc9598d0a\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x561f92a6e000 @  0x7f4f63e4d1e7 0x7f4f614cd0ce 0x7f4f61527726 0x7f4f61527b09 0x7f4f61529620 0x7f4f61529d1b 0x7f4f615ca333 0x561dc948911c 0x561dc9488ef0 0x561dc94fd123 0x561dc948a7aa 0x561dc94f8b4f 0x561dc948a7aa 0x561dc94fcd30 0x561dc94f7a2e 0x561dc948a88a 0x561dc94f9719 0x561dc948a7aa 0x561dc94f88f6 0x561dc94f7a2e 0x561dc94f7723 0x561dc95c1812 0x561dc95c1b8d 0x561dc95c1a36 0x561dc9599183 0x561dc9598e2c 0x7f4f62c37c87 0x561dc9598d0a\n",
            "Saving model\n",
            "cc.fa.100.bin saved\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "% cd fastText\n",
        "!./reduce_model.py cc.fa.300.bin 100\n",
        "% cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1GvRlOd7IFwn"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rtOY4RPkOrtr"
      },
      "outputs": [],
      "source": [
        "# run this or below cell\n",
        "!cp drive/MyDrive/دیتاست\\ بیجن\\ خان/test_clean.tsv data/test_clean.tsv\n",
        "!cp drive/MyDrive/دیتاست\\ بیجن\\ خان/train_clean.tsv data/train_clean.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL27nT6e079M",
        "outputId": "c998a9eb-184c-461a-fee9-91f9d270f7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9049352 data/train_clean.tsv\n"
          ]
        }
      ],
      "source": [
        "!wc -l data/train_clean.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Tk7enI1HvL",
        "outputId": "750ad0b1-895c-4323-e653-94a88cf5a870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1601230 data/test_clean.tsv\n"
          ]
        }
      ],
      "source": [
        "!wc -l data/test_clean.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vMw5h2D0FZu"
      },
      "outputs": [],
      "source": [
        "!head -n4000000 data/train_clean.tsv > data/train_clean_p1.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6oZsQ2y1Moj",
        "outputId": "109d7547-4bf1-4b45-90a4-171d36f0eb22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000000 data/train_clean_p1.tsv\n"
          ]
        }
      ],
      "source": [
        "!wc -l data/train_clean_p1.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPeQzq74III-",
        "outputId": "09315c2e-3643-414d-d395-afc21add915b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  drive/MyDrive/دیتاست بیجن خان/test_data.zip\n",
            "  inflating: data/test_data.txt      \n",
            "Archive:  drive/MyDrive/دیتاست بیجن خان/train_data.zip\n",
            "  inflating: data/train_data.txt     \n"
          ]
        }
      ],
      "source": [
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/test_data.zip -d data\n",
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/train_data.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IByGIyi0IMLm",
        "outputId": "a73e3761-8047-4e9b-d35a-d5c3c3da09da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-19 13:18:17 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-19 13:18:17 INFO: Use device: gpu\n",
            "2022-04-19 13:18:17 INFO: Loading: tokenize\n",
            "2022-04-19 13:18:17 INFO: Loading: mwt\n",
            "2022-04-19 13:18:17 INFO: Loading: pos\n",
            "2022-04-19 13:18:17 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGxCnhOfIO4W"
      },
      "outputs": [],
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')\n",
        "def pos_tager(text):\n",
        "  doc = nlp_pos(text)\n",
        "  pos = [word.xpos for sent in doc.sentences for word in sent.words if word.text not in ['ش','شان','م', 'مان', 'ند','ست','یت', 'تان', 'ت','اش']]\n",
        "  # pos_ = [(word.text , word.upos, word.xpos) for sent in doc.sentences for word in sent.words ]\n",
        "  # print(pos_)\n",
        "  return pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r8ZQFOE_IP13"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I70JzE8PIUg5"
      },
      "outputs": [],
      "source": [
        "def check_consist(pos_tag, kasre_tag, sent):\n",
        "  l1 = len(pos_tag)\n",
        "  l2 = len(kasre_tag)\n",
        "  l3 = len(sent.split())\n",
        "  if l1!=l2:\n",
        "    return False\n",
        "  if l1!=l3:\n",
        "    return False\n",
        "  if l3!=l2:\n",
        "    return False\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWMK6ZPIVaF",
        "outputId": "374e7f34-a84d-45eb-8abd-37c67ba35b04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "130it [00:00, 517.04it/s]/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n",
            "8612838it [1:46:31, 1347.55it/s]\n"
          ]
        }
      ],
      "source": [
        "with open('data/train_data.txt', encoding='utf-8') as f:\n",
        "    data = f.readlines()\n",
        "sents = list()\n",
        "kasre_tags = list()\n",
        "temp_sent = ''\n",
        "temp_tags = list()\n",
        "pos_tags = list()\n",
        "for i, line in tqdm(enumerate(data)):\n",
        "    # if i>10000: break\n",
        "    try:\n",
        "        word, ez = line.split()\n",
        "        word += ' '\n",
        "        temp_sent += word\n",
        "        temp_tags.append(ez)\n",
        "        if word in ['. ', '# ']:\n",
        "            pos_tag = pos_tager(temp_sent)\n",
        "            ok = check_consist(pos_tag, temp_tags, temp_sent)\n",
        "            if ok:\n",
        "              sents.append(temp_sent) \n",
        "              kasre_tags.append(temp_tags)\n",
        "              pos_tags.append(pos_tag)\n",
        "            temp_sent = ''\n",
        "            temp_tags = list()\n",
        "    except:\n",
        "        pos_tag = pos_tager(temp_sent)\n",
        "        ok = check_consist(pos_tag, temp_tags, temp_sent)\n",
        "        if ok:\n",
        "          sents.append(temp_sent) \n",
        "          kasre_tags.append(temp_tags)\n",
        "          pos_tags.append(pos_tag)\n",
        "        temp_sent = ''\n",
        "        temp_tags = list()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWuilPW2IYWW",
        "outputId": "3e989c40-07c8-404c-d2a6-aa8cda7fda71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(295721, 295721, 295721)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sents), len(kasre_tags), len(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyetfYuTIdCu"
      },
      "outputs": [],
      "source": [
        "raws = list()\n",
        "\n",
        "for i in range(len(pos_tags)):\n",
        "  for j in range(len(pos_tags[i])):\n",
        "    raw = f'{sents[i].split()[j]}\\t{pos_tags[i][j]}\\t{kasre_tags[i][j]}'\n",
        "    raws.append(raw)\n",
        "  raws.append('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw0bUhwYIeTW"
      },
      "outputs": [],
      "source": [
        "raws_text = '\\n'.join(raws)\n",
        "with open('data/train_clean.tsv', 'w') as f:\n",
        "  f.write(raws_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uJsLaiROct1"
      },
      "outputs": [],
      "source": [
        "!cp data/train_clean.tsv drive/MyDrive/دیتاست\\ بیجن\\ خان/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-mzML_PRHLU"
      },
      "outputs": [],
      "source": [
        "# run this or bellow cell\n",
        "!mkdir fastText\n",
        "!cp drive/MyDrive/fastText/cc.fa.300.vec fastText/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuY_O26bbHzf",
        "outputId": "4c1d417c-e4f6-4dae-cf15-d9067e810140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.0G fastText/cc.fa.300.vec\n"
          ]
        }
      ],
      "source": [
        "!ls -sh fastText/cc.fa.300.vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RqAd6MmUIgoG"
      },
      "outputs": [],
      "source": [
        "from fasttext import load_model\n",
        "\n",
        "# original BIN model loading\n",
        "f = load_model('fastText/cc.fa.100.bin')\n",
        "lines=[]\n",
        "\n",
        "# get all words from model\n",
        "words = f.get_words()\n",
        "\n",
        "with open('fastText/cc.fa.100.vec','w') as file_out:\n",
        "    \n",
        "    # the first line must contain number of total words and vector dimension\n",
        "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
        "\n",
        "    # line by line, you append vectors to VEC file\n",
        "    for w in words:\n",
        "        v = f.get_word_vector(w)\n",
        "        vstr = \"\"\n",
        "        for vi in v:\n",
        "            vstr += \" \" + str(vi)\n",
        "        try:\n",
        "            file_out.write(w + vstr+'\\n')\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw4QcEhuoR5L",
        "outputId": "59ff82c0-fd87-4b42-e89d-f7769712f5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4G fastText/cc.fa.100.vec\n"
          ]
        }
      ],
      "source": [
        "!ls -sh fastText/cc.fa.100.vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yx-MVhUoQ8dO"
      },
      "outputs": [],
      "source": [
        "# !mkdir drive/MyDrive/fastText\n",
        "!cp fastText/cc.fa.100.vec drive/MyDrive/fastText/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s8AtfVYDtgrw"
      },
      "outputs": [],
      "source": [
        "!mkdir checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Yi3Sdd_lsvMy"
      },
      "outputs": [],
      "source": [
        "RUN = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J3PlM7ZmJq1N"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        # directories\n",
        "        self.train_data_dir = 'data/train_clean.tsv'\n",
        "        self.model_dir = 'models'\n",
        "        self.we_model_dir = 'fastText/cc.fa.100.vec'\n",
        "        self.we_pickled_model_dir = 'fastText/cc.fa.100.pickle'\n",
        "\n",
        "        # general\n",
        "        self.data_split = .1\n",
        "        self.num_epochs = 25\n",
        "        self.batch_size = 16\n",
        "        self.shuffle_buffer = 320000\n",
        "        self.num_tags = 6\n",
        "        self.num_pos_tags = 33\n",
        "        self.word_max_len = 30\n",
        "        self.learning_rate = 1e-3\n",
        "        self.max_len = 100\n",
        "\n",
        "        # embeddings\n",
        "        self.num_words = 100000\n",
        "        self.word_embed_dim = 100\n",
        "        self.num_chars = 256  # number of most frequent characters to be kept\n",
        "        self.char_embed_dim = 32\n",
        "        self.pos_embed_dim = 16\n",
        "\n",
        "        # lstm variables\n",
        "        self.lstm_units = 256  # number of hidden units in the RNN\n",
        "        self.dropout = .5  # keeping probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WcnAZYHytnKr"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INvwEX06KaqU"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/indices.pickle ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uEQCFIPnvrQG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from torch.nn.functional import one_hot\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n",
        "cfg = Config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5C3SVZoupGKd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class KasreDS(Dataset):\n",
        "    def __init__(self, cfg):\n",
        "        # loading word embedding model\n",
        "        try:\n",
        "            handle = open(cfg.we_pickled_model_dir, 'rb') \n",
        "            self.word_embedding_model = pickle.load(handle)\n",
        "        except FileNotFoundError:\n",
        "            self.word_embedding_model = KeyedVectors.load_word2vec_format(cfg.we_model_dir, binary=False)\n",
        "            with open(cfg.we_pickled_model_dir, 'wb') as handle:\n",
        "                pickle.dump(self.word_embedding_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        sents, all_pos_tags, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "        print(len(sents))\n",
        "        sents_shuf = []\n",
        "        all_pos_tags_shuf = []\n",
        "        all_ezafe_tags_shuf = []\n",
        "        index_shuf = list(range(len(sents)))\n",
        "\n",
        "        for i in index_shuf:\n",
        "            sents_shuf.append(sents[i])\n",
        "            all_pos_tags_shuf.append(all_pos_tags[i])\n",
        "            all_ezafe_tags_shuf.append(all_ezafe_tags[i])\n",
        "\n",
        "        random.seed(17)\n",
        "        random.shuffle(index_shuf)\n",
        "        \n",
        "        self.sents_shuf = sents_shuf\n",
        "        print('data:', len(self.sents_shuf[0]))\n",
        "        self.data = sents_shuf\n",
        "        sents, all_pos_tags, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "        self.sents = sents\n",
        "        self.all_pos_tags = all_pos_tags\n",
        "        self.all_ezafe_tags = all_ezafe_tags\n",
        "\n",
        "        \n",
        "        try:\n",
        "              with open('indices.pickle', 'rb')  as handle:\n",
        "                self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index = pickle.load(handle)\n",
        "                \n",
        "                print(self.pos_tag_to_index)\n",
        "\n",
        "                self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "                self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "          \n",
        "              \n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print('Building vocabulary...')\n",
        "\n",
        "            vocab_list = []\n",
        "            char_list = []\n",
        "            for sent in self.data:\n",
        "                for word in sent:\n",
        "                    vocab_list.append(word)\n",
        "                    for char in word:\n",
        "                        char_list.append(char)\n",
        "            \n",
        "            most_common_words = Counter(vocab_list).most_common(cfg.num_words)\n",
        "            most_common_chars = Counter(char_list).most_common(cfg.num_chars)\n",
        "            \n",
        "            self.word_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0)] + most_common_words):\n",
        "                self.word_to_index[pair[0]] = i + 1\n",
        "\n",
        "            self.char_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0), ('<UNK>', 1)] + most_common_chars):\n",
        "                self.char_to_index[pair[0]] = i + 1\n",
        "            \n",
        "            self.pos_tag_to_index = {}\n",
        "            for i, tag in enumerate(set(x for y in self.all_pos_tags for x in y)):\n",
        "                self.pos_tag_to_index[tag] = i + 1\n",
        "\n",
        "            self.ezafe_tag_to_index = {'O': 0, 'e': 1,'ye': 2, 've':3, 'y':4, '@e':5}\n",
        "\n",
        "            self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "            self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "\n",
        "            # saving the tokenizers\n",
        "            with open('indices.pickle', 'wb') as handle:\n",
        "                indices = self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index\n",
        "                pickle.dump(indices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "    def _data_reader(self, directory):\n",
        "        sents, sent = [], []\n",
        "        all_ezafe_tags, ezafe_tags = [], []\n",
        "        all_pos_tags, pos_tags = [], []\n",
        "        with open(directory) as bijankhan_corpus:\n",
        "            for line in bijankhan_corpus:\n",
        "                if line != '\\n':\n",
        "                    word, pos_tag, ezafe_tag = line.strip().split('\\t')\n",
        "                    sent.append(word.replace('ي', 'ی').replace('ك', 'ک').replace('ة', 'ه'))\n",
        "                    pos_tags.append(pos_tag)\n",
        "                    ezafe_tags.append(ezafe_tag)\n",
        "                else:\n",
        "                    if len(sent)>1 :\n",
        "                      sents.append(sent)\n",
        "                      all_pos_tags.append(pos_tags)\n",
        "                      all_ezafe_tags.append(ezafe_tags)\n",
        "                     \n",
        "                    sent = []\n",
        "                    pos_tags = []\n",
        "                    ezafe_tags = []\n",
        "\n",
        "        return sents, all_pos_tags, all_ezafe_tags\n",
        "\t\n",
        "\n",
        "    def _pad(self, word):\n",
        "        for _ in range(cfg.word_max_len - len(word)):\n",
        "            word.append(0)\n",
        "        return word\n",
        "    \n",
        "\n",
        "    def _sent_to_index(self, sentence, mode='word'):\n",
        "        if mode is 'word':\n",
        "            return [self.word_to_index.get(word, 1) for word in sentence]\n",
        "        elif mode is 'char':\n",
        "            indexed_sentence = []\n",
        "            for word in sentence:\n",
        "                indexed_word = []\n",
        "                for char in word:\n",
        "                    indexed_word.append(self.char_to_index.get(word, 1))\n",
        "                indexed_sentence.append(self._pad(indexed_word))\n",
        "            return indexed_sentence\n",
        "\n",
        "\n",
        "    def _sent_to_embed(self, sentence):\n",
        "        embed_sent = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                embed_sent.append(self.word_embedding_model[word])\n",
        "            except KeyError:\n",
        "                embed_sent.append([0 for _ in range(cfg.word_embed_dim)])\n",
        "        return embed_sent\n",
        "\n",
        "    \n",
        "    def _pos_tags_to_index(self, tags):\n",
        "        return torch.stack([one_hot(torch.tensor(self.pos_tag_to_index[tag]), num_classes=cfg.num_pos_tags+1) for tag in tags])\n",
        "\n",
        "    \n",
        "    def _ezafe_tags_to_index(self, tags):\n",
        "        return [self.ezafe_tag_to_index[tag] for tag in tags]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        char = True\n",
        "        pos=None\n",
        "        sent, pos_tag, ezafe_tag = self.sents[idx], self.all_pos_tags[idx], self.all_ezafe_tags[idx]\n",
        "        sent_char = self._sent_to_index(sent, mode='char')\n",
        "        sent_word = self._sent_to_embed(sent)\n",
        "        length = [1 for _ in range(len(sent))]\n",
        "        tag = self._ezafe_tags_to_index(ezafe_tag)\n",
        "        pos_tag = self._pos_tags_to_index(pos_tag)\n",
        "        pos_tag = torch.tensor(pos_tag)\n",
        "        # if char:\n",
        "        #     return (np.array(sent_word), np.array(sent_char), np.array(length)), np.array(tag)\n",
        "        if char:\n",
        "            return torch.tensor(sent_word), pos_tag, torch.tensor(tag)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ad6WjDiarCWW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class KasreTokenizer:\n",
        "  def __init__(self, cfg, pos_pipe, normalizer):\n",
        "    self.normalizer = normalizer\n",
        "    self.pos_pipe = pos_pipe\n",
        "    punctuations = r')(}{:؟!،؛»«.' + r\"/<>?.,:;\"\n",
        "    self.punctuations = '[' + punctuations + string.punctuation + ']'\n",
        "    handle = open(cfg.we_pickled_model_dir, 'rb') \n",
        "    self.word_embedding_model = pickle.load(handle)\n",
        "    with open('indices.pickle', 'rb')  as handle:\n",
        "      self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index = pickle.load(handle)\n",
        "      self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "      self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "\n",
        "  def _sent_to_index(self, sentence, mode='word'):\n",
        "      if mode is 'word':\n",
        "          return [self.word_to_index.get(word, 1) for word in sentence]\n",
        "      elif mode is 'char':\n",
        "          indexed_sentence = []\n",
        "          for word in sentence:\n",
        "              indexed_word = []\n",
        "              for char in word:\n",
        "                  indexed_word.append(self.char_to_index.get(word, 1))\n",
        "              indexed_sentence.append(self._pad(indexed_word))\n",
        "          return indexed_sentence\n",
        "\n",
        "\n",
        "  def _sent_to_embed(self, sentence):\n",
        "      embed_sent = []\n",
        "      for word in sentence:\n",
        "          try:\n",
        "              embed_sent.append(self.word_embedding_model[word])\n",
        "          except KeyError:\n",
        "              embed_sent.append([0 for _ in range(cfg.word_embed_dim)])\n",
        "      return embed_sent\n",
        "\n",
        "  \n",
        "  def _pos_tager(self, text):\n",
        "    doc = self.pos_pipe(text)\n",
        "    pos = list()\n",
        "    for i in range(len(doc.sentences)):\n",
        "      for j in range(len(doc.sentences[i].tokens)):\n",
        "        text = doc.sentences[i].tokens[j].words[0].text\n",
        "        xpos = doc.sentences[i].tokens[j].words[0].xpos\n",
        "        pos.append(xpos)\n",
        "    return pos\n",
        "\n",
        "  def _pos_tags_to_index(self, tags):\n",
        "      return torch.stack([one_hot(torch.tensor(self.pos_tag_to_index[tag]), num_classes=cfg.num_pos_tags+1) for tag in tags])\n",
        "  \n",
        "  def _sent_to_pos(self, sent):\n",
        "      pos = self._pos_tager(sent)\n",
        "      return pos\n",
        "\n",
        "  def tokenizer(self, sent):\n",
        "      sent = self.normalizer.normalize(sent)\n",
        "      sent = re.sub(self.punctuations, lambda x: ' ' + x.group() + ' ', sent)\n",
        "      sent_ = sent.split()\n",
        "      sent_word = self._sent_to_embed(sent_)\n",
        "      pos_tag = self._sent_to_pos(sent)\n",
        "      pos_tag = self._pos_tags_to_index(pos_tag)\n",
        "      pos_tag = torch.tensor(pos_tag)\n",
        "      return torch.tensor(sent_word), pos_tag, sent_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi0XojytXK2z",
        "outputId": "2d1473aa-ff55-4845-bd8d-7756524060a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272933\n",
            "data: 23\n",
            "Building vocabulary...\n"
          ]
        }
      ],
      "source": [
        "kasre_ds = KasreDS(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D-SJzbuMKSJt"
      },
      "outputs": [],
      "source": [
        "!cp indices.pickle drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxrv2eqDg4ME",
        "outputId": "9271c9c9-9896-441d-96aa-6de60cd49c11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272933"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(kasre_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVPYR9ujIwqk",
        "outputId": "a1d514aa-ff77-4e9e-fb1d-828cd12b64b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:171: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "_, x, _ = kasre_ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "M9TMY9oVkLbu"
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset = torch.utils.data.random_split(kasre_ds,(271933, 1000), generator=torch.Generator().manual_seed(42) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUhCr1mEsmn7",
        "outputId": "6c5601c3-46cf-4469-f0a6-bf827cb50f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FUDmL6Ahkg51"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, \n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    val_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FDmmOi4ptcHq"
      },
      "outputs": [],
      "source": [
        "dataloaders = {'train': train_loader,\n",
        "               'test': test_loader,\n",
        "               'val': val_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AYg1NIvEI0D1"
      },
      "outputs": [],
      "source": [
        "class KasreAdder(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.lstm = nn.LSTM(cfg.word_embed_dim, cfg.lstm_units // 2,\n",
        "                            num_layers=2, bidirectional=True, batch_first=True)\n",
        "    \n",
        "    self.lstm_pos = nn.LSTM(34, 8,\n",
        "                            num_layers=1, bidirectional=True, batch_first=True)\n",
        "    \n",
        "    self.hidden2tag = nn.Linear(cfg.lstm_units+16, cfg.num_tags)\n",
        "    self.dropout = nn.Dropout()\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return (torch.zeros(4, 1, self.cfg.lstm_units // 2).to(device),\n",
        "            torch.zeros(4, 1, self.cfg.lstm_units // 2).to(device))\n",
        "\n",
        "  def init_hidden_pos(self):\n",
        "    return (torch.zeros(2, 1, 8).to(device),\n",
        "            torch.zeros(2, 1, 8).to(device)) \n",
        "  \n",
        "    \n",
        "  def forward(self, x, pos, hidden=None):\n",
        "    # print(f'x shape {x.shape}')\n",
        "    self.hidden = hidden\n",
        "    if hidden is None:\n",
        "      self.hidden = self.init_hidden()\n",
        "      self.hidden_pos = self.init_hidden_pos()\n",
        "    lstm_out, self.hidden = self.lstm(x, self.hidden,)\n",
        "    lstm_pos_out, self.hidden_pos = self.lstm_pos(pos, self.hidden_pos,)\n",
        "    # print(f'lstm_out {lstm_out.shape}')\n",
        "    # lstm_out = lstm_out.view(len(x), self.cfg.lstm_units)\n",
        "    lstm_out = torch.concat((lstm_out, lstm_pos_out), dim=2)\n",
        "    lstm_out = self.dropout(lstm_out)\n",
        "    lstm_feats = self.hidden2tag(lstm_out[0])\n",
        "    return lstm_feats\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oblrrmdmmlzq"
      },
      "outputs": [],
      "source": [
        "model = KasreAdder(cfg).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tijkR5ge2l5h"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load('drive/MyDrive/kasre_pos_model_big.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ERgU-grwsIQ0"
      },
      "outputs": [],
      "source": [
        "lr=1e-3\n",
        "epochs = 2\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, threshold=0.05, min_lr=1e-7, verbose=True, factor=0.1)\n",
        "es_patience = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Sv9MhXOjsgqy"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, lr_scheduler, dataloaders, num_epochs=10):\n",
        "  model = model.train()\n",
        "  train_loss_history = list()\n",
        "  val_loss_history = list()\n",
        "  best_epoch = {'epoch':0, 'accuracy':0, 'loss':-100.0}\n",
        "  model_path = f'checkpoints/RUN_{RUN}'\n",
        "  os.mkdir(model_path)\n",
        "  for epoch in range(num_epochs):\n",
        "    model = model.train()\n",
        "    pbar = tqdm(dataloaders['train'])\n",
        "    epoch_losses = np.array([])\n",
        "    for (batch, pos_batch, labels) in pbar:\n",
        "      batch = batch.to(device, dtype=torch.float)\n",
        "      pos_batch = pos_batch.to(device, dtype=torch.float)\n",
        "      labels = labels.to(device, dtype=torch.long)[0]\n",
        "      optimizer.zero_grad()\n",
        "      out = model(batch, pos_batch)\n",
        "      # print(batch.shape)\n",
        "      # print(labels.shape)\n",
        "      # print('*************')\n",
        "      # print(out.shape)\n",
        "      loss = criterion(out, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_losses = np.append(epoch_losses, loss.item())\n",
        "      pbar.set_description(f'epoch {epoch+1}/{num_epochs},\\\n",
        "                            loss= {epoch_losses.mean():.4f}')\n",
        "    train_loss_history.append(epoch_losses.mean())\n",
        "    # lr_scheduler.step()\n",
        "\n",
        "    # validation\n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "      pbar = tqdm(dataloaders['val'])\n",
        "      val_loss = np.array([])\n",
        "      n_samples = 0\n",
        "      n_corrects = 0\n",
        "      for (batch, pos_batch, labels) in pbar:\n",
        "        batch = batch.to(device, dtype=torch.float)\n",
        "        pos_batch = pos_batch.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device, dtype=torch.long)[0]\n",
        "        # labels = torch.tensor([l for l in labels for _ in range(30)]).to(device, dtype=torch.long)\n",
        "        out = model(batch, pos_batch)\n",
        "        loss = criterion(out, labels)\n",
        "        val_loss = np.append(val_loss, loss.item())\n",
        "        out = nn.Softmax()(out)\n",
        "        out = out.argmax(1)\n",
        "        n_corrects += (out == labels).sum()\n",
        "        n_samples += out.shape[0]\n",
        "      val_acc = n_corrects/n_samples\n",
        "      val_loss = val_loss.mean()\n",
        "      val_loss_history.append(val_loss)\n",
        "      lr_scheduler.step(val_loss)\n",
        "      if val_acc > best_epoch['accuracy']:\n",
        "        best_epoch = {'epoch':epoch, 'accuracy':val_acc, 'loss':val_loss}\n",
        "        best_model_path = os.path.join(model_path, f'best_val_checkpoint.pt')\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, loss:= {val_loss.mean():.4f}, accuracy= {(n_corrects/n_samples):.4f}')\n",
        "      pbar.set_description(f'epoch {epoch+1}/{num_epochs}, loss:= {val_loss.mean():.4f}, accuracy= {(n_corrects/n_samples):.4f}')\n",
        "    if (sorted(val_loss_history[-es_patience:]) == val_loss_history[-es_patience:]) and (len(val_loss_history)>2*es_patience):\n",
        "      break\n",
        "  model.load_state_dict(torch.load(best_model_path))\n",
        "  print(best_epoch)\n",
        "  return model, train_loss_history, val_loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pBFH833tS7D",
        "outputId": "1336087e-5958-4945-c393-28dfcdbf11c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/271933 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:161: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "epoch 1/2,                            loss= 0.0828: 100%|██████████| 271933/271933 [1:15:09<00:00, 60.31it/s]\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 137.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2, loss:= 0.0515, accuracy= 0.9851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2/2,                            loss= 0.0511: 100%|██████████| 271933/271933 [1:15:27<00:00, 60.06it/s]\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 131.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2/2, loss:= 0.0466, accuracy= 0.9873\n",
            "{'epoch': 1, 'accuracy': tensor(0.9873, device='cuda:0'), 'loss': 0.04660904896322677}\n"
          ]
        }
      ],
      "source": [
        "RUN += 1\n",
        "model, loss_history, val_loss_history = train(model, optimizer, criterion, lr_scheduler, dataloaders, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPXYSGkDSWJH",
        "outputId": "60f36f85-efba-4772-efc5-677cc7e9915c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bOxae36F5gdV"
      },
      "outputs": [],
      "source": [
        "!cp checkpoints/RUN_1/best_val_checkpoint.pt drive/MyDrive/kasre_pos_model_big_100d.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb8oVPlZTYrb"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('drive/MyDrive/kasre_model.pt'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdNeBoBH4PcX",
        "outputId": "12ce9a0c-a0e6-4857-f7f0-f0309de2e2a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KasreAdder(\n",
              "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (lstm_pos): LSTM(34, 8, batch_first=True, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=272, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yD-JZKh5v-hW"
      },
      "outputs": [],
      "source": [
        "from parsivar import Normalizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NDXGSM19u-FM"
      },
      "outputs": [],
      "source": [
        "my_normalizer = Normalizer()\n",
        "tokenizer = KasreTokenizer(cfg, pos_pipe=nlp_pos, normalizer=my_normalizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5hv8WcjC5cg7"
      },
      "outputs": [],
      "source": [
        "tag2kasre =  {0:'',\n",
        "              1:'ِ',\n",
        "              2:'‌یِ',\n",
        "              3:'ِ',\n",
        "              4:'ی',\n",
        "              5:'ِ'}\n",
        "\n",
        "def add_kasre(sent):\n",
        "  sent_words, pos, sent_ = tokenizer.tokenizer(sent)\n",
        "  # print(sent_)\n",
        "  sent_words = torch.tensor(sent_words).float().to(device)\n",
        "  pos = torch.tensor(pos).float().to(device)\n",
        "  # print(f'sent shape {sent_words.shape}, pos shape {pos.shape}')\n",
        "  with torch.no_grad():\n",
        "    out = model(sent_words.unsqueeze(0), pos.unsqueeze(0))\n",
        "    out = nn.Softmax()(out)\n",
        "    out = out.argmax(1).cpu().numpy()\n",
        "  result = ''\n",
        "  # print(out)\n",
        "  for i,word in enumerate(sent_):\n",
        "    ezafe_tag = tag2kasre[out[i]]\n",
        "    if (word[-1] in ['ی']) and out[i]==2:\n",
        "      ezafe_tag = tag2kasre[1]\n",
        "    result += word + ezafe_tag + ' '\n",
        "  return result\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "lF4-e3bxvpxI"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hH5_WcMjSURs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zV5RDmOqAgV",
        "outputId": "3a937d70-550e-4a00-8a1c-a76a0d09d8a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 1 0 0 2 0 1 2 0 0]\n",
            "در پنجاه سالگی نیز سرانجام به خاطرِ همین ازهم پاشیدگیِ هویتی دچارِ بحرانیِ عمیق شد \n",
            "0.18042421340942383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "print(add_kasre('در پنجاه سالگی نیز سرانجام به خاطر همین ازهم پاشیدگی هویتی دچار بحرانی عمیق شد'))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue5KdNw3p0Ud",
        "outputId": "ec443085-1f28-4834-897f-1f1cd108195d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تفسیر : \n",
            "تفسیر: \n",
            "\n",
            "جین دو بلسیل عطشِ زیادی برای جلبِ توجه داشت . \n",
            "جین دو بلسیل عطش زیادی برای جلب توجه داشت. \n",
            "\n",
            "او والدینش را خسته کرده‌بود ، طوری که مجبور شدند او را به صومعه‌ای در شهرِ پواتیه بفرستند . \n",
            "او والدینش را خسته کرده بود، طوری که مجبور شدند او را به صومعه ای در شهر پواتیه بفرستند. \n",
            "\n",
            "او در آنجا با خودخواهی‌ها و حسِ برتریِ اش دیگر راهبه‌ها را به حدِ جنون رساند . \n",
            "او در آنجا با خودخواهی ها و حس برتری اش دیگر راهبه ها را به حد جنون رساند. \n",
            "\n",
            "وقتی به لودون فرستاده شد ، تصمیم گرفت روشی متفاوت در پیش بگیرد تا به شهرتی که شدیدا به آن نیاز داشت ، دست یابد . \n",
            "وقتی به لودون فرستاده شد، تصمیم گرفت روشی متفاوت در پیش بگیرد تا به شهرتی که شدیداً به آن نیاز داشت، دست یابد. \n",
            "\n",
            "وقتی به او کتاب‌هایی در زمینه‌یِ معنویت داده شد ، به این نتیجه رسید که از نظرِ دانش و عرفان از بقیه پیشی گیرد تا برتریِ خود را اثبات کند . \n",
            "وقتی به او کتاب هایی در زمینۀ معنویت داده شد، به این نتیجه رسید که از نظر دانش و عرفان از بقیه پیشی گیرد تا برتری خود را اثبات کند. \n",
            "\n",
            "او در هر دو زمینه از خود درخشش نشان داد تا توانست نظرِ رئیسِ صومعه را جلب کند . \n",
            "او در هر دو زمینه از خود درخشش نشان داد تا توانست نظر رئیس صومعه را جلب کند. \n",
            "\n",
            "اما وقتی به عنوانِ ریاستِ صومعه انتخاب شد ، بی‌حوصله‌بود و توجهی که می‌گرفت برایش کافی نبود . \n",
            "اما وقتی به عنوان ریاست صومعه انتخاب شد، بی حوصله بود و توجهی که می گرفت برایش کافی نبود. \n",
            "\n",
            "خواب‌هایی که از گرندیر تعریف می‌کرد ، آمیزه‌ای از دروغ و تلقین‌بود . \n",
            "خواب هایی که از گرندیر تعریف می کرد، آمیزه ای از دروغ و تلقین بود. \n",
            "\n",
            "وقتی جن گیرها از راه رسیدند ، به او کتابی درباره‌یِ شیطان‌شناسی دادند و جین تمامِ آن را خواند تا فوتِ وفن‌یِ تسخیرشدگی توسطِ شیطان را بیاموزد و به جن گیرها نشانه‌هایی دقیق و مطمئن بدهد . \n",
            "وقتی جن گیرها از راه رسیدند، به او کتابی دربارۀ شیطان شناسی دادند و جین تمام آن را خواند تا فوت وفن تسخیرشدگی توسط شیطان را بیاموزد و به جن گیرها نشانه هایی دقیق و مطمئن بدهد. \n",
            "\n",
            "او حالا ستاره‌یِ تماشاچیان شده‌بود . \n",
            "او حالا ستارۀ تماشاچیان شده بود. \n",
            "\n",
            "او بیشتر از دیگر راهبه‌ها رفتارهایی عجیب که نشان از تنزلِ عرفانیِ او داشتند ، انجام می‌داد . \n",
            "او بیشتر از دیگر راهبه ها رفتارهایی عجیب که نشان از تنزل عرفانی او داشتند، انجام می داد.\n",
            "\n",
            "پس از اعدامِ وحشتناکِ گرندیر ، که تاثیرِ عمیقی بر راهبه‌ها گذاشته‌بود ، زیرا خود را تا حدی در آن مقصر می‌دانستند ، جین کمبودِ توجهِ زیادی را تجربه کرد و آن را غیرقابلِ تحمل دید ؛ \n",
            "پس از اعدام وحشتناک گرندیر، که تأثیر عمیقی بر راهبه ها گذاشته بود، زیرا خود را تا حدی در آن مقصر می دانستند، جین کمبود توجه زیادی را تجربه کرد و آن را غیرقابل تحمل دید؛\n",
            "\n",
            "پس طوری وانمود کرد که گویی شیاطین دست از سرِ او برنمی دارند . \n",
            " پس طوری وانمود کرد که گویی شیاطین دست از سر او برنمی دارند. \n",
            "\n",
            "او به استادی ماهر در تشخیصِ نقاطِ ضعف و تمناهایِ خفته‌یِ اطرافیانِ خود یعنی جن گیرها ، راهبه‌ها و حالا پدرِ سورین تبدیل شده‌بود . \n",
            "او به استادی ماهر در تشخیص نقاط ضعف و تمناهای خفتۀ اطرافیان خود یعنی جن گیرها، راهبه ها و حالا پدر سورین تبدیل شده بود. \n",
            "\n",
            "پدرِ سورین بسیار دوست داشت که به عنوانِ ناجیِ جین از دستِ شیاطین شناخته شود ، پس به سادگی فریبِ آن به اصطلاحِ معجزات را خورد . \n",
            "پدر سورین بسیار دوست داشت که به عنوان ناجی جین از دست شیاطین شناخته شود، پس به سادگی فریب آن به اصطلاح معجزات را خورد. \n",
            "\n",
            "درباره‌یِ نشانه‌هایِ کفِ دستِ چپ بررسی‌هایِ بعدی نشان داد که جین خودش این اسامی را با اسید یا با نشاسته‌هایِ رنگیِ کفِ دستش می‌نوشته است . \n",
            "دربارۀ نشانه های کف دست چپ بررسی های بعدی نشان داد که جین خودش این اسامی را با اسید یا با نشاسته های رنگی کف دستش می نوشته است. \n",
            "\n",
            "این بسیار عجیب‌بود که نشانه‌ها کفِ دستِ چپِ او نمایان می‌شدند و دلیلش این‌بود که او راستِ دست‌بود و خودش آن‌ها را می‌نوشت . \n",
            "این بسیار عجیب بود که نشانه ها کف دست چپ او نمایان می شدند و دلیلش این بود که او راست دست بود و خودش آن ها را می نوشت. \n",
            "\n",
            "گفته می‌شود وقتی فردی دچارِ هیستری باشد ، پوستِ بدنِ او بسیار نازک می‌شود و حتی یک خراشِ ناخن نیز می‌تواند رویِ پوستِ او ردی به جا بگذارد . \n",
            "گفته می شود وقتی فردی دچار هیستری باشد، پوست بدن او بسیار نازک می شود و حتی یک خراش ناخن نیز می تواند روی پوست او ردی به جا بگذارد. \n",
            "\n",
            "در موردِ تدهین17 نیز جین به عنوانِ کسی که سال‌ها با درمان‌هایِ گیاهی سروکار داشت ، به خوبی می‌توانست قطره‌هایِ معطرِ ماندگاری را انتخاب کند . \n",
            "در مورد تدهین17 نیز جین به عنوان کسی که سال ها با درمان های گیاهی سروکار داشت، به خوبی می توانست قطره های معطر ماندگاری را انتخاب کند. \n",
            "\n",
            "آن‌هایی که به راحتیِ فریبِ نشانه‌یِ کفِ دستش را خوردند ، به راحتی نیز آن داستان تدهین را باور کردند . \n",
            "آن هایی که به راحتی فریب نشانۀ کف دستش را خوردند، به راحتی نیز آن داستان تدهین را باور کردند.\n",
            "\n",
            "حتی سورین نیز به درخواستِ نیاز به سفر شک کرد . \n",
            "حتی سورین نیز به درخواست نیاز به سفر شک کرد. \n",
            "\n",
            "در این مرحله جین دیگر نمی‌توانست نیاز به توجه را از کسی پنهان کند . \n",
            "در این مرحله جین دیگر نمی توانست نیاز به توجه را از کسی پنهان کند. \n",
            "\n",
            "سال‌ها بعد ، جین یک خودزندگی نامه نوشت که در آن شخصیتِ نمایشی خود را پذیرفته‌بود . \n",
            "سال ها بعد، جین یک خودزندگی نامه نوشت که در آن شخصیت نمایشی خود را پذیرفته بود. \n",
            "\n",
            "او دائم در حالِ نقشِ بازیِ کردن‌بود ، هرچند که ادعا می‌کرد معجزه‌یِ آخر ، واقعی بوده است . \n",
            "او دائم در حال نقش بازی کردن بود، هرچند که ادعا می کرد معجزۀ آخر، واقعی بوده است. \n",
            "\n",
            "بسیاری از خواهرها که هر روز با او در تعامل‌بودند ، این وجهه‌یِ شخصیتیِ او را می‌شناختند و او را یک هنرپیشه‌یِ تشنه‌یِ شهرت و توجه توصیف می‌کردند . \n",
            "بسیاری از خواهرها که هر روز با او در تعامل بودند، این وجهۀ شخصیتی او را می شناختند و او را یک هنرپیشۀ تشنۀ شهرت و توجه توصیف می کردند.\n",
            "\n",
            "یکی از عجیب ترین تضادها درباره‌یِ خودشیفتگیِ عمیق این است که اغلب قابلِ تشخیص نیست ، مگر آنکه رفتارِ فرد آنقدر افراطی باشد که نادیده گرفتنِ آن مشکل شود . \n",
            "یکی از عجیب ترین تضادها دربارۀ خودشیفتگی عمیق این است که اغلب قابل تشخیص نیست، مگر آنکه رفتار فرد آنقدر افراطی باشد که نادیده گرفتن آن مشکل شود. \n",
            "\n",
            "دلیلش ساده است : \n",
            "دلیلش ساده است: \n",
            "\n",
            "خودشیفتگان عمیقِ استاد پنهان کاری‌اند . \n",
            "خودشیفتگان عمیق استاد پنهان کاری اند. \n",
            "\n",
            "آن‌ها از همان ابتدا می‌دانند که اگر شخصیتِ اصلیِ خود یعنی نیاز به توجه و برتری را رو کنند ، مردم از آن‌ها دور می‌شوند . \n",
            "آن ها از همان ابتدا می دانند که اگر شخصیت اصلی خود یعنی نیاز به توجه و برتری را رو کنند، مردم از آن ها دور می شوند. \n",
            "\n",
            "آن‌ها فقدانِ یک خودِ منسجم را امتیاز می‌دانند . \n",
            "آن ها فقدان یک خود منسجم را امتیاز می دانند. \n",
            "\n",
            "آن‌ها می‌توانند نقش‌هایِ زیادی بازی کنند . \n",
            "آن ها می توانند نقش های زیادی بازی کنند. \n",
            "\n",
            "می‌توانند نیاز به توجه را با ابزارِ گوناگون مخفی کنند . \n",
            "می توانند نیاز به توجه را با ابزار گوناگون مخفی کنند. \n",
            "\n",
            "آن‌ها می‌توانند بیشتر از آدم‌هایِ عادیِ خود را اخلاقِ گرا و متدین نشان دهند . \n",
            "آن ها می توانند بیشتر از آدم های عادی خود را اخلاق گرا و متدین نشان دهند. \n",
            "\n",
            "آن‌ها هرگز از یک هدفِ خوب و اخلاقی حمایت نمی‌کنند و در خدمتش نیستند ، اما تظاهر به این کار را بلدند . \n",
            "آن ها هرگز از یک هدف خوب و اخلاقی حمایت نمی کنند و در خدمتش نیستند، اما تظاهر به این کار را بلدند. \n",
            "\n",
            "چه کسی می‌تواند جدیتِ این نمایشِ اخلاقی را زیرِ سوال ببرد ؟ گاهی نیز مسیری مخالف را در پیش می‌گیرند و خود را یک قربانی یا فردی که در دستِ یک ظالم افتاده است و دنیا او را نمی‌بیند ، جا می‌زنند . \n",
            "چه کسی می تواند جدیت این نمایش اخلاقی را زیر سؤال ببرد؟ گاهی نیز مسیری مخالف را در پیش می گیرند و خود را یک قربانی یا فردی که در دست یک ظالم افتاده است و دنیا او را نمی بیند، جا می زنند. \n",
            "\n",
            "کافی است همان یک لحظه فریبشان را بخورید تا بعدها طعمه‌یِ نیازهایِ آن‌ها یا وسیله‌یِ رسیدن به هدف‌هایشان شوید . \n",
            "کافی است همان یک لحظه فریبشان را بخورید تا بعدها طعمۀ نیازهای آن ها یا وسیلۀ رسیدن به هدف هایشان شوید. \n",
            "\n",
            "آن‌ها همدلیِ شما را به بازی می‌گیرند . \n",
            "آن ها همدلی شما را به بازی می گیرند.\n",
            "\n",
            "تنها راهکار این است که حیله‌یِ شان را به خوبی بشناسید . \n",
            "تنها راهکار این است که حیله شان را به خوبی بشناسید. \n",
            "\n",
            "این طور آن‌ها را تشخیص دهید که همیشه تمرکز را بر خودشان می‌گذارند . \n",
            "این طور آن ها را تشخیص دهید که همیشه تمرکز را بر خودشان می گذارند. \n",
            "\n",
            "توجه کنید که چطور همیشه در نیکی یا در رنج یا حتی در فسادِ خودشان را برتر از همه نشان می‌دهند . \n",
            "توجه کنید که چطور همیشه در نیکی یا در رنج یا حتی در فساد خودشان را برتر از همه نشان می دهند. \n",
            "\n",
            "به کیفیتِ نمایشی دائمیِ رفتارها و حرکاتشان نگاه کنید . \n",
            "به کیفیت نمایشی دائمی رفتارها و حرکاتشان نگاه کنید. \n",
            "\n",
            "هرچه می‌گویند یا انجام می‌دهند مصرفِ عمومی دارد . \n",
            "هرچه می گویند یا انجام می دهند مصرف عمومی دارد. \n",
            "\n",
            "اجازه ندهید در سناریویِ آن‌ها قربانی شوید . \n",
            "اجازه ندهید در سناریوی آن ها قربانی شوید.\n",
            "\n",
            "3 . \n",
            "3. \n",
            "\n",
            "زوجِ خودشیفته . \n",
            "زوج خودشیفته. \n",
            "\n",
            "در سالِ 1862 ، چند روز قبل از آنکه لئو تولستوی سی ودو ساله ، سونیا بهرز را که فقط هجده سال داشت به عقدِ خود درآورد ، تصمیم گرفت که هیچ رازی بینِ آن دو پنهان نماند . \n",
            "در سال 1862، چند روز قبل از آنکه لئو تولستوی سی ودو ساله، سونیا بهرز را که فقط هجده سال داشت به عقد خود درآورد، تصمیم گرفت که هیچ رازی بین آن دو پنهان نماند. \n",
            "\n",
            "به عنوانِ بخشی از این رازگشاییِ او دفترچه‌یِ یادداشت‌هایش را به سونیا داد . \n",
            "به عنوان بخشی از این رازگشایی او دفترچۀ یادداشت هایش را به سونیا داد. \n",
            "\n",
            "سونیا همان طورکه آن‌ها را می‌خواند ، می‌گریست و عصبانی شده‌بود . \n",
            "سونیا همان طورکه آن ها را می خواند، می گریست و عصبانی شده بود. \n",
            "\n",
            "در این صفحات تولستوی همه چیز از جمله رابطه‌یِ اش با یک زنِ روستایی را که از او پسری نامشروع داشت ، نوشته‌بود . \n",
            "در این صفحات تولستوی همه چیز از جمله رابطه اش با یک زن روستایی را که از او پسری نامشروع داشت، نوشته بود. \n",
            "\n",
            "او همچنین از قمارها و زنانِ فاحشه‌ای نوشته‌بود که با آن‌ها حشرونشر داشت . \n",
            "او همچنین از قمارها و زنان فاحشه ای نوشته بود که با آن ها حشرونشر داشت. \n",
            "\n",
            "سونیا با خواندنِ این صفحات هم حسِ حسادتش برانگیخته شد هم نفرت و بیزاریِ تمامِ وجودش را گرفت . \n",
            "سونیا با خواندن این صفحات هم حس حسادتش برانگیخته شد هم نفرت و بیزاری تمام وجودش را گرفت. \n",
            "\n",
            "چه چیز باعث شد تولستوی سونیا را به خواندنِ یادداشت‌ها وادارد ؟ سونیا تولستوی را متهم کرد که دوستش ندارد و همواره فکرش پیشِ زنانِ دیگر است . \n",
            "چه چیز باعث شد تولستوی سونیا را به خواندن یادداشت ها وادارد؟ سونیا تولستوی را متهم کرد که دوستش ندارد و همواره فکرش پیش زنان دیگر است. \n",
            "\n",
            "وقتی تولستوی چنین واکنشی را دید ، خودش هم همین اتهامات را به سونیا زد . \n",
            "وقتی تولستوی چنین واکنشی را دید، خودش هم همین اتهامات را به سونیا زد. \n",
            "\n",
            "تولستوی می‌خواست با این دفترچه روزهایِ گذشته‌یِ خود را با سونیا شریک شود و به او بفهماند که به خاطرِ عشقش به سونیا تمامِ آن خوشگذرانی‌ها را کنار گذاشته است و می‌خواهد با او زندگیِ جدیدی را شروع کند . \n",
            "تولستوی می خواست با این دفترچه روزهای گذشتۀ خود را با سونیا شریک شود و به او بفهماند که به خاطر عشقش به سونیا تمام آن خوشگذرانی ها را کنار گذاشته است و می خواهد با او زندگی جدیدی را شروع کند. \n",
            "\n",
            "حالا چرا سونیا باید صداقتِ او را زیرِ سوال می‌برد ؟ به نظر می‌رسید سونیا آن طورکه ادعا می‌کرد ، تولستوی را دوست نداشت . \n",
            "حالا چرا سونیا باید صداقت او را زیر سؤال می برد؟ به نظر می رسید سونیا آن طورکه ادعا می کرد، تولستوی را دوست نداشت. \n",
            "\n",
            "اصلا چرا خداحافظی با خانواده‌یِ اش قبل از جشن برایش سخت‌بود ؟ آیا خانواده‌یِ اش را بیشتر از تولستوی دوست داشت ؟ آن‌ها سرانجام آشتی کردند و عروسی گرفتند ، اما الگویی به زندگیِ آن‌ها رخنه کرد که چهل وهشت سال ادامه داشت . \n",
            "اصلاً چرا خداحافظی با خانواده اش قبل از جشن برایش سخت بود؟ آیا خانواده اش را بیشتر از تولستوی دوست  داشت؟ آن ها سرانجام آشتی کردند و عروسی گرفتند، اما الگویی به زندگی آن ها رخنه کرد که چهل وهشت سال ادامه داشت.\n",
            "\n",
            "زندگیِ مشترک به رغمِ درگیری‌هایِ لفظیِ مکرر برای سونیا یک ضرباهنگ آرام گرفت . \n",
            "زندگی مشترک به رغم درگیری های لفظی مکرر برای سونیا یک ضرباهنگ آرام گرفت. \n",
            "\n",
            "او به معتمدترین دستیارِ تولستوی تبدیل شد . \n",
            "او به معتمدترین دستیار تولستوی تبدیل شد. \n",
            "\n",
            "کنارِ زایمانِ هشت بچه در طولِ دوازده سال که البته پنج تایِ آن‌ها زنده ماندند ، او به دقتِ کتاب‌هایِ تولستوی از جمله جنگ و صلح و آنا کارنینا را نسخه برداری می‌کرد و بیشترِ امورِ مربوط به چاپ را نیز خود عهده‌یِ دار‌بود . \n",
            "کنار زایمان هشت بچه در طول دوازده سال که البته پنج تای آن ها زنده ماندند، او به دقت کتاب های تولستوی از جمله جنگ و صلح و آنا کارنینا را نسخه برداری می کرد و بیشتر امور مربوط به چاپ را نیز خود عهده دار بود. \n",
            "\n",
            "همه چیز در زندگیِ آن دو خوب پیش می‌رفت . \n",
            "همه چیز در زندگی آن دو خوب پیش می رفت. \n",
            "\n",
            "او مردی ثروتمند‌بود و در کنارِ درآمدِ خوبی که از کتاب‌هایش داشت ، زمین‌هایی ارزشمند نیز به ارث برده‌بود . \n",
            "او مردی ثروتمند بود و در کنار درآمد خوبی که از کتاب هایش داشت، زمین هایی ارزشمند نیز به ارث برده بود. \n",
            "\n",
            "او خانواده‌یِ بزرگی داشت که به او علاقه‌یِ زیادی داشتند . \n",
            "او خانوادۀ بزرگی داشت که به او علاقۀ زیادی داشتند. \n",
            "\n",
            "او مشهور‌بود . \n",
            "او مشهور بود. \n",
            "\n",
            "اما ناگهان در پنجاه سالگی ، به شدت احساسِ غم و اندوه کرد و از کتاب‌هایی که نوشته‌بود ، احساسِ شرمساری کرد . \n",
            "اما ناگهان در پنجاه سالگی، به شدت احساس غم و اندوه کرد و از کتاب هایی که نوشته بود، احساس شرمساری کرد. \n",
            "\n",
            "او دیگر نمی‌دانست کیست و بحرانِ روحیِ عمیقی را تجربه می‌کرد . \n",
            "او دیگر نمی دانست کیست و بحران روحی عمیقی را تجربه می کرد. \n",
            "\n",
            "از نظرِ تولستوی کلیسایِ کاتولیکِ متعصب تر از آن‌بود که بتواند از آن‌ها کمکی بگیرد . \n",
            "از نظر تولستوی کلیسای کاتولیک متعصب تر از آن بود که بتواند از آن ها کمکی بگیرد. \n",
            "\n",
            "زندگیِ او تغییر کرد . \n",
            "زندگی او تغییر کرد. \n",
            "\n",
            "دیگر رمانی ننوشت و مانندِ یک رعیت به زندگی ادامه داد . \n",
            "دیگر رمانی ننوشت و مانند یک رعیت به زندگی ادامه داد. \n",
            "\n",
            "او تمامِ دارایی‌هایش را رها کرد و حقِ التالیفِ کتاب‌هایش را باطل کرد و از خانواده‌یِ خود خواست تا در این سبکِ جدیدِ زندگی با او همراه شوند و زندگیِ خود را وقفِ کمک به دیگران و امورِ روحانی کنند . \n",
            "او تمام دارایی هایش را رها کرد و حق التألیف کتاب هایش را باطل کرد و از خانوادۀ خود خواست تا در این سبک جدید زندگی با او همراه شوند و زندگی خود را وقف کمک به دیگران و امور روحانی کنند.\n",
            "\n",
            "برخلافِ انتظارش ، خانواده به ویژه‌یِ سونیا از این کار سر باز زد و با عصبانیت واکنش نشان داد . \n",
            "برخلاف انتظارش، خانواده به ویژه سونیا از این کار سر باز زد و با عصبانیت واکنش نشان داد. \n",
            "\n",
            "تولستوی از آن‌ها خواسته‌بود که سبکِ زندگی ، رفاه و آسایش و حتی میراثشان را رها کنند . \n",
            "تولستوی از آن ها خواسته بود که سبک زندگی، رفاه و آسایش و حتی میراثشان را رها کنند. \n",
            "\n",
            "سونیا هیچ نیازی به این تغییرِ عجیب در زندگیِ اش نمی‌دید و از تهمت‌هایِ تولستوی که او را شیطان زده و مادیِ گرا می‌خواند ، بیزار‌بود . \n",
            "سونیا هیچ نیازی به این تغییر عجیب در زندگی اش نمی دید و از تهمت های تولستوی که او را شیطان زده و مادی گرا می خواند، بیزار بود. \n",
            "\n",
            "آن‌ها یکریز مشاجره داشتند و هرگز اعلامِ آتش بس نمی‌کردند . \n",
            "آن ها یکریز مشاجره داشتند و هرگز اعلام آتش بس نمی کردند. \n",
            "\n",
            "حالا وقتی تولستوی همسرِ خود را تحلیل می‌کرد ، تمامِ چیزی که می‌دید فردی‌بود که از او به خاطرِ شهرت و پولش خوشش آمده‌بود . \n",
            "حالا وقتی تولستوی همسر خود را تحلیل می کرد، تمام چیزی که می دید فردی بود که از او به خاطر شهرت و پولش خوشش آمده بود. \n",
            "\n",
            "برایش روشن شده‌بود که چرا سونیا با او ازدواج کرده‌بود . \n",
            "برایش روشن شده بود که چرا سونیا با او ازدواج کرده بود. \n",
            "\n",
            "سونیا از نظرِ او یک زنِ دورو‌بود . \n",
            "سونیا از نظر او یک زن دورو بود. \n",
            "\n",
            "با اینکه تولستوی تمامِ حقوقِ املاک و دارایی‌هایش را کنار گذاشت ، باز هم مثلِ یک پادشاه زندگی می‌کرد و از سونیا می‌خواست برای عادت‌هایش پول خرج کند . \n",
            "با اینکه تولستوی تمام حقوق املاک و دارایی هایش را کنار گذاشت، باز هم مثل یک پادشاه زندگی می کرد و از سونیا می خواست برای عادت هایش پول خرج کند. \n",
            "\n",
            "تولستوی مثلِ یک روستایی لباس می‌پوشید ، اما اگر بیمار می‌شد ، با یک کالسکهِ خصوصیِ تجملاتی به ویلایی در جنوب می‌رفت تا آرامش بگیرد و به رغمِ اعتقادِ جدیدش به نداشتنِ رابطه ، دست از باردار کردنِ سونیا نمی‌کشید . \n",
            "تولستوی مثل یک روستایی لباس می پوشید، اما اگر بیمار می شد، با یک کالسکۀ خصوصی تجملاتی به ویلایی در جنوب می رفت تا آرامش بگیرد و به رغم اعتقاد جدیدش به نداشتن رابطه، دست از باردار کردن سونیا نمی کشید.\n",
            "\n",
            "تولستوی در آرزویِ یک زندگیِ ساده‌یِ معنوی‌بود و اکنون سونیا تنها مانعِ او در رسیدن به این زندگی‌بود . \n",
            "تولستوی در آرزوی یک زندگی سادۀ معنوی بود و اکنون سونیا تنها مانع او در رسیدن به این زندگی بود. \n",
            "\n",
            "او حضورِ سونیا در آن خانه را سرکوبگرانه می‌دانست . \n",
            "او حضور سونیا در آن خانه را سرکوبگرانه می دانست. \n",
            "\n",
            "تولستوی در نامه‌ای خطاب به سونیا نوشت : \n",
            "تولستوی در نامه ای خطاب به سونیا نوشت: \n",
            "\n",
            "« تو تمامِ اتفاقاتِ زندگیِ مان را به همه چیز به جز یک موضوعِ مهم نسبت دادی و این موضوع این‌بود که تو بی‌آنکه بدانی عاملِ بدبختی و رنج‌هایم هستی . \n",
            "«تو تمام اتفاقات زندگی مان را به همه چیز به جز یک موضوع مهم نسبت دادی و این موضوع این بود که تو بی آنکه بدانی عامل بدبختی و رنج هایم هستی. \n",
            "\n",
            "انگار قرار است تا دمِ مرگ با هم مجادله داشته باشیم . » او کتابِ سوناتِ کرویتسر را از دلِ همین تلخی‌هایِ زندگیِ اش نوشت . \n",
            "انگار قرار است تا دم مرگ با هم مجادله داشته باشیم.» او کتاب سونات کرویتسر را از دل همین تلخی های زندگی اش نوشت. \n",
            "\n",
            "در این کتاب ازدواج و زندگیِ مشترکِ خود را به رشته‌یِ تحریر درآورد و تصویریِ سیاه از سونیا را به خوانندگان ارائه داد . \n",
            "در این کتاب ازدواج و زندگی مشترک خود را به رشتۀ تحریر درآورد و تصویری سیاه از سونیا را به خوانندگان ارائه داد. \n",
            "\n",
            "نتیجه‌یِ این رفتارهایِ تولستوی این شد که سونیا به دیوانگی برسد . \n",
            "نتیجۀ این رفتارهای تولستوی این شد که سونیا به دیوانگی برسد. \n",
            "\n",
            "سرانجام در سالِ 1894 ، این حالات در سونیا شدیدتر شد ، به طوری که به تقلید از یکی از شخصیت‌هایِ رمانِ تولستوی دست به خودکشی زد . \n",
            "سرانجام در سال 1894، این حالات در سونیا شدیدتر شد، به طوری که به تقلید از یکی از شخصیت های رمان تولستوی دست به خودکشی زد. \n",
            "\n",
            "او روزی برفی در سرمایِ زمستان از خانه بیرون رفت تا از فرطِ سرمازدگی بمیرد . \n",
            "او روزی برفی در سرمای زمستان از خانه بیرون رفت تا از فرط سرمازدگی بمیرد. \n",
            "\n",
            "یکی از اعضایِ خانواده با او برخورد کرد و او را به خانه برگرداند . \n",
            "یکی از اعضای خانواده با او برخورد کرد و او را به خانه برگرداند. \n",
            "\n",
            "او دوبار دیگر نیز اقدام به خودکشی کرد ، اما زنده ماند . \n",
            "او دوبار دیگر نیز اقدام به خودکشی کرد، اما زنده ماند.\n",
            "\n",
            "اکنون این الگو تندتر و خشن تر شد . \n",
            "اکنون این الگو تندتر و خشن تر شد. \n",
            "\n",
            "تولستوی هر بار او را آزار می‌داد و او نیز از رویِ بیچارگی کاری عجیب می‌کرد ؛ \n",
            "تولستوی هر بار او را آزار می داد و او نیز از روی بیچارگی کاری عجیب می کرد؛\n",
            "\n",
            "تولستوی کم کم از سردی با سونیا پشیمان شد و از او‌طلب بخشش کرد . \n",
            " تولستوی کم کم از سردی با سونیا پشیمان شد و از او طلب بخشش کرد. \n",
            "\n",
            "او برای جبرانِ رفتارهایش به سونیا لطف‌هایی کرد . \n",
            "او برای جبران رفتارهایش به سونیا لطف هایی کرد. \n",
            "\n",
            "برای مثال ، به خانواده‌یِ اش اجازه داد حقِ التالیف کتاب‌هایش را پس بگیرند . \n",
            "برای مثال، به خانواده اش اجازه داد حق التألیف کتاب هایش را پس بگیرند. \n",
            "\n",
            "سپس رفتارهایِ جدیدی از سونیا دید که از این کرده خود نادم شد . \n",
            "سپس رفتارهای جدیدی از سونیا دید که از این کردۀ خود نادم شد. \n",
            "\n",
            "او دائمِ فرزندانش را علیهِ پدرشان می‌شوراند . \n",
            "او دائم فرزندانش را علیه پدرشان می شوراند. \n",
            "\n",
            "سونیا تولستوی را مجبور کرد که تمامِ یادداشت‌هایش را برای او بخواند و اگر او چیزی را مخفی می‌کرد ، با حیله‌یِ گری از آن‌ها سر در می‌آورد . \n",
            "سونیا تولستوی را مجبور کرد که تمام یادداشت هایش را برای او بخواند و اگر او چیزی را مخفی می کرد، با حیله گری از آن ها سر در می آورد. \n",
            "\n",
            "سونیا مراقبِ کوچک ترین حرکاتِ تولستوی‌بود . \n",
            "سونیا مراقب کوچک ترین حرکات تولستوی بود. \n",
            "\n",
            "تولستوی از فضولی‌های سونیا خسته شده‌بود و گاهی او را بسیار سرزنش می‌کرد و در بسترِ بیماری می‌افتاد و آن وقت سونیا از رفتارهایِ خودش پشیمان می‌شد . \n",
            "تولستوی از فضولی های سونیا خسته شده بود و گاهی او را بسیار سرزنش می کرد و در بستر بیماری می افتاد و آن وقت سونیا از رفتارهای خودش پشیمان می شد. \n",
            "\n",
            "چه چیز آن دو نفر را کنارِ هم نگه داشته‌بود ؟ هر یک در پی گرفتنِ توجه و عشق یکدیگر‌بودند ، اما نیل به این هدفِ دیگر محال به نظر می‌رسید . \n",
            "چه چیز آن دو نفر را کنار هم نگه داشته بود؟ هر یک در پی گرفتن توجه و عشق یکدیگر بودند، اما نیل به این هدف دیگر محال به نظر می رسید.\n",
            "\n",
            "پس از سال‌ها درد و رنج در اواخرِ اکتبرِ 1910 ، سرانجام کارد به استخوان‌یِ تولستوی رسید . \n",
            "پس از سال ها درد و رنج در اواخر اکتبر 1910، سرانجام کارد به استخوان تولستوی رسید. \n",
            "\n",
            "او در نیمه‌یِ شب به کمکِ دوستِ پزشکش وسایلش را از خانه‌یِ دزدید و تصمیم گرفت سونیا را برای همیشه ترک کند . \n",
            "او در نیمه شب به کمک دوست پزشکش وسایلش را از خانه دزدید و تصمیم گرفت سونیا را برای همیشه ترک کند. \n",
            "\n",
            "او تمامِ آن شب از ترس اینکه سونیا متوجه شود ، می‌لرزید ، اما درهرصورت سوارِ قطار از همسرش دور شد . \n",
            "او تمام آن شب از ترس اینکه سونیا متوجه شود، می لرزید، اما درهرصورت سوار قطار از همسرش دور شد. \n",
            "\n",
            "وقتی سونیا باخبر شد ، دوباره دست به خودکشی زد و خودش را در استخری که نزدیکِ خانه‌بود ، انداخت ؛ \n",
            "وقتی سونیا باخبر شد، دوباره دست به خودکشی زد و خودش را در استخری که نزدیک خانه بود، انداخت؛\n",
            "\n",
            "اما دوباره نجات یافت . \n",
            " اما دوباره نجات یافت. \n",
            "\n",
            "سپس به تولستوی نامه‌ای نوشت و از او خواهش کرد که برگردد . \n",
            "سپس به تولستوی نامه ای نوشت و از او خواهش کرد که برگردد. \n",
            "\n",
            "سونیا قول داد که رفتارش را تغییر خواهد داد ، دست از تجملات خواهد کشید و عارفانه زندگی خواهد کرد . \n",
            "سونیا قول داد که رفتارش را تغییر خواهد داد، دست از تجملات خواهد کشید و عارفانه زندگی خواهد کرد. \n",
            "\n",
            "او قول داد که تولستوی را بی‌قیدوشرط دوست داشته باشد ؛ \n",
            "او قول داد که تولستوی را بی قیدوشرط دوست داشته باشد؛\n",
            "\n",
            "زیرا زندگی بدونِ او برایش دشوار است . \n",
            " زیرا زندگی بدون او برایش دشوار است.\n",
            "\n",
            "برای تولستوی این زندگی آزادانه‌یِ کوتاه‌بود . \n",
            "برای تولستوی این زندگی آزادانه کوتاه بود. \n",
            "\n",
            "به زودی روزنامه‌ها مقالاتی درباره‌یِ فرارِ تولستوی از دستِ همسرش نوشتند . \n",
            "به زودی روزنامه ها مقالاتی دربارۀ فرار تولستوی از دست همسرش نوشتند. \n",
            "\n",
            "قطار در هر جا که می‌ایستاد ، طرفداران ، گزارشگران و مردم کنجکاو دورِ او را می‌گرفتند . \n",
            "قطار در هر جا که می ایستاد، طرفداران، گزارشگران و مردم کنجکاو دور او را می گرفتند. \n",
            "\n",
            "او به زودی به حدِ مرگِ بیمار شد و ناچار به کلبه‌ای نزدیکِ خطوطِ راهِ آهن در روستایی دورافتاده منتقل شد . \n",
            "او به زودی به حد مرگ بیمار شد و ناچار به کلبه ای نزدیک خطوط راه آهن در روستایی دورافتاده منتقل شد. \n",
            "\n",
            "وضعیتِ او نشان از مرگ داشت . \n",
            "وضعیت او نشان از مرگ داشت. \n",
            "\n",
            "او شنید که سونیا به شهر رسیده است ، اما حتی فکرِ دیدنِ او نیز برایش غیرقابلِ تحمل‌بود . \n",
            "او شنید که سونیا به شهر رسیده است، اما حتی فکر دیدن او نیز برایش غیرقابل تحمل بود. \n",
            "\n",
            "خانواده‌یِ سونیا را بیرون از کلبه نگه داشتند و او فقط از پنجره‌یِ شیشه‌ایِ یواشکی تولستوی را می‌دید . \n",
            "خانواده سونیا را بیرون از کلبه نگه داشتند و او فقط از پنجرۀ شیشه ای یواشکی تولستوی را می دید. \n",
            "\n",
            "وقتی سرانجام تولستوی بیهوش شد ، او اجازه‌یِ ورود یافت . \n",
            "وقتی سرانجام تولستوی بیهوش شد، او اجازۀ ورود یافت. \n",
            "\n",
            "سونیا نزدیکِ تولستوی زانو زد ، مدام به پیشانیِ او بوسه زد و در گوشش زمزمه کرد : \n",
            "سونیا نزدیک تولستوی زانو زد، مدام به پیشانی او بوسه  زد و در گوشش زمزمه کرد: \n",
            "\n",
            "« مرا ببخش . \n",
            "«مرا ببخش. \n",
            "\n",
            "لطفا مرا ببخش . » تولستوی مدتِ کوتاهی پس از آن فوت کرد . \n",
            "لطفاً مرا ببخش.» تولستوی مدت کوتاهی پس از آن فوت کرد. \n",
            "\n",
            "یک ماه بعد ، فردی که از خانه‌یِ تولستوی بازدید کرده‌بود ، این کلمات را از سونیا شنید و نقل کرد : \n",
            "یک ماه بعد، فردی که از خانۀ تولستوی بازدید کرده بود، این کلمات را از سونیا شنید و نقل کرد: \n",
            "\n",
            "« بر سرِ من چه آمد ؟ این چه بلایی‌بود ؟ چطور توانستم این کار را انجام دهم ؟ می‌دانی من او را کشتم . » \n",
            "«بر سر من چه آمد؟ این چه بلایی بود؟ چطور توانستم این کار را انجام دهم؟ می دانی من او را کُشتم.»\n",
            "\n",
            "تفسیر : \n",
            "تفسیر: \n",
            "\n",
            "لئو تولستوی تمامِ نشانه‌هایِ خودشیفتگیِ عمیق را داشت . \n",
            "لئو تولستوی تمام نشانه های خودشیفتگی عمیق را داشت. \n",
            "\n",
            "وقتی دو سالش‌بود ، مادرش را از دست داد و همین مسئله حفره‌ای عمیق در دلش باز کرد و به رغمِ تلاش‌هایِ فراوانش هرگز جایش پر نشد . \n",
            "وقتی دو سالش بود، مادرش را از دست داد و همین مسئله حفره ای عمیق در دلش باز کرد و به رغم تلاش های فراوانش هرگز جایش پر نشد. \n",
            "\n",
            "او در جوانی بی‌پروا‌بود ، گویی این طرزِ رفتار به او حسِ زنده بودن و تکامل می‌بخشید . \n",
            "او در جوانی بی پروا بود، گویی این طرز رفتار به او حس زنده بودن و تکامل می بخشید. \n",
            "\n",
            "او همواره از خودش بیزار‌بود و نمی‌توانست هویتِ واقعیِ خود را بیابد . \n",
            "او همواره از خودش بیزار بود و نمی توانست هویت واقعی خود را بیابد. \n",
            "\n",
            "او این تردید و ناامنی را در رمان‌هایش منعکس کرد و برای شخصیت‌هایی که خلق می‌کرد ، نقش‌هایِ مختلفی قائل می‌شد . \n",
            "او این تردید و ناامنی را در رمان هایش منعکس کرد و برای شخصیت هایی که خلق می کرد، نقش های مختلفی قائل می شد. \n",
            "\n",
            "در پنجاه سالگی نیز سرانجام به خاطرِ همین ازهم پاشیدگیِ هویتی دچارِ بحرانیِ عمیق شد . \n",
            "در پنجاه سالگی نیز سرانجام به خاطر همین ازهم پاشیدگی هویتی دچار بحرانی عمیق شد. \n",
            "\n",
            "سونیا نیز از نظرِ درخودفرورفتگی درجه‌یِ بالایی داشت . \n",
            "سونیا نیز از نظر درخودفرورفتگی درجۀ بالایی داشت. \n",
            "\n",
            "اما ما عادت داریم وقتی دیگران را در نظر می‌گیریم ، بر ویژگی‌هایِ فردیِ آن‌ها متمرکز شویم ، تصویرِ پیچیده‌یِ تری درباره‌یِ اینکه هر طرف در یک رابطه‌یِ چگونه فرد مقابل را شکل می‌دهد ، نادیده بگیریم . \n",
            "اما ما عادت داریم وقتی دیگران را در نظر می گیریم، بر ویژگی های فردی آن ها متمرکز شویم، تصویر پیچیده تری دربارۀ اینکه هر طرف در یک رابطه چگونه فرد مقابل را شکل می دهد، نادیده بگیریم. \n",
            "\n",
            "یک رابطه نیز به خودیِ خود می‌تواند خودشیفته باشد و گرایش‌هایِ خودخواهانه دو طرف را برجسته‌یِ تر کند یا حتی بیرون بکشد . \n",
            "یک رابطه نیز به خودی خود می تواند خودشیفته باشد و گرایش های خودخواهانۀ دو طرف را برجسته تر کند یا حتی بیرون بکشد.\n",
            "\n",
            "به‌طورِ معمول آنچه یک رابطه را خودشیفته می‌کند ، فقدان یا کمبودِ همدلی است که موجب می‌شود دو طرفِ عمیقِ تر از قبل واردِ جبهه‌یِ تدافعی شوند . \n",
            "به طور معمول آنچه یک رابطه را خودشیفته می کند، فقدان یا کمبود همدلی است که موجب می شود دو طرف عمیق تر از قبل وارد جبهۀ تدافعی شوند. \n",
            "\n",
            "در موردِ تولستوی و همسرش این موضوع با خواندنِ دفترچه‌یِ یادداشت آغاز شد . \n",
            "در مورد تولستوی  و همسرش این موضوع با خواندن دفترچۀ یادداشت آغاز شد. \n",
            "\n",
            "هر طرف ارزش‌هایِ متفاوتی داشت که از طریقِ آن به دیگری نگاه می‌کرد . \n",
            "هر طرف ارزش های متفاوتی داشت که از طریق آن به دیگری نگاه می کرد. \n",
            "\n",
            "برای سونیا که در ذهنیتِ خانه‌داری بزرگ شده‌بود ، این کار نشان از پشیمان شدنِ تولستوی از خواستگاری کردنش داشت ؛ \n",
            "برای سونیا که در ذهنیت خانه داری بزرگ شده بود، این کار نشان از پشیمان شدن تولستوی از خواستگاری کردنش داشت؛\n",
            "\n",
            "برای تولستوی که هنرمندی سنتِ شکن‌بود ، واکنشِ سونیا به این معنا‌بود که نمی‌تواند روحیاتِ تولستوی را بفهمد و عشقِ او به شروعِ زندگیِ جدید را درک کند . \n",
            " برای تولستوی که هنرمندی سنت شکن بود، واکنش سونیا به این معنا بود که نمی تواند روحیات تولستوی را بفهمد و عشق او به شروع زندگی جدید را درک کند. \n",
            "\n",
            "آن‌ها با سوئبرداشت از یکدیگر به مواضعی سخت پناه بردند که چهل وهشت سال طول کشید . \n",
            "آن ها با سوءبرداشت از یکدیگر به مواضعی سخت پناه بردند که چهل وهشت سال طول کشید.\n",
            "\n",
            "بحرانِ روحیِ تولستوی همین پویاییِ خودشیفتگی را مجسم می‌کند . \n",
            "بحران روحی تولستوی همین پویایی خودشیفتگی را مجسم می کند. \n",
            "\n",
            "‌ای کاش در همان لحظه آن‌ها یکدیگر را درک و تلاش می‌کردند این رفتارها را از دیدِ طرفِ مقابل ببینند . \n",
            "ای کاش در همان لحظه آن ها یکدیگر را درک و تلاش می کردند این رفتارها را از دید طرف مقابل ببینند. \n",
            "\n",
            "تولستوی می‌توانست به روشنی واکنشِ سونیا را پیش‌بینی کند . \n",
            "تولستوی می توانست به روشنی واکنش سونیا را پیش بینی کند. \n",
            "\n",
            "سونیا در رفاهی نسبی زندگی کرده‌بود و همین رفاه دورانِ مجردی به او کمک کرد که بارداری‌ها و پرورشِ آن همه فرزند را به خوبی مدیریت کند . \n",
            "سونیا در رفاهی نسبی زندگی کرده بود و همین رفاه دوران مجردی به او کمک کرد که بارداری ها و پرورش آن همه فرزند را به خوبی مدیریت کند. \n",
            "\n",
            "او هرگز معنویت و عرفانِ عمیقی نداشت . \n",
            "او هرگز معنویت و عرفان عمیقی نداشت. \n",
            "\n",
            "ارتباط و پیوندِ آن‌ها همیشه بیشتر از اینکهِ روحی باشد ، فیزیکی و جسمی‌بود . \n",
            "ارتباط و پیوند آن ها همیشه بیشتر از اینکه روحی باشد، فیزیکی و جسمی بود. \n",
            "\n",
            "چطور تولستوی انتظار داشت به ناگاه تغییر کند ؟ درخواست‌هایِ تولستوی بیشتر سادیستی‌بود . \n",
            "چطور تولستوی انتظار داشت به ناگاه تغییر کند؟ درخواست های تولستوی بیشتر سادیستی بود. \n",
            "\n",
            "او می‌توانست به سادگی بدونِ درخواست از سونیا خواسته‌یِ خودش را بیان کند و حتی بگوید که موقعیت و نیازهایِ سونیا را درک می‌کند . \n",
            "او می توانست به سادگی بدون درخواست از سونیا خواستۀ خودش را بیان کند و حتی بگوید که موقعیت و نیازهای سونیا را درک می کند. \n",
            "\n",
            "در این صورت سونیا به خودیِ خود به معنویت و عرفانِ درونیِ تولستوی پی می‌برد و سونیا به جایِ مقاومت و تمرکز بر خواسته‌هایِ خودش ، مردی را می‌دید که از خودِ فعلیِ اش ناراضی است و بحرانِ شخصیِ سختی را تجربه می‌کند . \n",
            "در این صورت سونیا به خودی خود به معنویت و عرفان درونی تولستوی پی می برد و سونیا به جای مقاومت و تمرکز بر خواسته های خودش، مردی را می دید که از خود فعلی اش ناراضی است و بحران شخصی سختی را تجربه می کند. \n",
            "\n",
            "آن وقت به احتمالِ زیاد سونیا عشق و حمایتِ خود را نثارش می‌کرد و بدونِ آنکه از تولستوی تبعیت کند ، در این زندگیِ جدید او را آرام می‌کرد . \n",
            "آن وقت به احتمال زیاد سونیا عشق و حمایت خود را نثارش می کرد و بدون آنکه از تولستوی تبعیت کند، در این زندگی جدید او را آرام می کرد.\n",
            "\n",
            "چنین استفاده‌ای از همدلی بر خودشیفتگیِ دوسویه تاثیری متضاد دارد . \n",
            "چنین استفاده ای از همدلی بر خودشیفتگی دوسویه تأثیری متضاد دارد. \n",
            "\n",
            "به این معنا که همدلی از سویِ یک طرف آغاز و موجبِ نرم شدنِ دلِ طرفِ دیگر می‌شود و او را به همدلی کردن دعوت می‌کند . \n",
            "به این معنا که همدلی از سوی یک طرف آغاز و موجب نرم شدن دل طرف دیگر می شود و او را به همدلی کردن دعوت می کند. \n",
            "\n",
            "وقتی طرفِ مقابل به درونِ شما رخنه می‌کند و به خوبی روحیاتِ شما را می‌بیند و درک می‌کند ، دیگر برایتان دشوار است که در موقعیتِ تدافعی بمانید و به سویِ همدلیِ متقابل سوق داده می‌شوید . \n",
            "وقتی طرف مقابل به درون شما رخنه می کند و به خوبی روحیات شما را می بیند و درک می کند، دیگر برایتان دشوار است که در موقعیت تدافعی بمانید و به سوی همدلی متقابل سوق داده می شوید. \n",
            "\n",
            "ماندن در موقعیتِ تدافعی و بدگمانی برای مدتِ طولانی بسیار دشوار است . \n",
            "ماندن در موقعیت تدافعی و بدگمانی برای مدت طولانی بسیار دشوار است.\n",
            "\n",
            "کلید به کارگیریِ همدلیِ درونِ یک رابطه این است که سیستمِ ارزشیِ فردِ دیگر را درک کنید ، زیرا این سیستم قطعا با نظامِ ارزشیِ شما متفاوت است . \n",
            "کلید به کارگیری همدلی درون یک رابطه این است که سیستم ارزشی فرد دیگر را درک کنید، زیرا این سیستم قطعاً با نظام ارزشی شما متفاوت است. \n",
            "\n",
            "آنچه آن‌ها از عشق ، توجه یا سخاوت برداشت می‌کنند با برداشتِ شما متفاوت است . \n",
            "آنچه آن ها از عشق، توجه یا سخاوت برداشت می کنند با برداشت شما متفاوت است. \n",
            "\n",
            "این سیستم‌هایِ ارزشی به‌طورِ معمول در سنینِ کودکی تشکیل می‌شوند و افراد آگاهانهِ آن‌ها را خلق نمی‌کنند . \n",
            "این سیستم های ارزشی به طور معمول در سنین کودکی تشکیل می شوند و افراد آگاهانه آن ها را خلق نمی کنند. \n",
            "\n",
            "به خاطر داشته باشید که این نظامِ ارزشی به شما اجازه می‌دهد در همان لحظه که تمایل دارید دیواره‌یِ دفاعی بکشید ، واردِ روح و دیدگاهِ آن‌ها شوید . \n",
            "به خاطر داشته باشید که این نظام ارزشی به شما اجازه می دهد در همان لحظه که تمایل دارید دیوارۀ دفاعی بکشید، وارد روح و دیدگاه آن ها شوید. \n",
            "\n",
            "حتی افراد عمیقا خودشیفته می‌توانند به همین شیوه از پوسته‌یِ خود بیرون آیند ، زیرا چنین توجهی بسیار نادر است . \n",
            "حتی افراد عمیقاً خودشیفته می توانند به همین شیوه از پوستۀ خود بیرون آیند، زیرا چنین توجهی بسیار نادر است. \n",
            "\n",
            "همواره تمامِ روابطِ خود را بر اساسِ این طیف خودشیفتگی بسنجید . \n",
            "همواره تمام روابط خود را بر اساس این طیف خودشیفتگی بسنجید. \n"
          ]
        }
      ],
      "source": [
        "f = open('sample_text.txt', 'r')\n",
        "for line in f:\n",
        "  print(add_kasre(line))\n",
        "  print(line)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qBQmON8W-cn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KxLf3sfCSl6Q",
        "outputId": "fb492f0c-d770-4a9d-c565-9fb45dc4d62d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'انگار قرار است تا دم مرگ با هم مجادله داشته باشیم !  او کتاب سونات کرویتسر را از دل همین تلخی های زندگی اش نوشت'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent = 'انگار قرار است تا دم مرگ با هم مجادله داشته باشیم! او کتاب سونات کرویتسر را از دل همین تلخی های زندگی اش نوشت'\n",
        "punctuations = r')(}{:؟!،؛»«.' + r\"/<>?.,:;\"\n",
        "punctuations = '[' + punctuations + string.punctuation + ']'\n",
        "sent = re.sub(punctuations, lambda x: ' ' + x.group() + ' ', sent)\n",
        "sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dzuAbw2ZTa46",
        "outputId": "a6081f52-3c55-4fe9-c086-0e434ab5c418"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\\\)\\\\(}{:؟،؛»«\\\\./<>?.,:;!'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAjC6zXs7UtL"
      },
      "outputs": [],
      "source": [
        "doc = nlp_pos('انگار قرار است تا دم مرگ با هم مجادله داشته باشیم.» او کتاب سونات کرویتسر را از دل همین تلخی های زندگی اش نوشت')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkRzBM6wHu3Y",
        "outputId": "43f14fcb-333b-4d52-9bc9-bc242f128d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "انگار PSUS\n",
            "قرار N_IANM\n",
            "است AUX\n",
            "تا PREP\n",
            "دم N_IANM\n",
            "مرگ N_IANM\n",
            "با PREP\n",
            "هم PR_RECPR\n",
            "مجادله N_IANM\n",
            "داشته V_ACT\n",
            "باشیم AUX\n",
            ". PUNC\n",
            "» PUNC\n",
            "او PR_SEPER\n",
            "کتاب N_IANM\n",
            "سونات N_IANM\n",
            "کرویتسر N_IANM\n",
            "را POSTP\n",
            "از PREP\n",
            "دل N_IANM\n",
            "همین PREM_DEMAJ\n",
            "تلخی N_IANM\n",
            "های N_IANM\n",
            "زندگی N_IANM\n",
            "اش PR_JOPER\n",
            "نوشت V_ACT\n"
          ]
        }
      ],
      "source": [
        "pos = list()\n",
        "for i in range(len(doc.sentences)):\n",
        "  for j in range(len(doc.sentences[i].tokens)):\n",
        "    text = doc.sentences[i].tokens[j].words[0].text\n",
        "    xpos = doc.sentences[i].tokens[j].words[0].xpos\n",
        "    print(text, xpos)\n",
        "    pos.append((text, xpos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_ODrcTNBs_v"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ezafe_blstm_pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMP+EixxL1CM1mX2827Dijz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7cac6af573e46f9a4afefd9046c727f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca7ceca9a763413bac5ad850f5f04197",
              "IPY_MODEL_e5667e30e15047aeb8300116c97798a7",
              "IPY_MODEL_2b4f18679e814d5180085a59ac0430d7"
            ],
            "layout": "IPY_MODEL_ef1452346508471ab3a723b03b1aee42"
          }
        },
        "ca7ceca9a763413bac5ad850f5f04197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31de5f4e0d45493e8217b9aa16cf5735",
            "placeholder": "​",
            "style": "IPY_MODEL_4dfe13073a83445980de88613a2177b6",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
          }
        },
        "e5667e30e15047aeb8300116c97798a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a8aa4684374ccc9f6f6bdd64443ea4",
            "max": 24459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b6544ea9d5e4bb3853ad2a8739a64b1",
            "value": 24459
          }
        },
        "2b4f18679e814d5180085a59ac0430d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a8db1c48304883904ff847950e5fc0",
            "placeholder": "​",
            "style": "IPY_MODEL_c107bdf56d8a444ca0d274e56bda7381",
            "value": " 142k/? [00:00&lt;00:00, 4.35MB/s]"
          }
        },
        "ef1452346508471ab3a723b03b1aee42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31de5f4e0d45493e8217b9aa16cf5735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfe13073a83445980de88613a2177b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a8aa4684374ccc9f6f6bdd64443ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6544ea9d5e4bb3853ad2a8739a64b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8a8db1c48304883904ff847950e5fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c107bdf56d8a444ca0d274e56bda7381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a7a96f223574bdbaecbdaad16873c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a4682d2da1c451cbec8f0eb89ebfd95",
              "IPY_MODEL_c7ac1fa504c6402c916f59f9692354ff",
              "IPY_MODEL_3220e57ef014462d89988bd775e77bd3"
            ],
            "layout": "IPY_MODEL_a14ad23ef4c2420993f7b43210dacdc9"
          }
        },
        "3a4682d2da1c451cbec8f0eb89ebfd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fe898a2e8a4ad6b98c43c4fbf43f06",
            "placeholder": "​",
            "style": "IPY_MODEL_d1cb05a876d34f6d858927fd8648a45a",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.3.0/models/default.zip: 100%"
          }
        },
        "c7ac1fa504c6402c916f59f9692354ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9c9d6b7e284b5b84a54ab6258f2bf7",
            "max": 210965214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57c03e699890440d86da8f56718f3410",
            "value": 210965214
          }
        },
        "3220e57ef014462d89988bd775e77bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db50f85af09445d7ac7099acf6c1df3f",
            "placeholder": "​",
            "style": "IPY_MODEL_2e84247a37024f7d8b268880a9d1f3b0",
            "value": " 211M/211M [00:01&lt;00:00, 129MB/s]"
          }
        },
        "a14ad23ef4c2420993f7b43210dacdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2fe898a2e8a4ad6b98c43c4fbf43f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1cb05a876d34f6d858927fd8648a45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e9c9d6b7e284b5b84a54ab6258f2bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c03e699890440d86da8f56718f3410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db50f85af09445d7ac7099acf6c1df3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e84247a37024f7d8b268880a9d1f3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}