{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ezafe_blstm_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLHVh8x2+6uMje3G4Bezte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1d7b36c245548f49c9e0911a938de82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df738b2e52264f01840b6a02262828b9",
              "IPY_MODEL_73228fa008f248ecbae985d422f1c440",
              "IPY_MODEL_56d0b9a5bbe24437a26c52350c8cd488"
            ],
            "layout": "IPY_MODEL_cb750fdcf4634b5e83b0b7fb9d623a26"
          }
        },
        "df738b2e52264f01840b6a02262828b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff32ea16d064aa7b61a677fdc35b972",
            "placeholder": "​",
            "style": "IPY_MODEL_4710444771c74f63a129713929237066",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
          }
        },
        "73228fa008f248ecbae985d422f1c440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f0b7a183934bcb9b249d7c144d65a2",
            "max": 24459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3837e205f090494f816b3fbd6a546699",
            "value": 24459
          }
        },
        "56d0b9a5bbe24437a26c52350c8cd488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1f6e4e5fc2b4b909531452555e9995e",
            "placeholder": "​",
            "style": "IPY_MODEL_a9b1b5ed07734af1b14db4d370433209",
            "value": " 142k/? [00:00&lt;00:00, 3.77MB/s]"
          }
        },
        "cb750fdcf4634b5e83b0b7fb9d623a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff32ea16d064aa7b61a677fdc35b972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4710444771c74f63a129713929237066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f0b7a183934bcb9b249d7c144d65a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3837e205f090494f816b3fbd6a546699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1f6e4e5fc2b4b909531452555e9995e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b1b5ed07734af1b14db4d370433209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiEsrafili/pert/blob/master/ezafe_blstm_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk2oqX4CHbHt",
        "outputId": "58647cd2-c16c-4c2a-c9e2-e7c78bb0c6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnebXvZ2HiRB",
        "outputId": "4d674d6a-7e6b-4928-94e8-a4ebfbf4a743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 307 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 358 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 368 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 430 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 432 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.5)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=ef8cf517999970f4c7230cf77061f42e2e6a55efd7e444d611c587681fdfd0aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.download('fa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "a1d7b36c245548f49c9e0911a938de82",
            "df738b2e52264f01840b6a02262828b9",
            "73228fa008f248ecbae985d422f1c440",
            "56d0b9a5bbe24437a26c52350c8cd488",
            "cb750fdcf4634b5e83b0b7fb9d623a26",
            "7ff32ea16d064aa7b61a677fdc35b972",
            "4710444771c74f63a129713929237066",
            "52f0b7a183934bcb9b249d7c144d65a2",
            "3837e205f090494f816b3fbd6a546699",
            "e1f6e4e5fc2b4b909531452555e9995e",
            "a9b1b5ed07734af1b14db4d370433209"
          ]
        },
        "id": "K67Qbr_4Hs3b",
        "outputId": "ba3b5adc-38f6-46fc-b742-d90bdc3983b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1d7b36c245548f49c9e0911a938de82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-16 07:55:09 INFO: Downloading default packages for language: fa (Persian)...\n",
            "2022-04-16 07:55:10 INFO: File exists: /root/stanza_resources/fa/default.zip.\n",
            "2022-04-16 07:55:12 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY9qy_5sIAw_",
        "outputId": "3dec791b-5e75-4797-c4b6-349cb02760b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-16 07:55:12 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-16 07:55:12 INFO: Use device: gpu\n",
            "2022-04-16 07:55:12 INFO: Loading: tokenize\n",
            "2022-04-16 07:55:21 INFO: Loading: mwt\n",
            "2022-04-16 07:55:21 INFO: Loading: pos\n",
            "2022-04-16 07:55:21 INFO: Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "% cd fastText\n",
        "!  pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EloiwuwfIB7P",
        "outputId": "378b6830-5ef9-4b1f-8b85-3a6a8d6f7fe0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3930, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 3930 (delta 28), reused 42 (delta 11), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3930/3930), 8.33 MiB | 38.27 MiB/s, done.\n",
            "Resolving deltas: 100% (2445/2445), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3139533 sha256=98cc7ca5d1af18910d7b21d5387950286ea748c6c5a497c0ee1f807e09b06f4c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9rxqqt_f/wheels/22/04/6e/b3aba25c1a5845898b5871a0df37c2126cb0cc9326ad0c08e7\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd fastText\n",
        "!./download_model.py fa\n",
        "% cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fw2SkiaID03",
        "outputId": "91fd7afe-094e-4a2d-94e5-11b3a8ca032d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastText\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            " (100.00%) [==================================================>]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "1GvRlOd7IFwn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this or below cell\n",
        "!cp drive/MyDrive/دیتاست\\ بیجن\\ خان/test_clean.tsv data/test_clean.tsv"
      ],
      "metadata": {
        "id": "rtOY4RPkOrtr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/test_data.zip -d data\n",
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/train_data.zip -d data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPeQzq74III-",
        "outputId": "7ca4bde5-57d3-4961-f7d1-3e3029742648"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/دیتاست بیجن خان/test_data.zip\n",
            "  inflating: data/test_data.txt      \n",
            "Archive:  drive/MyDrive/دیتاست بیجن خان/train_data.zip\n",
            "  inflating: data/train_data.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IByGIyi0IMLm",
        "outputId": "e9432e46-88ab-4bfc-a041-c14c01567417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-16 07:55:21 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-16 07:55:21 INFO: Use device: gpu\n",
            "2022-04-16 07:55:21 INFO: Loading: tokenize\n",
            "2022-04-16 07:55:21 INFO: Loading: mwt\n",
            "2022-04-16 07:55:21 INFO: Loading: pos\n",
            "2022-04-16 07:55:21 INFO: Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pos_tager(text):\n",
        "  doc = nlp_pos(text)\n",
        "  pos = [word.xpos for sent in doc.sentences for word in sent.words if word.text not in ['ش','شان','م', 'مان', 'ند','ست','یت', 'تان', 'ت','اش']]\n",
        "  # pos_ = [(word.text , word.upos, word.xpos) for sent in doc.sentences for word in sent.words ]\n",
        "  # print(pos_)\n",
        "  return pos"
      ],
      "metadata": {
        "id": "TGxCnhOfIO4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "r8ZQFOE_IP13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_consist(pos_tag, kasre_tag, sent):\n",
        "  l1 = len(pos_tag)\n",
        "  l2 = len(kasre_tag)\n",
        "  l3 = len(sent.split())\n",
        "  if l1!=l2:\n",
        "    return False\n",
        "  if l1!=l3:\n",
        "    return False\n",
        "  if l3!=l2:\n",
        "    return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "I70JzE8PIUg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/test_data.txt', encoding='utf-8') as f:\n",
        "    data = f.readlines()\n",
        "sents = list()\n",
        "kasre_tags = list()\n",
        "temp_sent = ''\n",
        "temp_tags = list()\n",
        "pos_tags = list()\n",
        "for i, line in tqdm(enumerate(data)):\n",
        "    # if i>10000: break\n",
        "    try:\n",
        "        word, ez = line.split()\n",
        "        word += ' '\n",
        "        temp_sent += word\n",
        "        temp_tags.append(ez)\n",
        "        if word in ['. ', '# ']:\n",
        "            pos_tag = pos_tager(temp_sent)\n",
        "            ok = check_consist(pos_tag, temp_tags, temp_sent)\n",
        "            if ok:\n",
        "              sents.append(temp_sent) \n",
        "              kasre_tags.append(temp_tags)\n",
        "              pos_tags.append(pos_tag)\n",
        "            temp_sent = ''\n",
        "            temp_tags = list()\n",
        "    except:\n",
        "        pos_tag = pos_tager(temp_sent)\n",
        "        ok = check_consist(pos_tag, temp_tags, temp_sent)\n",
        "        if ok:\n",
        "          sents.append(temp_sent) \n",
        "          kasre_tags.append(temp_tags)\n",
        "          pos_tags.append(pos_tag)\n",
        "        temp_sent = ''\n",
        "        temp_tags = list()   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWMK6ZPIVaF",
        "outputId": "e63efa6d-5041-49cc-c9a3-20d777ff3b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "970it [00:01, 1102.52it/s]/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n",
            "1525970it [19:16, 1319.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sents), len(kasre_tags), len(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWuilPW2IYWW",
        "outputId": "079a6ea1-7181-4be3-b5f5-619f6023ea1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56132, 56132, 56132)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raws = list()\n",
        "\n",
        "for i in range(len(pos_tags)):\n",
        "  for j in range(len(pos_tags[i])):\n",
        "    raw = f'{sents[i].split()[j]}\\t{pos_tags[i][j]}\\t{kasre_tags[i][j]}'\n",
        "    raws.append(raw)\n",
        "  raws.append('\\n')"
      ],
      "metadata": {
        "id": "IyetfYuTIdCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raws_text = '\\n'.join(raws)\n",
        "with open('data/test_clean.tsv', 'w') as f:\n",
        "  f.write(raws_text)"
      ],
      "metadata": {
        "id": "Bw0bUhwYIeTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp data/test_clean.tsv drive/MyDrive/دیتاست\\ بیجن\\ خان/"
      ],
      "metadata": {
        "id": "6uJsLaiROct1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this or bellow cell\n",
        "!cp drive/MyDrive/fastText/cc.fa.300.vec fastText/"
      ],
      "metadata": {
        "id": "q-mzML_PRHLU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fasttext import load_model\n",
        "\n",
        "# original BIN model loading\n",
        "f = load_model('fastText/cc.fa.300.bin')\n",
        "lines=[]\n",
        "\n",
        "# get all words from model\n",
        "words = f.get_words()\n",
        "\n",
        "with open('fastText/cc.fa.300.vec','w') as file_out:\n",
        "    \n",
        "    # the first line must contain number of total words and vector dimension\n",
        "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
        "\n",
        "    # line by line, you append vectors to VEC file\n",
        "    for w in words:\n",
        "        v = f.get_word_vector(w)\n",
        "        vstr = \"\"\n",
        "        for vi in v:\n",
        "            vstr += \" \" + str(vi)\n",
        "        try:\n",
        "            file_out.write(w + vstr+'\\n')\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "RqAd6MmUIgoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir drive/MyDrive/fastText\n",
        "!cp fastText/cc.fa.300.vec drive/MyDrive/fastText/"
      ],
      "metadata": {
        "id": "yx-MVhUoQ8dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "metadata": {
        "id": "s8AtfVYDtgrw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RUN = 20"
      ],
      "metadata": {
        "id": "Yi3Sdd_lsvMy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        # directories\n",
        "        self.train_data_dir = 'data/train_data.txt'\n",
        "        self.model_dir = 'models'\n",
        "        self.we_model_dir = 'fastText/cc.fa.300.vec'\n",
        "        self.we_pickled_model_dir = 'fastText/cc.fa.300.pickle'\n",
        "\n",
        "        # general\n",
        "        self.data_split = .1\n",
        "        self.num_epochs = 25\n",
        "        self.batch_size = 16\n",
        "        self.shuffle_buffer = 320000\n",
        "        self.num_tags = 6\n",
        "        self.num_pos_tags = 33\n",
        "        self.word_max_len = 30\n",
        "        self.learning_rate = 1e-3\n",
        "        self.max_len = 100\n",
        "\n",
        "        # embeddings\n",
        "        self.num_words = 100000\n",
        "        self.word_embed_dim = 300\n",
        "        self.num_chars = 256  # number of most frequent characters to be kept\n",
        "        self.char_embed_dim = 32\n",
        "        self.pos_embed_dim = 16\n",
        "\n",
        "        # lstm variables\n",
        "        self.lstm_units = 256  # number of hidden units in the RNN\n",
        "        self.dropout = .5  # keeping probability"
      ],
      "metadata": {
        "id": "J3PlM7ZmJq1N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "WcnAZYHytnKr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "class KasreDSNew(Dataset):\n",
        "    def __init__(self, cfg):\n",
        "        # loading word embedding model\n",
        "        try:\n",
        "            handle = open(cfg.we_pickled_model_dir, 'rb') \n",
        "            self.word_embedding_model = pickle.load(handle)\n",
        "        except FileNotFoundError:\n",
        "            self.word_embedding_model = KeyedVectors.load_word2vec_format(cfg.we_model_dir, binary=False)\n",
        "            with open(cfg.we_pickled_model_dir, 'wb') as handle:\n",
        "                pickle.dump(self.word_embedding_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        self.max_len = cfg.max_len\n",
        "        sents, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "        print(len(sents))\n",
        "        sents_shuf = []\n",
        "        all_ezafe_tags_shuf = []\n",
        "        index_shuf = list(range(len(sents)))\n",
        "\n",
        "        for i in index_shuf:\n",
        "            sents_shuf.append(sents[i])\n",
        "            all_ezafe_tags_shuf.append(all_ezafe_tags[i])\n",
        "\n",
        "        random.seed(17)\n",
        "        random.shuffle(index_shuf)\n",
        "        \n",
        "        self.sents_shuf = sents_shuf\n",
        "        print('data:', len(self.sents_shuf[0]))\n",
        "        self.data = sents_shuf\n",
        "        sents, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "        self.sents = sents\n",
        "        self.all_ezafe_tags = all_ezafe_tags\n",
        "        \n",
        "        try:\n",
        "              with open('indices.pickle', 'rb')  as handle:\n",
        "                self.char_to_index, self.word_to_index,  self.ezafe_tag_to_index = pickle.load(handle)\n",
        "                self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "                self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "          \n",
        "              \n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print('Building vocabulary...')\n",
        "\n",
        "            vocab_list = []\n",
        "            char_list = []\n",
        "            for sent in self.data:\n",
        "                for word in sent:\n",
        "                    vocab_list.append(word)\n",
        "                    for char in word:\n",
        "                        char_list.append(char)\n",
        "            \n",
        "            most_common_words = Counter(vocab_list).most_common(cfg.num_words)\n",
        "            most_common_chars = Counter(char_list).most_common(cfg.num_chars)\n",
        "            \n",
        "            self.word_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0)] + most_common_words):\n",
        "                self.word_to_index[pair[0]] = i + 1\n",
        "\n",
        "            self.char_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0), ('<UNK>', 1)] + most_common_chars):\n",
        "                self.char_to_index[pair[0]] = i + 1\n",
        "            \n",
        "            self.ezafe_tag_to_index = {'O': 0, 'e': 1,'ye': 2, 've':3, 'y':4, '@e':5}\n",
        "\n",
        "            self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "            self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "\n",
        "            # saving the tokenizers\n",
        "            with open('indices.pickle', 'wb') as handle:\n",
        "                indices = self.char_to_index, self.word_to_index, self.ezafe_tag_to_index\n",
        "                pickle.dump(indices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "    def _data_reader(self, directory):\n",
        "        sents, sent = [], []\n",
        "        all_ezafe_tags, ezafe_tags = [], []\n",
        "        with open(directory) as bijankhan_corpus:\n",
        "            for line in bijankhan_corpus:\n",
        "                try:\n",
        "                    if line not in ['.\\tO\\n', '#\\tO\\n']:\n",
        "                        word, ezafe_tag = line.strip().split('\\t')\n",
        "                        sent.append(word.replace('ي', 'ی').replace('ك', 'ک').replace('ة', 'ه'))\n",
        "                        ezafe_tags.append(ezafe_tag)\n",
        "                    else:\n",
        "                        word, ezafe_tag = line.strip().split('\\t')\n",
        "                        sent.append(word)\n",
        "                        ezafe_tags.append(ezafe_tag)\n",
        "                        if len(sent)>1:\n",
        "                          if len(sent)<self.max_len :\n",
        "                            all_ezafe_tags.append(ezafe_tags)\n",
        "                            sents.append(sent)\n",
        "                        sent = []\n",
        "                        ezafe_tags = []\n",
        "                except Exception as e:\n",
        "                  sent = []\n",
        "                  ezafe_tags = []\n",
        "        print(f'data reader {len(sents)}')\n",
        "        return sents, all_ezafe_tags\n",
        "\t\n",
        "\n",
        "    def _pad(self, word):\n",
        "        for _ in range(cfg.word_max_len - len(word)):\n",
        "            word.append(0)\n",
        "        return word\n",
        "    \n",
        "\n",
        "    def _sent_to_index(self, sentence, mode='word'):\n",
        "        if mode is 'word':\n",
        "            return [self.word_to_index.get(word, 1) for word in sentence]\n",
        "        elif mode is 'char':\n",
        "            indexed_sentence = []\n",
        "            for word in sentence:\n",
        "                indexed_word = []\n",
        "                for char in word:\n",
        "                    indexed_word.append(self.char_to_index.get(word, 1))\n",
        "                indexed_sentence.append(self._pad(indexed_word))\n",
        "            return indexed_sentence\n",
        "\n",
        "\n",
        "    def _sent_to_embed(self, sentence):\n",
        "        embed_sent = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                embed_sent.append(self.word_embedding_model[word])\n",
        "            except KeyError:\n",
        "                embed_sent.append([0 for _ in range(cfg.word_embed_dim)])\n",
        "        return embed_sent\n",
        "    \n",
        "    def _ezafe_tags_to_index(self, tags):\n",
        "        return [self.ezafe_tag_to_index[tag] for tag in tags]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        char = True\n",
        "        sent, ezafe_tag = self.sents[idx], self.all_ezafe_tags[idx]\n",
        "        sent_char = self._sent_to_index(sent, mode='char')\n",
        "        sent_word = self._sent_to_embed(sent)\n",
        "        length = [1 for _ in range(len(sent))]\n",
        "        tag = self._ezafe_tags_to_index(ezafe_tag)\n",
        "        \n",
        "        # if char:\n",
        "        #     return (np.array(sent_word), np.array(sent_char), np.array(length)), np.array(tag)\n",
        "        return torch.tensor(sent_word), torch.tensor(tag)\n"
      ],
      "metadata": {
        "id": "5C3SVZoupGKd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kasre_ds = KasreDSNew(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi0XojytXK2z",
        "outputId": "279623b8-81aa-4458-9129-a2752af85fc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data reader 271410\n",
            "271410\n",
            "data: 23\n",
            "data reader 271410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(kasre_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxrv2eqDg4ME",
        "outputId": "e7416f66-eac2-4852-cb9a-2ef605d6d3c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "271410"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "IVPYR9ujIwqk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "et = [e for t in kasre_ds.all_ezafe_tags for e in t]\n",
        "list(set(et))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBGknYUtfHn4",
        "outputId": "63dbe644-7d16-491b-cd8d-fdc8525177a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e', 've', 'ye', '@e', 'O', 'y']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = kasre_ds[15118]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFusz7kNeTnv",
        "outputId": "efd1ed58-e864-4d49-97b4-84968d38dd1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:168: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOrHQ0BTkk5l",
        "outputId": "7e208d3f-dbec-447f-bbb9-395f311e696a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 300]), torch.Size([100]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens = list()\n",
        "for i in range(len(kasre_ds)):\n",
        "  x, _ = kasre_ds[i]\n",
        "  lens.append(x.shape[0])\n",
        "  if x.shape[0] <1:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "ylQRnErTjH8u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDBBG4M8s6Xo",
        "outputId": "e6b9d512-6b6c-4146-f579-bdc5bd7f9f97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpYKbUbou_Xg",
        "outputId": "5c8db5f0-86c3-45f6-c914-c967a3194767"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = torch.utils.data.random_split(kasre_ds,(270410, 1000), generator=torch.Generator().manual_seed(42) )"
      ],
      "metadata": {
        "id": "M9TMY9oVkLbu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUhCr1mEsmn7",
        "outputId": "a4a4a626-ee09-4aaf-859a-55add9f03aaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, \n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    val_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "FUDmL6Ahkg51"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train': train_loader,\n",
        "               'test': test_loader,\n",
        "               'val': val_loader}"
      ],
      "metadata": {
        "id": "FDmmOi4ptcHq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KasreAdder(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.lstm = nn.LSTM(cfg.word_embed_dim, cfg.lstm_units // 2,\n",
        "                            num_layers=1, bidirectional=True, batch_first=True)\n",
        "    self.hidden2tag = nn.Linear(cfg.lstm_units, cfg.num_tags)\n",
        "    self.dropout = nn.Dropout()\n",
        "    self.hidden = self.init_hidden(1)\n",
        "\n",
        "  def init_hidden(self, shape):\n",
        "    return (torch.randn(2, 1, self.cfg.lstm_units // 2).to(device),\n",
        "            torch.randn(2, 1, self.cfg.lstm_units // 2).to(device))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # print(f'x shape {x.shape}')\n",
        "    self.hidden = self.init_hidden(x.shape[1])\n",
        "    lstm_out, self.hidden = self.lstm(x, self.hidden,)\n",
        "    # print(f'lstm_out {lstm_out.shape}')\n",
        "    # lstm_out = lstm_out.view(len(x), self.cfg.lstm_units)\n",
        "    lstm_out = self.dropout(lstm_out)\n",
        "    lstm_feats = self.hidden2tag(lstm_out[0])\n",
        "    return lstm_feats\n",
        "    "
      ],
      "metadata": {
        "id": "AYg1NIvEI0D1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KasreAdder(cfg).to(device)"
      ],
      "metadata": {
        "id": "oblrrmdmmlzq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=1e-3\n",
        "epochs = 5\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, threshold=0.05, min_lr=1e-7, verbose=True, factor=0.1)\n",
        "es_patience = 50"
      ],
      "metadata": {
        "id": "ERgU-grwsIQ0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, lr_scheduler, dataloaders, num_epochs=10):\n",
        "  model = model.train()\n",
        "  train_loss_history = list()\n",
        "  val_loss_history = list()\n",
        "  best_epoch = {'epoch':0, 'accuracy':0, 'loss':-100.0}\n",
        "  model_path = f'checkpoints/RUN_{RUN}'\n",
        "  os.mkdir(model_path)\n",
        "  for epoch in range(num_epochs):\n",
        "    model = model.train()\n",
        "    pbar = tqdm(dataloaders['train'])\n",
        "    epoch_losses = np.array([])\n",
        "    for (batch, labels) in pbar:\n",
        "      batch = batch.to(device, dtype=torch.float)\n",
        "      labels = labels.to(device, dtype=torch.long)[0]\n",
        "      optimizer.zero_grad()\n",
        "      out = model(batch)\n",
        "      # print(batch.shape)\n",
        "      # print(labels.shape)\n",
        "      # print('*************')\n",
        "      # print(out.shape)\n",
        "      loss = criterion(out, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_losses = np.append(epoch_losses, loss.item())\n",
        "      pbar.set_description(f'epoch {epoch+1}/{num_epochs},\\\n",
        "                            loss= {epoch_losses.mean():.4f}')\n",
        "    train_loss_history.append(epoch_losses.mean())\n",
        "    # lr_scheduler.step()\n",
        "\n",
        "    # validation\n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "      pbar = tqdm(dataloaders['val'])\n",
        "      val_loss = np.array([])\n",
        "      n_samples = 0\n",
        "      n_corrects = 0\n",
        "      for (batch, labels) in pbar:\n",
        "        batch = batch.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device, dtype=torch.long)[0]\n",
        "        # labels = torch.tensor([l for l in labels for _ in range(30)]).to(device, dtype=torch.long)\n",
        "        out = model(batch)\n",
        "        loss = criterion(out, labels)\n",
        "        val_loss = np.append(val_loss, loss.item())\n",
        "        out = nn.Softmax()(out)\n",
        "        out = out.argmax(1)\n",
        "        n_corrects += (out == labels).sum()\n",
        "        n_samples += out.shape[0]\n",
        "      val_acc = n_corrects/n_samples\n",
        "      val_loss = val_loss.mean()\n",
        "      val_loss_history.append(val_loss)\n",
        "      lr_scheduler.step(val_loss)\n",
        "      if val_acc > best_epoch['accuracy']:\n",
        "        best_epoch = {'epoch':epoch, 'accuracy':val_acc, 'loss':val_loss}\n",
        "        best_model_path = os.path.join(model_path, f'best_val_checkpoint.pt')\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, loss:= {val_loss.mean():.4f}, accuracy= {(n_corrects/n_samples):.4f}')\n",
        "      pbar.set_description(f'epoch {epoch+1}/{num_epochs}, loss:= {val_loss.mean():.4f}, accuracy= {(n_corrects/n_samples):.4f}')\n",
        "    if (sorted(val_loss_history[-es_patience:]) == val_loss_history[-es_patience:]) and (len(val_loss_history)>2*es_patience):\n",
        "      break\n",
        "  model.load_state_dict(torch.load(best_model_path))\n",
        "  print(best_epoch)\n",
        "  return model, train_loss_history, val_loss_history"
      ],
      "metadata": {
        "id": "Sv9MhXOjsgqy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RUN += 1\n",
        "model, loss_history, val_loss_history = train(model, optimizer, criterion, lr_scheduler, dataloaders, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pBFH833tS7D",
        "outputId": "69b76d8e-7fe3-41c8-8f57-081a82b067fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 1/5,                            loss= 0.0958: 100%|██████████| 270410/270410 [42:01<00:00, 107.22it/s]\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 1000/1000 [00:03<00:00, 280.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1/5, loss:= 0.0583, accuracy= 0.9826\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 2/5,                            loss= 0.0648: 100%|██████████| 270410/270410 [42:09<00:00, 106.90it/s]\n",
            "100%|██████████| 1000/1000 [00:03<00:00, 281.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2/5, loss:= 0.0521, accuracy= 0.9848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3/5,                            loss= 0.0585: 100%|██████████| 270410/270410 [43:22<00:00, 103.89it/s]\n",
            "100%|██████████| 1000/1000 [00:03<00:00, 291.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3/5, loss:= 0.0496, accuracy= 0.9852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4/5,                            loss= 0.0555: 100%|██████████| 270410/270410 [45:01<00:00, 100.08it/s]\n",
            "100%|██████████| 1000/1000 [00:03<00:00, 293.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4/5, loss:= 0.0480, accuracy= 0.9862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5/5,                            loss= 0.0534: 100%|██████████| 270410/270410 [45:10<00:00, 99.77it/s] \n",
            "100%|██████████| 1000/1000 [00:03<00:00, 285.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5/5, loss:= 0.0450, accuracy= 0.9869\n",
            "{'epoch': 4, 'accuracy': tensor(0.9869, device='cuda:0'), 'loss': 0.044961439092578444}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp checkpoints/RUN_22/best_val_checkpoint.pt drive/MyDrive/kasre_model.pt"
      ],
      "metadata": {
        "id": "bOxae36F5gdV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'توپ سبز رنگ'.split()\n",
        "sent_words = kasre_ds._sent_to_embed(sent)\n",
        "sent_words = torch.tensor(sent_words).to(device)\n",
        "sent_words.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCprxrkE3HGT",
        "outputId": "993263d4-78dd-4b02-bc5d-eff3d9d2d726"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out = model(sent_words.unsqueeze(0))\n"
      ],
      "metadata": {
        "id": "DCK59Dn6tjOH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3d5ANjd3zbE",
        "outputId": "1bd73f6c-0b0f-490c-f8db-2823f6cde9f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = nn.Softmax()(out)\n",
        "out = out.argmax(1)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdNeBoBH4PcX",
        "outputId": "5c76c1f1-4469-45a2-c66e-2408cd9752fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sent:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siJpFk5U4XJn",
        "outputId": "8715f49e-74a5-4dc7-b34b-0ca044d2fd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "حال\n",
            "شما\n",
            "چطور\n",
            "است\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5hv8WcjC5cg7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}