{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ezafe_blstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab44f0f498a44e5fa21a650f53106281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b444dd6539094126a47af4b128e82834",
              "IPY_MODEL_6c59d0c5744649409b8cd68c4e3b9686",
              "IPY_MODEL_56ee5f8ea0e14ea1be29df0a980b2c4a"
            ],
            "layout": "IPY_MODEL_6a62f641a42f46c489b6802056846c29"
          }
        },
        "b444dd6539094126a47af4b128e82834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4599b2e1b9439985c66f948f74c158",
            "placeholder": "​",
            "style": "IPY_MODEL_d885cfcc7339498786df3d4760c3edc5",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
          }
        },
        "6c59d0c5744649409b8cd68c4e3b9686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd885350994a4d91b34f149f391b11a1",
            "max": 24459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d68ab43a920c4d8b835d86fa9b6f6986",
            "value": 24459
          }
        },
        "56ee5f8ea0e14ea1be29df0a980b2c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4f4c59ca304fd7b269585ea82bb311",
            "placeholder": "​",
            "style": "IPY_MODEL_e429cc6844cb463fb203e6efda29473f",
            "value": " 142k/? [00:00&lt;00:00, 2.96MB/s]"
          }
        },
        "6a62f641a42f46c489b6802056846c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4599b2e1b9439985c66f948f74c158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d885cfcc7339498786df3d4760c3edc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd885350994a4d91b34f149f391b11a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68ab43a920c4d8b835d86fa9b6f6986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e4f4c59ca304fd7b269585ea82bb311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e429cc6844cb463fb203e6efda29473f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VcXqIsFR4kjb",
        "outputId": "d2d38147-2fa0-461a-8581-8670ba8cd0f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHI_vtGDuKt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb53ddb-2e2b-4d8e-f687-47eef532245d"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.15\n",
        "\n",
        "!pip install git+https://github.com/guillaumegenthial/tf_metrics.git\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.8.0\n",
            "Collecting tensorflow-gpu==1.15\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.44.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.14.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.0.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.21.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=b619fe1b432c68f6eec2cb2d803bccd54426522c7b18362225c1e50b804cce55\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Collecting git+https://github.com/guillaumegenthial/tf_metrics.git\n",
            "  Cloning https://github.com/guillaumegenthial/tf_metrics.git to /tmp/pip-req-build-a8oxalgv\n",
            "  Running command git clone -q https://github.com/guillaumegenthial/tf_metrics.git /tmp/pip-req-build-a8oxalgv\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tf-metrics==0.0.1) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-gpu>=1.6 in /usr/local/lib/python3.7/dist-packages (from tf-metrics==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.44.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.5.2)\n",
            "Building wheels for collected packages: tf-metrics\n",
            "  Building wheel for tf-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-metrics: filename=tf_metrics-0.0.1-py3-none-any.whl size=7704 sha256=eb59c5418a51f3bf2b2350aff7caa244310133216b227759f56697367e42a888\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eaivfc8b/wheels/cd/99/60/5a21f2d1b0d0ce16599235e678a1687791243b7752abfb61cd\n",
            "Successfully built tf-metrics\n",
            "Installing collected packages: tf-metrics\n",
            "Successfully installed tf-metrics-0.0.1\n",
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "l6Uf-8u27dnb",
        "outputId": "c3929622-8ae9-47a8-b127-ab5ea4163c73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 432 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.5)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=886e710a8dc34ad0189e75325a53c2c460ef196c85ceeb2ac18148b61b71ba17\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.download('fa')"
      ],
      "metadata": {
        "id": "5uiJKFFb7kgQ",
        "outputId": "36c0532b-b874-4cbf-88d7-aa72905b6055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "ab44f0f498a44e5fa21a650f53106281",
            "b444dd6539094126a47af4b128e82834",
            "6c59d0c5744649409b8cd68c4e3b9686",
            "56ee5f8ea0e14ea1be29df0a980b2c4a",
            "6a62f641a42f46c489b6802056846c29",
            "0f4599b2e1b9439985c66f948f74c158",
            "d885cfcc7339498786df3d4760c3edc5",
            "cd885350994a4d91b34f149f391b11a1",
            "d68ab43a920c4d8b835d86fa9b6f6986",
            "9e4f4c59ca304fd7b269585ea82bb311",
            "e429cc6844cb463fb203e6efda29473f"
          ]
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab44f0f498a44e5fa21a650f53106281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-13 07:42:22 INFO: Downloading default packages for language: fa (Persian)...\n",
            "2022-04-13 07:42:22 INFO: File exists: /root/stanza_resources/fa/default.zip.\n",
            "2022-04-13 07:42:25 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ],
      "metadata": {
        "id": "3g4pAEec7ux5",
        "outputId": "1127749c-b995-4ea5-f826-f9315db5ef64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-13 07:42:27 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-13 07:42:27 INFO: Use device: gpu\n",
            "2022-04-13 07:42:27 INFO: Loading: tokenize\n",
            "2022-04-13 07:42:31 INFO: Loading: mwt\n",
            "2022-04-13 07:42:31 INFO: Loading: pos\n",
            "2022-04-13 07:42:32 INFO: Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "% cd fastText\n",
        "!  pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "id": "VpY9zQDp8Jux",
        "outputId": "a80b9003-0e52-4eeb-9183-134be126669f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3930, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 3930 (delta 28), reused 42 (delta 11), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3930/3930), 8.33 MiB | 30.48 MiB/s, done.\n",
            "Resolving deltas: 100% (2445/2445), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3139847 sha256=490cb453a83891f3f9af610c207609471e117b44d5e39e5595e13b355bdc0617\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xml7hll9/wheels/22/04/6e/b3aba25c1a5845898b5871a0df37c2126cb0cc9326ad0c08e7\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd fastText\n",
        "!./download_model.py fa\n",
        "% cd .."
      ],
      "metadata": {
        "id": "DoKi4iNn8ZUH",
        "outputId": "f715407d-fd45-4c00-9d70-6c1271467c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastText\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            " (100.00%) [==================================================>]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "t42lvGmI4_9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/test_data.zip -d data"
      ],
      "metadata": {
        "id": "Dnz8jjIu5cXG",
        "outputId": "707d08a9-78c5-4dd9-f3f3-22290efe0315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/دیتاست بیجن خان/test_data.zip\n",
            "  inflating: data/test_data.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/train_data.zip -d data"
      ],
      "metadata": {
        "id": "tWHVk-7Y5pSN",
        "outputId": "b11d3e68-cc5d-4d55-ecca-dc885d563caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/دیتاست بیجن خان/train_data.zip\n",
            "  inflating: data/train_data.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gJNO0vEv5tTF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/test_data.txt', sep='\\t', header=None)\n",
        "df.rename(columns={0:'word', 1:'tag'}, inplace=True)"
      ],
      "metadata": {
        "id": "XlzUtvkA5wB9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "agWAZ_MS52rO",
        "outputId": "88600917-c4af-4f15-8820-ba9b2cdf41e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      word tag\n",
              "0        #   O\n",
              "1    سلسله  ye\n",
              "2  صفاریان   O\n",
              "3        #   O\n",
              "4     طاهر   e"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4294af0-eaa2-41f2-a2c6-de3cb2cfacdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلسله</td>\n",
              "      <td>ye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>صفاریان</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>طاهر</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4294af0-eaa2-41f2-a2c6-de3cb2cfacdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4294af0-eaa2-41f2-a2c6-de3cb2cfacdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4294af0-eaa2-41f2-a2c6-de3cb2cfacdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ],
      "metadata": {
        "id": "5FPbeFOQQ5Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pos_tager(text):\n",
        "  doc = nlp_pos(text)\n",
        "  pos = [word.xpos for sent in doc.sentences for word in sent.words if word.text not in ['ش','شان','م', 'مان', 'ند','ست','یت', 'تان', 'ت','اش']]\n",
        "  # pos_ = [(word.text , word.upos, word.xpos) for sent in doc.sentences for word in sent.words ]\n",
        "  # print(pos_)\n",
        "  return pos"
      ],
      "metadata": {
        "id": "ysPjTc9uJQrn"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pos_tager('این معبد از یادگارهای دوران سلوکی‌ها ) شصت و چهار - سیصد و سیزده ق م ( است که در شهر کنگاور قرار دارد و از نظر ساختمانی ، مخلوطی از سبک یونانی و ایرانی است و چنان‌که از نامش پیداست مربوط به آناهیتا دختر دین‌مهر می‌باشد که نزد ایرانیان قدیم مقام والایی داشته است . '))"
      ],
      "metadata": {
        "id": "vzsYDdS0JgbH",
        "outputId": "4f145a7f-f2a3-4b2c-c660-75ccb95ae556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('این', 'DET', 'PREM_DEMAJ'), ('معبد', 'NOUN', 'N_IANM'), ('از', 'ADP', 'PREP'), ('یادگارهای', 'NOUN', 'N_IANM'), ('دوران', 'NOUN', 'N_IANM'), ('سلوکی\\u200cها', 'NOUN', 'N_ANM'), (')', 'PUNCT', 'PUNC'), ('شصت', 'NUM', 'PRENUM'), ('و', 'CCONJ', 'CONJ'), ('چهار', 'NUM', 'PRENUM'), ('-', 'PUNCT', 'PUNC'), ('سیصد', 'NUM', 'PRENUM'), ('و', 'CCONJ', 'CONJ'), ('سیزده', 'NOUN', 'N_IANM'), ('ق', 'NOUN', 'N_IANM'), ('م', 'PRON', 'PR_JOPER'), ('(', 'PUNCT', 'PUNC'), ('است', 'AUX', 'AUX'), ('که', 'SCONJ', 'SUBR'), ('در', 'ADP', 'PREP'), ('شهر', 'PROPN', 'N_IANM'), ('کنگاور', 'PROPN', 'N_IANM'), ('قرار', 'NOUN', 'N_IANM'), ('دارد', 'VERB', 'V_ACT'), ('و', 'CCONJ', 'CONJ'), ('از', 'ADP', 'PREP'), ('نظر', 'NOUN', 'N_IANM'), ('ساختمانی', 'ADJ', 'ADJ_AJP'), ('،', 'PUNCT', 'PUNC'), ('مخلوطی', 'ADJ', 'ADJ_AJP'), ('از', 'ADP', 'PREP'), ('سبک', 'NOUN', 'N_IANM'), ('یونانی', 'ADJ', 'ADJ_AJP'), ('و', 'CCONJ', 'CONJ'), ('ایرانی', 'ADJ', 'ADJ_AJP'), ('است', 'AUX', 'AUX'), ('و', 'CCONJ', 'CONJ'), ('چنان\\u200cکه', 'PROPN', 'N_ANM'), ('از', 'ADP', 'PREP'), ('نامش', 'NOUN', 'N_IANM'), ('پیداست', 'NOUN', 'N_IANM'), ('مربوط', 'ADJ', 'ADJ_AJP'), ('به', 'ADP', 'PREP'), ('آناهیتا', 'PROPN', 'N_IANM'), ('دختر', 'NOUN', 'N_ANM'), ('دین\\u200cمهر', 'PROPN', 'N_ANM'), ('می\\u200cباشد', 'AUX', 'AUX'), ('که', 'SCONJ', 'SUBR'), ('نزد', 'ADP', 'PREP'), ('ایرانیان', 'NOUN', 'N_ANM'), ('قدیم', 'ADJ', 'ADJ_AJP'), ('مقام', 'NOUN', 'N_IANM'), ('والایی', 'ADJ', 'ADJ_AJP'), ('داشته', 'VERB', 'V_ACT'), ('است', 'AUX', 'AUX'), ('.', 'PUNCT', 'PUNC')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "IrgJRAmA3vzk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "Gj1O3oMm_FHg",
        "outputId": "90be0f2b-66e6-499b-da46-3d7fef7bd4a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1525970"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_consist(pos_tag, kasre_tag, sent):\n",
        "  l1 = len(pos_tag)\n",
        "  l2 = len(kasre_tag)\n",
        "  l3 = len(sent.split())\n",
        "  if l1!=l2:\n",
        "    return False\n",
        "  if l1!=l3:\n",
        "    return False\n",
        "  if l3!=l2:\n",
        "    return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "BOI3dbHJUK5z"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/test_data.txt', encoding='utf-8') as f:\n",
        "    data = f.readlines()\n",
        "sents = list()\n",
        "kasre_tags = list()\n",
        "temp_sent = ''\n",
        "temp_tags = list()\n",
        "pos_tags = list()\n",
        "for i, line in tqdm(enumerate(data)):\n",
        "    # if i>10000: break\n",
        "    try:\n",
        "        word, ez = line.split()\n",
        "        word += ' '\n",
        "        temp_sent += word\n",
        "        temp_tags.append(ez)\n",
        "        if word in ['. ', '# ']:\n",
        "            pos_tag = pos_tager(temp_sent)\n",
        "            ok = check_consist(pos_tag, temp_tags, temp_sent)\n",
        "            if ok:\n",
        "              sents.append(temp_sent) \n",
        "              kasre_tags.append(temp_tags)\n",
        "              pos_tags.append(pos_tag)\n",
        "            temp_sent = ''\n",
        "            temp_tags = list()\n",
        "    except:\n",
        "        pos_tag = pos_tager(temp_sent)\n",
        "        ok = check_consist(pos_tag, temp_tags, temp_sent)\n",
        "        if ok:\n",
        "          sents.append(temp_sent) \n",
        "          kasre_tags.append(temp_tags)\n",
        "          pos_tags.append(pos_tag)\n",
        "        temp_sent = ''\n",
        "        temp_tags = list()   "
      ],
      "metadata": {
        "id": "CczRNmjYHMeo",
        "outputId": "bf487860-8681-40e5-8f5b-f864e47a9a85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1022it [00:02, 715.32it/s]/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n",
            "1525970it [26:57, 943.18it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sents), len(kasre_tags), len(pos_tags)"
      ],
      "metadata": {
        "id": "xHhVjrW7VWs4",
        "outputId": "e2c506b2-7b32-4b85-9dd9-e01abce2c6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56132, 56132, 56132)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sents[455].split()), len(kasre_tags[455]), len(pos_tags[455])"
      ],
      "metadata": {
        "id": "byJ_XyJ7SIG9",
        "outputId": "6cac5a37-2a3f-4bf4-ba0a-3f7fbfd37bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents[455]"
      ],
      "metadata": {
        "id": "UwwsY3_SSoEO",
        "outputId": "4e89224b-ba2f-498f-de96-0967e4f443f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'این معبد از یادگارهای دوران سلوکی\\u200cها ) شصت و چهار - سیصد و سیزده ق م ( است که در شهر کنگاور قرار دارد و از نظر ساختمانی ، مخلوطی از سبک یونانی و ایرانی است و چنان\\u200cکه از نامش پیداست مربوط به آناهیتا دختر دین\\u200cمهر می\\u200cباشد که نزد ایرانیان قدیم مقام والایی داشته است . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents[2]"
      ],
      "metadata": {
        "id": "chE8WH_YSOdE",
        "outputId": "de19459e-bebe-4dc5-a23f-a74cc2270bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'طاهرِ ذوالیمینین مؤسسِ این سلسله در خراسان بود . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pos_tags)):\n",
        "  l1 = len(pos_tags[i])\n",
        "  l2 = len(kasre_tags[i])\n",
        "  l3 = len(sents[i].split())\n",
        "  if l1!=l2:\n",
        "    print(f'type1 {i}')\n",
        "  if l1!=l3:\n",
        "    print(f'type2 {i}')\n",
        "  if l3!=l2:\n",
        "    print(f'type3 {i}')"
      ],
      "metadata": {
        "id": "2O-AWsTiRYz_",
        "outputId": "b1167f59-f911-4b8d-b467-f23113b0ca16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type1 455\n",
            "type2 455\n",
            "type1 465\n",
            "type2 465\n",
            "type1 470\n",
            "type2 470\n",
            "type1 526\n",
            "type2 526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raws = list()\n",
        "\n",
        "for i in range(len(pos_tags)):\n",
        "  for j in range(len(pos_tags[i])):\n",
        "    raw = f'{sents[i].split()[j]}\\t{pos_tags[i][j]}\\t{kasre_tags[i][j]}'\n",
        "    raws.append(raw)\n",
        "  raws.append('\\n')"
      ],
      "metadata": {
        "id": "T135cmSTb6xD"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raws_text = '\\n'.join(raws)\n",
        "with open('data/test_clean.tsv', 'w') as f:\n",
        "  f.write(raws_text)"
      ],
      "metadata": {
        "id": "BJdv-AQPciog"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r models\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "3K9fl9H075NQ"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "1ZCu237t79ne",
        "outputId": "e49b5513-a4d6-46e9-dac7-1090570475fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fasttext import load_model\n",
        "\n",
        "# original BIN model loading\n",
        "f = load_model('fastText/cc.fa.300.bin')\n",
        "lines=[]\n",
        "\n",
        "# get all words from model\n",
        "words = f.get_words()\n",
        "\n",
        "with open('fastText/cc.fa.300.vec','w') as file_out:\n",
        "    \n",
        "    # the first line must contain number of total words and vector dimension\n",
        "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
        "\n",
        "    # line by line, you append vectors to VEC file\n",
        "    for w in words:\n",
        "        v = f.get_word_vector(w)\n",
        "        vstr = \"\"\n",
        "        for vi in v:\n",
        "            vstr += \" \" + str(vi)\n",
        "        try:\n",
        "            file_out.write(w + vstr+'\\n')\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "jGbN7OqcBSGS"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ7tDnc7s76q"
      },
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        # directories\n",
        "        self.train_data_dir = 'data/test_clean.tsv'\n",
        "        self.model_dir = 'models'\n",
        "        self.we_model_dir = 'fastText/cc.fa.300.vec'\n",
        "        self.we_pickled_model_dir = 'fastText/cc.fa.300.pickle'\n",
        "\n",
        "        # general\n",
        "        self.data_split = .1\n",
        "        self.num_epochs = 25\n",
        "        self.batch_size = 16\n",
        "        self.shuffle_buffer = 320000\n",
        "        self.num_tags = 5\n",
        "        self.num_pos_tags = 33\n",
        "        self.word_max_len = 30\n",
        "        self.learning_rate = 1e-3\n",
        "        self.max_len = 1276\n",
        "\n",
        "        # embeddings\n",
        "        self.num_words = 100000\n",
        "        self.word_embed_dim = 300\n",
        "        self.num_chars = 256  # number of most frequent characters to be kept\n",
        "        self.char_embed_dim = 32\n",
        "        self.pos_embed_dim = 16\n",
        "\n",
        "        # lstm variables\n",
        "        self.lstm_units = 256  # number of hidden units in the RNN\n",
        "        self.dropout = .5  # keeping probability"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GarAaRl8lvft"
      },
      "source": [
        "import re\n",
        "import random\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        # loading word embedding model\n",
        "        try:\n",
        "            handle = open(cfg.we_pickled_model_dir, 'rb') \n",
        "            self.word_embedding_model = pickle.load(handle)\n",
        "        except FileNotFoundError:\n",
        "            self.word_embedding_model = KeyedVectors.load_word2vec_format(cfg.we_model_dir, binary=False)\n",
        "            with open(cfg.we_pickled_model_dir, 'wb') as handle:\n",
        "                pickle.dump(self.word_embedding_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        sents, all_pos_tags, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "        print(len(sents))\n",
        "        sents_shuf = []\n",
        "        all_pos_tags_shuf = []\n",
        "        all_ezafe_tags_shuf = []\n",
        "        index_shuf = list(range(len(sents)))\n",
        "\n",
        "        for i in index_shuf:\n",
        "            sents_shuf.append(sents[i])\n",
        "            all_pos_tags_shuf.append(all_pos_tags[i])\n",
        "            all_ezafe_tags_shuf.append(all_ezafe_tags[i])\n",
        "\n",
        "        random.seed(17)\n",
        "        random.shuffle(index_shuf)\n",
        "        data_split_1 = int(len(sents_shuf) * .1)\n",
        "        data_split_2 = int(len(sents_shuf) * .2)\n",
        "        \n",
        "        self.test_data = sents_shuf[:data_split_1], all_pos_tags_shuf[:data_split_1], all_ezafe_tags_shuf[:data_split_1]\n",
        "        self.valid_data = sents_shuf[data_split_1:data_split_2], all_pos_tags_shuf[data_split_1:data_split_2], all_ezafe_tags_shuf[data_split_1:data_split_2]\n",
        "        self.train_data = sents_shuf[data_split_2:], all_pos_tags_shuf[data_split_2:], all_ezafe_tags_shuf[data_split_2:]            \n",
        "        \n",
        "        print('train data:', len(self.train_data[0]))\n",
        "        print('validation data:', len(self.valid_data[0]))\n",
        "        print('test data:', len(self.test_data[0]))\n",
        "        \n",
        "        try:\n",
        "            with open('indices.pickle', 'rb') as handle:\n",
        "                self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index = pickle.load(handle)\n",
        "            \n",
        "            print(self.pos_tag_to_index)\n",
        "\n",
        "            self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "            self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "        \n",
        "            sents, all_pos_tags, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print('Building vocabulary...')\n",
        "\n",
        "            vocab_list = []\n",
        "            char_list = []\n",
        "            for sent in self.train_data[0]:\n",
        "                for word in sent:\n",
        "                    vocab_list.append(word)\n",
        "                    for char in word:\n",
        "                        char_list.append(char)\n",
        "            \n",
        "            most_common_words = Counter(vocab_list).most_common(cfg.num_words)\n",
        "            most_common_chars = Counter(char_list).most_common(cfg.num_chars)\n",
        "            \n",
        "            self.word_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0)] + most_common_words):\n",
        "                self.word_to_index[pair[0]] = i + 1\n",
        "\n",
        "            self.char_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0), ('<UNK>', 1)] + most_common_chars):\n",
        "                self.char_to_index[pair[0]] = i + 1\n",
        "            \n",
        "            self.pos_tag_to_index = {}\n",
        "            for i, tag in enumerate(set(x for y in self.train_data[1] for x in y)):\n",
        "                self.pos_tag_to_index[tag] = i + 1\n",
        "\n",
        "            self.ezafe_tag_to_index = {'O': 0, 'e': 1,'ye': 2, 've':3, 'y':4}\n",
        "\n",
        "            self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "            self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "\n",
        "            # saving the tokenizers\n",
        "            with open('indices.pickle', 'wb') as handle:\n",
        "                indices = self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index\n",
        "                pickle.dump(indices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "    def _data_reader(self, directory):\n",
        "        sents, sent = [], []\n",
        "        all_ezafe_tags, ezafe_tags = [], []\n",
        "        all_pos_tags, pos_tags = [], []\n",
        "        with open(directory) as bijankhan_corpus:\n",
        "            for line in bijankhan_corpus:\n",
        "                if line != '\\n':\n",
        "                    word, pos_tag, ezafe_tag = line.strip().split('\\t')\n",
        "                    sent.append(word.replace('ي', 'ی').replace('ك', 'ک').replace('ة', 'ه'))\n",
        "                    pos_tags.append(pos_tag)\n",
        "                    ezafe_tags.append(ezafe_tag)\n",
        "                else:\n",
        "                    if len(sent)>1 :\n",
        "                      sents.append(sent)\n",
        "                      all_pos_tags.append(pos_tags)\n",
        "                      all_ezafe_tags.append(ezafe_tags)\n",
        "                     \n",
        "                    sent = []\n",
        "                    pos_tags = []\n",
        "                    ezafe_tags = []\n",
        "\n",
        "        return sents, all_pos_tags, all_ezafe_tags\n",
        "\t\n",
        "\n",
        "    def _pad(self, word):\n",
        "        for _ in range(cfg.word_max_len - len(word)):\n",
        "            word.append(0)\n",
        "        return word\n",
        "    \n",
        "\n",
        "    def _sent_to_index(self, sentence, mode='word'):\n",
        "        if mode is 'word':\n",
        "            return [self.word_to_index.get(word, 1) for word in sentence]\n",
        "        elif mode is 'char':\n",
        "            indexed_sentence = []\n",
        "            for word in sentence:\n",
        "                indexed_word = []\n",
        "                for char in word:\n",
        "                    indexed_word.append(self.char_to_index.get(word, 1))\n",
        "                indexed_sentence.append(self._pad(indexed_word))\n",
        "            return indexed_sentence\n",
        "\n",
        "\n",
        "    def _sent_to_embed(self, sentence):\n",
        "        embed_sent = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                embed_sent.append(self.word_embedding_model[word])\n",
        "            except KeyError:\n",
        "                embed_sent.append([0 for _ in range(cfg.word_embed_dim)])\n",
        "        return embed_sent\n",
        "\n",
        "    \n",
        "    def _pos_tags_to_index(self, tags):\n",
        "        return [self.pos_tag_to_index[tag] for tag in tags]\n",
        "\n",
        "    \n",
        "    def _ezafe_tags_to_index(self, tags):\n",
        "        return [self.ezafe_tag_to_index[tag] for tag in tags]\n",
        "\n",
        "\n",
        "    def data_generator(self, mode=None, char=False, pos=None):\n",
        "        if mode is 'train':\n",
        "            sents, pos_tags, ezafe_tags = self.train_data\n",
        "        elif mode is 'eval': \n",
        "            sents, pos_tags, ezafe_tags = self.valid_data\n",
        "        else:\n",
        "            raise ArgumentError(\"Invalid argument. 'mode' must be either 'train', 'eval', or 'pred'.\")\n",
        "    \n",
        "        for sent, pos_tag, ezafe_tag in zip(sents, pos_tags, ezafe_tags):\n",
        "            sent_char = self._sent_to_index(sent, mode='char')\n",
        "            # sent_word = self._sent_to_index(sent)\n",
        "            sent_word = self._sent_to_embed(sent)\n",
        "            length = [1 for _ in range(len(sent))]\n",
        "            # print('############')\n",
        "            # print(pos_tag)\n",
        "            pos_tag = self._pos_tags_to_index(pos_tag)\n",
        "            tag = self._ezafe_tags_to_index(ezafe_tag)\n",
        "            weights = [1. if x == 0 else 1.5 for x in tag]\n",
        "            # print('************')\n",
        "            # print(tag)\n",
        "            if char:\n",
        "                yield (np.array(sent_word), np.array(sent_char), np.array(length)), np.array(tag)\n",
        "            elif pos is 'cposi':\n",
        "                yield (np.array(sent_word), np.array(sent_char), np.array(pos_tag), np.array(length), np.array(weights)), np.array(ezafe_tag)\n",
        "            else:\n",
        "                yield np.array(sent_word), np.array(tag)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader()"
      ],
      "metadata": {
        "id": "yX5nFw2hOdfM",
        "outputId": "2c3f4d2b-9611-48c6-9b1f-d1d57dcefaa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53412\n",
            "train data: 42730\n",
            "validation data: 5341\n",
            "test data: 5341\n",
            "{'N_ANM': 1, 'PUNC': 2, 'AUX_PASS': 3, 'ADR_POSADR': 4, 'PR_INTG': 5, 'IDEN': 6, 'PR_JOPER': 7, 'V_MODL': 8, 'PSUS': 9, 'PR_DEMON': 10, 'AUX': 11, 'PREP': 12, 'POSTP': 13, 'PREM_QUAJ': 14, 'ADV_SADV': 15, 'V_PASS': 16, 'PR_UCREFX': 17, 'PART': 18, 'ADR_PRADR': 19, 'V_ACT': 20, 'PREM_AMBAJ': 21, 'PREM_DEMAJ': 22, 'ADJ_AJP': 23, 'POSNUM': 24, 'PR_RECPR': 25, 'PR_SEPER': 26, 'PR_CREFX': 27, 'ADJ_AJCM': 28, 'ADJ_AJSUP': 29, 'N_IANM': 30, 'PRENUM': 31, 'CONJ': 32, 'SUBR': 33}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dl.pos_tag_to_index.keys())"
      ],
      "metadata": {
        "id": "FD29hCG7Ofqb",
        "outputId": "9e48cb1b-195a-4c8b-a4ff-9dcb0a0b070e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmuk5Gc9lyrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd40b82-6b99-45c0-b2e4-b9a6a8c25c8f"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.contrib import layers\n",
        "from tf_metrics import precision, recall, f1\n",
        "\n",
        "\n",
        "data_loader = DataLoader()\n",
        "\n",
        "\n",
        "def model_fn(mode, features, labels):\n",
        "    # Logging\n",
        "    Path('results').mkdir(exist_ok=True)\n",
        "    tf.logging.set_verbosity(logging.INFO)\n",
        "    handlers = [logging.FileHandler('results/main.log'),\n",
        "                logging.StreamHandler(sys.stdout)]\n",
        "    logging.getLogger('tensorflow').handlers = handlers\n",
        "    \n",
        "    word_inputs, char_inputs, length = features\n",
        "\n",
        "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    batch_size = tf.shape(word_inputs)[0]\n",
        "    # input_lengths = tf.count_nonzero(word_inputs, 1, dtype=tf.int32)\n",
        "    input_lengths = tf.count_nonzero(length, 1, dtype=tf.int32)\n",
        "\n",
        "    \n",
        "    # Char Embeddings\n",
        "    # char_embeddings = tf.get_variable('char_embeddings', [cfg.num_chars + 2, cfg.char_embed_dim])\n",
        "    # embedded_chars = tf.nn.embedding_lookup(char_embeddings, char_inputs)\n",
        "    # embedded_chars = tf.layers.dropout(embedded_chars, rate=.5, training=training)\n",
        "    \n",
        "    # Reshaping for CNN\n",
        "    # output = tf.reshape(embedded_chars, [-1, tf.shape(char_inputs)[2], cfg.char_embed_dim])\n",
        "\n",
        "    # CNN\n",
        "    # output = tf.layers.conv1d(output, filters=64, kernel_size=2, strides=1, padding=\"same\", activation=tf.nn.relu)\n",
        "    # output = tf.layers.max_pooling1d(output, pool_size=2, strides=2)\n",
        "    # output = tf.layers.conv1d(output, filters=128, kernel_size=2, strides=1, padding=\"same\", activation=tf.nn.relu)\n",
        "    # output = tf.layers.max_pooling1d(output, pool_size=2, strides=2)\n",
        "\n",
        "    # cnn_output = tf.layers.dropout(output, rate=.5, training=training)\n",
        "    # cnn_output = tf.layers.flatten(cnn_output)\n",
        "\n",
        "    # Word Embeddings\n",
        "    # word_embeddings = tf.get_variable('word_embeddings', [cfg.num_words + 2, cfg.word_embed_dim])\n",
        "    # embedded_words = tf.nn.embedding_lookup(word_embeddings, word_inputs)\n",
        "    # word_inputs = tf.layers.dropout(word_inputs, rate=.5, training=training)\n",
        "    \n",
        "    # Reshaping CNN and concatenating for LSTM\n",
        "    # cnn_output = tf.reshape(cnn_output, [-1, tf.shape(char_inputs)[1], 128 * int(cfg.word_max_len / 4)])\n",
        "    # lstm_inputs = tf.concat([word_inputs, cnn_output], axis=-1) \n",
        "\n",
        "    # LSTM\n",
        "    transposed_emb = tf.transpose(word_inputs, perm=[1, 0, 2])\n",
        "    fw_cell = tf.contrib.rnn.LSTMBlockFusedCell(cfg.lstm_units)\n",
        "    bw_cell = tf.contrib.rnn.TimeReversedFusedRNN(tf.contrib.rnn.LSTMBlockFusedCell(cfg.lstm_units))\n",
        "    output_fw, _ = fw_cell(transposed_emb, dtype=tf.float32, sequence_length=input_lengths)\n",
        "    output_bw, _ = bw_cell(transposed_emb, dtype=tf.float32, sequence_length=input_lengths)\n",
        "    output = tf.concat([output_fw, output_bw], axis=-1)\n",
        "    output = tf.transpose(output, perm=[1, 0, 2])\n",
        "    lstm_output = tf.layers.dropout(output, rate=.5, training=training)\n",
        "\n",
        "    # Dense\n",
        "    output = tf.reshape(lstm_output, [-1, 2 * cfg.lstm_units])\n",
        "    logits = tf.layers.dense(output, cfg.num_tags)\n",
        "    pred = tf.reshape(logits, [-1, tf.shape(word_inputs)[1], cfg.num_tags])\n",
        "    pred_ids = tf.cast(tf.argmax(pred, axis=-1), tf.int32)\n",
        "    \n",
        "    # Loss\n",
        "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=pred))\n",
        "\n",
        "    # Metrics\n",
        "    weights = tf.to_float(tf.sign(length))\n",
        "    indices = [1]\n",
        "    metrics = {'acc': tf.metrics.accuracy(labels, pred_ids, weights),\n",
        "               'precision': precision(labels, pred_ids, cfg.num_tags, indices, weights),\n",
        "               'recall': recall(labels, pred_ids, cfg.num_tags, indices, weights),\n",
        "               'f1': f1(labels, pred_ids, cfg.num_tags, indices, weights)}\n",
        "    \n",
        "    for metric_name, op in metrics.items():\n",
        "        tf.summary.scalar(metric_name, op[1])\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        return tf.estimator.EstimatorSpec(mode, loss=loss, \n",
        "                                          eval_metric_ops=metrics)\n",
        "\n",
        "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        train_op = tf.train.AdamOptimizer().minimize(loss, \n",
        "                                                     global_step=tf.train.get_or_create_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode, \n",
        "                                          loss=loss, \n",
        "                                          train_op=train_op)\n",
        "\n",
        "def input_fn(mode=None):\n",
        "    data_generator = lambda: data_loader.data_generator(mode=mode, char=True)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(data_generator, \n",
        "                                             output_types=((tf.float32, tf.int32, tf.int32), tf.int32),\n",
        "                                             output_shapes=(([None, cfg.word_embed_dim], [None, None], [None]), [None]))\n",
        "\n",
        "    if mode is 'train':\n",
        "        dataset = dataset.shuffle(cfg.shuffle_buffer).repeat(cfg.num_epochs)\n",
        "        \n",
        "    dataset = dataset.padded_batch(cfg.batch_size, padded_shapes=(([None, cfg.word_embed_dim], [None, None], [None]), [None]))\n",
        "        \n",
        "    return dataset\n",
        "\n",
        "\n",
        "def train():\n",
        "    train_input_func = lambda: input_fn(mode='train')\n",
        "    eval_input_func = lambda: input_fn(mode='eval')\n",
        "    \n",
        "    est_conf = tf.estimator.RunConfig(cfg.model_dir, save_checkpoints_secs=60)\n",
        "    estimator = tf.estimator.Estimator(model_fn, cfg.model_dir, est_conf)\n",
        "    \n",
        "    Path(estimator.eval_dir()).mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_func)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_func, throttle_secs=60)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n",
            "53412\n",
            "train data: 42730\n",
            "validation data: 5341\n",
            "test data: 5341\n",
            "{'N_ANM': 1, 'PUNC': 2, 'AUX_PASS': 3, 'ADR_POSADR': 4, 'PR_INTG': 5, 'IDEN': 6, 'PR_JOPER': 7, 'V_MODL': 8, 'PSUS': 9, 'PR_DEMON': 10, 'AUX': 11, 'PREP': 12, 'POSTP': 13, 'PREM_QUAJ': 14, 'ADV_SADV': 15, 'V_PASS': 16, 'PR_UCREFX': 17, 'PART': 18, 'ADR_PRADR': 19, 'V_ACT': 20, 'PREM_AMBAJ': 21, 'PREM_DEMAJ': 22, 'ADJ_AJP': 23, 'POSNUM': 24, 'PR_RECPR': 25, 'PR_SEPER': 26, 'PR_CREFX': 27, 'ADJ_AJCM': 28, 'ADJ_AJSUP': 29, 'N_IANM': 30, 'PRENUM': 31, 'CONJ': 32, 'SUBR': 33}\n",
            "Using config: {'_model_dir': 'models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 60, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa5f9392590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "Not using Distribute Coordinator.\n",
            "Running training and evaluation locally (non-distributed).\n",
            "Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Create CheckpointSaverHook.\n",
            "Graph was finalized.\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Saving checkpoints for 0 into models/model.ckpt.\n",
            "Saving checkpoints for 1 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:11:00Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-1\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:11:03\n",
            "Saving dict for global step 1: acc = 0.7677572, f1 = 0.0033397558, global_step = 1, loss = 1.5506423, precision = 0.25, recall = 0.001681107\n",
            "Saving 'checkpoint_path' summary for global step 1: models/model.ckpt-1\n",
            "loss = 1.6166959, step = 0\n",
            "global_step/sec: 31.7784\n",
            "loss = 1.0618339, step = 100 (3.145 sec)\n",
            "global_step/sec: 29.2233\n",
            "loss = 0.7799273, step = 200 (3.419 sec)\n",
            "global_step/sec: 30.5541\n",
            "loss = 0.7543081, step = 300 (3.274 sec)\n",
            "global_step/sec: 29.622\n",
            "loss = 0.83165646, step = 400 (3.374 sec)\n",
            "global_step/sec: 30.0925\n",
            "loss = 0.47144115, step = 500 (3.323 sec)\n",
            "global_step/sec: 31.8494\n",
            "loss = 0.6094232, step = 600 (3.140 sec)\n",
            "global_step/sec: 29.5624\n",
            "loss = 0.50591016, step = 700 (3.382 sec)\n",
            "global_step/sec: 30.8735\n",
            "loss = 0.5492866, step = 800 (3.241 sec)\n",
            "global_step/sec: 29.8808\n",
            "loss = 0.46044227, step = 900 (3.345 sec)\n",
            "global_step/sec: 30.9473\n",
            "loss = 0.4531899, step = 1000 (3.231 sec)\n",
            "global_step/sec: 32.0184\n",
            "loss = 0.35290617, step = 1100 (3.124 sec)\n",
            "global_step/sec: 29.865\n",
            "loss = 0.32414994, step = 1200 (3.348 sec)\n",
            "global_step/sec: 31.1401\n",
            "loss = 0.28729066, step = 1300 (3.213 sec)\n",
            "global_step/sec: 32.1824\n",
            "loss = 0.31466037, step = 1400 (3.105 sec)\n",
            "global_step/sec: 30.4488\n",
            "loss = 0.28268486, step = 1500 (3.284 sec)\n",
            "global_step/sec: 31.5638\n",
            "loss = 0.22600299, step = 1600 (3.167 sec)\n",
            "global_step/sec: 28.899\n",
            "loss = 0.23330843, step = 1700 (3.461 sec)\n",
            "Saving checkpoints for 1740 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:12:00Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-1740\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:12:03\n",
            "Saving dict for global step 1740: acc = 0.93383056, f1 = 0.8413274, global_step = 1740, loss = 0.2260662, precision = 0.8155882, recall = 0.8687443\n",
            "Saving 'checkpoint_path' summary for global step 1740: models/model.ckpt-1740\n",
            "global_step/sec: 15.5169\n",
            "loss = 0.20273507, step = 1800 (6.445 sec)\n",
            "global_step/sec: 30.1272\n",
            "loss = 0.21128708, step = 1900 (3.318 sec)\n",
            "global_step/sec: 30.3035\n",
            "loss = 0.17358498, step = 2000 (3.300 sec)\n",
            "global_step/sec: 30.9017\n",
            "loss = 0.17756632, step = 2100 (3.239 sec)\n",
            "global_step/sec: 31.108\n",
            "loss = 0.16640787, step = 2200 (3.212 sec)\n",
            "global_step/sec: 29.1217\n",
            "loss = 0.16801438, step = 2300 (3.434 sec)\n",
            "global_step/sec: 29.6384\n",
            "loss = 0.15270986, step = 2400 (3.374 sec)\n",
            "global_step/sec: 31.3473\n",
            "loss = 0.12795629, step = 2500 (3.192 sec)\n",
            "global_step/sec: 31.8348\n",
            "loss = 0.1189493, step = 2600 (3.140 sec)\n",
            "global_step/sec: 30.716\n",
            "loss = 0.11750095, step = 2700 (3.254 sec)\n",
            "global_step/sec: 32.2403\n",
            "loss = 0.11375183, step = 2800 (3.104 sec)\n",
            "global_step/sec: 30.7793\n",
            "loss = 0.10814811, step = 2900 (3.248 sec)\n",
            "global_step/sec: 30.1774\n",
            "loss = 0.113971315, step = 3000 (3.312 sec)\n",
            "global_step/sec: 30.7928\n",
            "loss = 0.10446459, step = 3100 (3.248 sec)\n",
            "global_step/sec: 29.6098\n",
            "loss = 0.08125556, step = 3200 (3.377 sec)\n",
            "global_step/sec: 29.3781\n",
            "loss = 0.08338253, step = 3300 (3.404 sec)\n",
            "global_step/sec: 29.6992\n",
            "loss = 0.11335515, step = 3400 (3.366 sec)\n",
            "Saving checkpoints for 3480 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:13:00Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-3480\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:13:03\n",
            "Saving dict for global step 3480: acc = 0.9447088, f1 = 0.86729985, global_step = 3480, loss = 0.107224874, precision = 0.8850451, recall = 0.85025215\n",
            "Saving 'checkpoint_path' summary for global step 3480: models/model.ckpt-3480\n",
            "global_step/sec: 15.9529\n",
            "loss = 0.07130431, step = 3500 (6.269 sec)\n",
            "global_step/sec: 30.0409\n",
            "loss = 0.08917282, step = 3600 (3.329 sec)\n",
            "global_step/sec: 30.3796\n",
            "loss = 0.113333546, step = 3700 (3.292 sec)\n",
            "global_step/sec: 28.847\n",
            "loss = 0.073800534, step = 3800 (3.465 sec)\n",
            "global_step/sec: 31.1795\n",
            "loss = 0.08384567, step = 3900 (3.207 sec)\n",
            "global_step/sec: 30.5266\n",
            "loss = 0.076940484, step = 4000 (3.275 sec)\n",
            "global_step/sec: 29.7596\n",
            "loss = 0.07705577, step = 4100 (3.361 sec)\n",
            "global_step/sec: 30.0499\n",
            "loss = 0.06664278, step = 4200 (3.328 sec)\n",
            "global_step/sec: 29.931\n",
            "loss = 0.061980475, step = 4300 (3.342 sec)\n",
            "global_step/sec: 28.3975\n",
            "loss = 0.081625044, step = 4400 (3.520 sec)\n",
            "global_step/sec: 30.7032\n",
            "loss = 0.09452538, step = 4500 (3.257 sec)\n",
            "global_step/sec: 30.5599\n",
            "loss = 0.09367576, step = 4600 (3.272 sec)\n",
            "global_step/sec: 31.3373\n",
            "loss = 0.0586324, step = 4700 (3.192 sec)\n",
            "global_step/sec: 30.3163\n",
            "loss = 0.06965815, step = 4800 (3.297 sec)\n",
            "global_step/sec: 28.838\n",
            "loss = 0.05923145, step = 4900 (3.468 sec)\n",
            "global_step/sec: 28.3744\n",
            "loss = 0.04824628, step = 5000 (3.524 sec)\n",
            "global_step/sec: 32.2893\n",
            "loss = 0.060774248, step = 5100 (3.097 sec)\n",
            "Saving checkpoints for 5200 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:14:00Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-5200\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:14:03\n",
            "Saving dict for global step 5200: acc = 0.95216763, f1 = 0.8898338, global_step = 5200, loss = 0.074670285, precision = 0.886635, recall = 0.89305574\n",
            "Saving 'checkpoint_path' summary for global step 5200: models/model.ckpt-5200\n",
            "global_step/sec: 16.3328\n",
            "loss = 0.06430918, step = 5200 (6.123 sec)\n",
            "global_step/sec: 30.9708\n",
            "loss = 0.053116843, step = 5300 (3.229 sec)\n",
            "global_step/sec: 30.0435\n",
            "loss = 0.06906158, step = 5400 (3.328 sec)\n",
            "global_step/sec: 30.5955\n",
            "loss = 0.055156823, step = 5500 (3.271 sec)\n",
            "global_step/sec: 30.1407\n",
            "loss = 0.059690915, step = 5600 (3.315 sec)\n",
            "global_step/sec: 29.4941\n",
            "loss = 0.056024414, step = 5700 (3.391 sec)\n",
            "global_step/sec: 29.9614\n",
            "loss = 0.05989517, step = 5800 (3.337 sec)\n",
            "global_step/sec: 31.6609\n",
            "loss = 0.04805823, step = 5900 (3.158 sec)\n",
            "global_step/sec: 29.2513\n",
            "loss = 0.032308925, step = 6000 (3.420 sec)\n",
            "global_step/sec: 30.0124\n",
            "loss = 0.06002398, step = 6100 (3.332 sec)\n",
            "global_step/sec: 31.1694\n",
            "loss = 0.0633966, step = 6200 (3.206 sec)\n",
            "global_step/sec: 30.6288\n",
            "loss = 0.040959317, step = 6300 (3.267 sec)\n",
            "global_step/sec: 31.487\n",
            "loss = 0.040089972, step = 6400 (3.175 sec)\n",
            "global_step/sec: 30.9137\n",
            "loss = 0.073890515, step = 6500 (3.237 sec)\n",
            "global_step/sec: 31.1358\n",
            "loss = 0.043325245, step = 6600 (3.210 sec)\n",
            "global_step/sec: 30.6158\n",
            "loss = 0.045521352, step = 6700 (3.266 sec)\n",
            "global_step/sec: 29.4118\n",
            "loss = 0.050224386, step = 6800 (3.400 sec)\n",
            "global_step/sec: 29.8146\n",
            "loss = 0.034811474, step = 6900 (3.353 sec)\n",
            "Saving checkpoints for 6930 into models/model.ckpt.\n",
            "From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:15:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-6930\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:15:03\n",
            "Saving dict for global step 6930: acc = 0.9578667, f1 = 0.90360504, global_step = 6930, loss = 0.060858864, precision = 0.9029051, recall = 0.90430623\n",
            "Saving 'checkpoint_path' summary for global step 6930: models/model.ckpt-6930\n",
            "global_step/sec: 15.3588\n",
            "loss = 0.03543133, step = 7000 (6.512 sec)\n",
            "global_step/sec: 30.3368\n",
            "loss = 0.037174016, step = 7100 (3.296 sec)\n",
            "global_step/sec: 32.2606\n",
            "loss = 0.055673547, step = 7200 (3.100 sec)\n",
            "global_step/sec: 30.2213\n",
            "loss = 0.041114524, step = 7300 (3.310 sec)\n",
            "global_step/sec: 30.0864\n",
            "loss = 0.0418004, step = 7400 (3.323 sec)\n",
            "global_step/sec: 29.6545\n",
            "loss = 0.04042722, step = 7500 (3.372 sec)\n",
            "global_step/sec: 29.8431\n",
            "loss = 0.05079589, step = 7600 (3.351 sec)\n",
            "global_step/sec: 28.341\n",
            "loss = 0.03501857, step = 7700 (3.529 sec)\n",
            "global_step/sec: 32.1349\n",
            "loss = 0.027960462, step = 7800 (3.111 sec)\n",
            "global_step/sec: 32.8013\n",
            "loss = 0.020114405, step = 7900 (3.049 sec)\n",
            "global_step/sec: 31.0169\n",
            "loss = 0.023317749, step = 8000 (3.224 sec)\n",
            "global_step/sec: 31.6829\n",
            "loss = 0.027708672, step = 8100 (3.156 sec)\n",
            "global_step/sec: 28.8796\n",
            "loss = 0.021592593, step = 8200 (3.462 sec)\n",
            "global_step/sec: 29.838\n",
            "loss = 0.046679046, step = 8300 (3.352 sec)\n",
            "global_step/sec: 30.7577\n",
            "loss = 0.034908228, step = 8400 (3.251 sec)\n",
            "global_step/sec: 30.2508\n",
            "loss = 0.02522215, step = 8500 (3.307 sec)\n",
            "global_step/sec: 31.2979\n",
            "loss = 0.028063744, step = 8600 (3.193 sec)\n",
            "Saving checkpoints for 8668 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:16:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-8668\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:16:03\n",
            "Saving dict for global step 8668: acc = 0.96092623, f1 = 0.91086763, global_step = 8668, loss = 0.05426528, precision = 0.9241416, recall = 0.8979697\n",
            "Saving 'checkpoint_path' summary for global step 8668: models/model.ckpt-8668\n",
            "global_step/sec: 15.9599\n",
            "loss = 0.022790967, step = 8700 (6.266 sec)\n",
            "global_step/sec: 30.007\n",
            "loss = 0.03400925, step = 8800 (3.332 sec)\n",
            "global_step/sec: 30.288\n",
            "loss = 0.030462408, step = 8900 (3.302 sec)\n",
            "global_step/sec: 30.4933\n",
            "loss = 0.019697746, step = 9000 (3.278 sec)\n",
            "global_step/sec: 30.8944\n",
            "loss = 0.030818354, step = 9100 (3.238 sec)\n",
            "global_step/sec: 30.0246\n",
            "loss = 0.026965166, step = 9200 (3.332 sec)\n",
            "global_step/sec: 31.9708\n",
            "loss = 0.030873844, step = 9300 (3.128 sec)\n",
            "global_step/sec: 29.2634\n",
            "loss = 0.04016662, step = 9400 (3.416 sec)\n",
            "global_step/sec: 29.1177\n",
            "loss = 0.055408318, step = 9500 (3.433 sec)\n",
            "global_step/sec: 30.5479\n",
            "loss = 0.031337295, step = 9600 (3.275 sec)\n",
            "global_step/sec: 29.874\n",
            "loss = 0.023830973, step = 9700 (3.347 sec)\n",
            "global_step/sec: 29.605\n",
            "loss = 0.022025462, step = 9800 (3.377 sec)\n",
            "global_step/sec: 30.3842\n",
            "loss = 0.025398226, step = 9900 (3.293 sec)\n",
            "global_step/sec: 30.5961\n",
            "loss = 0.063398294, step = 10000 (3.267 sec)\n",
            "global_step/sec: 28.8962\n",
            "loss = 0.021882804, step = 10100 (3.460 sec)\n",
            "global_step/sec: 30.3782\n",
            "loss = 0.016868666, step = 10200 (3.291 sec)\n",
            "global_step/sec: 29.837\n",
            "loss = 0.038725972, step = 10300 (3.352 sec)\n",
            "Saving checkpoints for 10383 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:17:00Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-10383\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:17:03\n",
            "Saving dict for global step 10383: acc = 0.96328586, f1 = 0.9169179, global_step = 10383, loss = 0.049167365, precision = 0.9098548, recall = 0.9240916\n",
            "Saving 'checkpoint_path' summary for global step 10383: models/model.ckpt-10383\n",
            "global_step/sec: 15.5051\n",
            "loss = 0.026664877, step = 10400 (6.451 sec)\n",
            "global_step/sec: 32.342\n",
            "loss = 0.022925284, step = 10500 (3.092 sec)\n",
            "global_step/sec: 32.5573\n",
            "loss = 0.013761169, step = 10600 (3.071 sec)\n",
            "global_step/sec: 30.7662\n",
            "loss = 0.02836946, step = 10700 (3.250 sec)\n",
            "global_step/sec: 29.6358\n",
            "loss = 0.026924988, step = 10800 (3.374 sec)\n",
            "global_step/sec: 30.7872\n",
            "loss = 0.022191677, step = 10900 (3.247 sec)\n",
            "global_step/sec: 30.5865\n",
            "loss = 0.035343416, step = 11000 (3.270 sec)\n",
            "global_step/sec: 30.6905\n",
            "loss = 0.054703124, step = 11100 (3.258 sec)\n",
            "global_step/sec: 32.313\n",
            "loss = 0.02509399, step = 11200 (3.096 sec)\n",
            "global_step/sec: 31.2968\n",
            "loss = 0.02785896, step = 11300 (3.194 sec)\n",
            "global_step/sec: 31.7969\n",
            "loss = 0.05394067, step = 11400 (3.146 sec)\n",
            "global_step/sec: 29.6218\n",
            "loss = 0.03649212, step = 11500 (3.376 sec)\n",
            "global_step/sec: 30.5753\n",
            "loss = 0.03411003, step = 11600 (3.270 sec)\n",
            "global_step/sec: 31.8473\n",
            "loss = 0.039343484, step = 11700 (3.140 sec)\n",
            "global_step/sec: 33.2351\n",
            "loss = 0.028469697, step = 11800 (3.010 sec)\n",
            "global_step/sec: 29.482\n",
            "loss = 0.022841975, step = 11900 (3.393 sec)\n",
            "global_step/sec: 30.6954\n",
            "loss = 0.03336649, step = 12000 (3.256 sec)\n",
            "global_step/sec: 29.673\n",
            "loss = 0.032305475, step = 12100 (3.370 sec)\n",
            "Saving checkpoints for 12146 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:18:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-12146\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:18:03\n",
            "Saving dict for global step 12146: acc = 0.9654055, f1 = 0.921869, global_step = 12146, loss = 0.046484966, precision = 0.9252312, recall = 0.918531\n",
            "Saving 'checkpoint_path' summary for global step 12146: models/model.ckpt-12146\n",
            "global_step/sec: 15.1146\n",
            "loss = 0.05095889, step = 12200 (6.616 sec)\n",
            "global_step/sec: 31.5798\n",
            "loss = 0.033821076, step = 12300 (3.167 sec)\n",
            "global_step/sec: 29.4083\n",
            "loss = 0.021190584, step = 12400 (3.400 sec)\n",
            "global_step/sec: 29.2547\n",
            "loss = 0.019375848, step = 12500 (3.418 sec)\n",
            "global_step/sec: 29.1103\n",
            "loss = 0.038231745, step = 12600 (3.435 sec)\n",
            "global_step/sec: 29.8633\n",
            "loss = 0.027938312, step = 12700 (3.349 sec)\n",
            "global_step/sec: 31.4277\n",
            "loss = 0.02121834, step = 12800 (3.183 sec)\n",
            "global_step/sec: 28.2114\n",
            "loss = 0.021492308, step = 12900 (3.543 sec)\n",
            "global_step/sec: 28.7989\n",
            "loss = 0.01989542, step = 13000 (3.472 sec)\n",
            "global_step/sec: 29.2356\n",
            "loss = 0.042473964, step = 13100 (3.420 sec)\n",
            "global_step/sec: 32.4176\n",
            "loss = 0.026114186, step = 13200 (3.086 sec)\n",
            "global_step/sec: 33.4623\n",
            "loss = 0.020656215, step = 13300 (2.988 sec)\n",
            "global_step/sec: 29.9244\n",
            "loss = 0.018881341, step = 13400 (3.341 sec)\n",
            "global_step/sec: 30.538\n",
            "loss = 0.031782348, step = 13500 (3.274 sec)\n",
            "global_step/sec: 29.148\n",
            "loss = 0.047377873, step = 13600 (3.432 sec)\n",
            "global_step/sec: 29.5367\n",
            "loss = 0.026035713, step = 13700 (3.384 sec)\n",
            "global_step/sec: 31.8685\n",
            "loss = 0.02327136, step = 13800 (3.139 sec)\n",
            "Saving checkpoints for 13860 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:19:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-13860\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:19:03\n",
            "Saving dict for global step 13860: acc = 0.9657855, f1 = 0.92220503, global_step = 13860, loss = 0.045272775, precision = 0.9185375, recall = 0.92590195\n",
            "Saving 'checkpoint_path' summary for global step 13860: models/model.ckpt-13860\n",
            "global_step/sec: 15.8037\n",
            "loss = 0.03325855, step = 13900 (6.327 sec)\n",
            "global_step/sec: 30.9861\n",
            "loss = 0.0469233, step = 14000 (3.227 sec)\n",
            "global_step/sec: 30.7625\n",
            "loss = 0.019229814, step = 14100 (3.251 sec)\n",
            "global_step/sec: 29.6127\n",
            "loss = 0.03008546, step = 14200 (3.376 sec)\n",
            "global_step/sec: 31.6709\n",
            "loss = 0.021636505, step = 14300 (3.159 sec)\n",
            "global_step/sec: 32.9071\n",
            "loss = 0.023255782, step = 14400 (3.039 sec)\n",
            "global_step/sec: 31.889\n",
            "loss = 0.03385753, step = 14500 (3.136 sec)\n",
            "global_step/sec: 30.2197\n",
            "loss = 0.04645432, step = 14600 (3.309 sec)\n",
            "global_step/sec: 30.2344\n",
            "loss = 0.021172846, step = 14700 (3.308 sec)\n",
            "global_step/sec: 29.5477\n",
            "loss = 0.018565582, step = 14800 (3.384 sec)\n",
            "global_step/sec: 29.7827\n",
            "loss = 0.032901175, step = 14900 (3.358 sec)\n",
            "global_step/sec: 31.0918\n",
            "loss = 0.022175765, step = 15000 (3.215 sec)\n",
            "global_step/sec: 29.9017\n",
            "loss = 0.022600759, step = 15100 (3.345 sec)\n",
            "global_step/sec: 29.8083\n",
            "loss = 0.029193338, step = 15200 (3.355 sec)\n",
            "global_step/sec: 29.7142\n",
            "loss = 0.01876422, step = 15300 (3.365 sec)\n",
            "global_step/sec: 30.0689\n",
            "loss = 0.027423961, step = 15400 (3.327 sec)\n",
            "global_step/sec: 30.9717\n",
            "loss = 0.021108605, step = 15500 (3.229 sec)\n",
            "Saving checkpoints for 15592 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:20:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-15592\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:20:03\n",
            "Saving dict for global step 15592: acc = 0.96716523, f1 = 0.9258245, global_step = 15592, loss = 0.04368264, precision = 0.9333684, recall = 0.91840166\n",
            "Saving 'checkpoint_path' summary for global step 15592: models/model.ckpt-15592\n",
            "global_step/sec: 15.3318\n",
            "loss = 0.02506412, step = 15600 (6.521 sec)\n",
            "global_step/sec: 29.3085\n",
            "loss = 0.0153678795, step = 15700 (3.413 sec)\n",
            "global_step/sec: 32.5675\n",
            "loss = 0.027828494, step = 15800 (3.072 sec)\n",
            "global_step/sec: 32.8558\n",
            "loss = 0.022635652, step = 15900 (3.044 sec)\n",
            "global_step/sec: 32.419\n",
            "loss = 0.02459121, step = 16000 (3.083 sec)\n",
            "global_step/sec: 29.4656\n",
            "loss = 0.039627235, step = 16100 (3.394 sec)\n",
            "global_step/sec: 31.4214\n",
            "loss = 0.022674484, step = 16200 (3.183 sec)\n",
            "global_step/sec: 29.0417\n",
            "loss = 0.015161631, step = 16300 (3.443 sec)\n",
            "global_step/sec: 30.5027\n",
            "loss = 0.015962953, step = 16400 (3.279 sec)\n",
            "global_step/sec: 29.8031\n",
            "loss = 0.030739546, step = 16500 (3.355 sec)\n",
            "global_step/sec: 31.1065\n",
            "loss = 0.018294249, step = 16600 (3.215 sec)\n",
            "global_step/sec: 30.2046\n",
            "loss = 0.02963176, step = 16700 (3.310 sec)\n",
            "global_step/sec: 30.2863\n",
            "loss = 0.038306646, step = 16800 (3.302 sec)\n",
            "global_step/sec: 29.4472\n",
            "loss = 0.014001848, step = 16900 (3.396 sec)\n",
            "global_step/sec: 30.789\n",
            "loss = 0.030899355, step = 17000 (3.248 sec)\n",
            "global_step/sec: 31.9202\n",
            "loss = 0.030684574, step = 17100 (3.133 sec)\n",
            "global_step/sec: 31.4663\n",
            "loss = 0.013457098, step = 17200 (3.179 sec)\n",
            "global_step/sec: 31.8611\n",
            "loss = 0.021203665, step = 17300 (3.137 sec)\n",
            "Saving checkpoints for 17350 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:21:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-17350\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:21:03\n",
            "Saving dict for global step 17350: acc = 0.96776515, f1 = 0.92758554, global_step = 17350, loss = 0.043756332, precision = 0.93857557, recall = 0.91684985\n",
            "Saving 'checkpoint_path' summary for global step 17350: models/model.ckpt-17350\n",
            "global_step/sec: 16.2654\n",
            "loss = 0.017463705, step = 17400 (6.147 sec)\n",
            "global_step/sec: 30.7185\n",
            "loss = 0.023387102, step = 17500 (3.256 sec)\n",
            "global_step/sec: 30.5092\n",
            "loss = 0.012568834, step = 17600 (3.277 sec)\n",
            "global_step/sec: 30.2358\n",
            "loss = 0.0119259795, step = 17700 (3.307 sec)\n",
            "global_step/sec: 29.1952\n",
            "loss = 0.04061941, step = 17800 (3.426 sec)\n",
            "global_step/sec: 29.4412\n",
            "loss = 0.022333914, step = 17900 (3.397 sec)\n",
            "global_step/sec: 30.2478\n",
            "loss = 0.028690787, step = 18000 (3.308 sec)\n",
            "global_step/sec: 30.1647\n",
            "loss = 0.049880743, step = 18100 (3.314 sec)\n",
            "global_step/sec: 30.5999\n",
            "loss = 0.018539304, step = 18200 (3.269 sec)\n",
            "global_step/sec: 29.7333\n",
            "loss = 0.02264396, step = 18300 (3.363 sec)\n",
            "global_step/sec: 29.6268\n",
            "loss = 0.033904925, step = 18400 (3.373 sec)\n",
            "global_step/sec: 30.0113\n",
            "loss = 0.02476415, step = 18500 (3.333 sec)\n",
            "global_step/sec: 32.4179\n",
            "loss = 0.020060964, step = 18600 (3.084 sec)\n",
            "global_step/sec: 31.0798\n",
            "loss = 0.020363498, step = 18700 (3.219 sec)\n",
            "global_step/sec: 30.6152\n",
            "loss = 0.0220042, step = 18800 (3.267 sec)\n",
            "global_step/sec: 28.0546\n",
            "loss = 0.018901361, step = 18900 (3.563 sec)\n",
            "global_step/sec: 29.2841\n",
            "loss = 0.016172078, step = 19000 (3.416 sec)\n",
            "Saving checkpoints for 19065 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:22:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-19065\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:22:03\n",
            "Saving dict for global step 19065: acc = 0.968745, f1 = 0.93178743, global_step = 19065, loss = 0.04206084, precision = 0.92825973, recall = 0.935342\n",
            "Saving 'checkpoint_path' summary for global step 19065: models/model.ckpt-19065\n",
            "global_step/sec: 15.44\n",
            "loss = 0.030715514, step = 19100 (6.476 sec)\n",
            "global_step/sec: 28.544\n",
            "loss = 0.016677717, step = 19200 (3.504 sec)\n",
            "global_step/sec: 30.2843\n",
            "loss = 0.028087448, step = 19300 (3.302 sec)\n",
            "global_step/sec: 29.5759\n",
            "loss = 0.016798254, step = 19400 (3.382 sec)\n",
            "global_step/sec: 28.9428\n",
            "loss = 0.024165718, step = 19500 (3.454 sec)\n",
            "global_step/sec: 30.3449\n",
            "loss = 0.021546716, step = 19600 (3.295 sec)\n",
            "global_step/sec: 30.6527\n",
            "loss = 0.020667205, step = 19700 (3.263 sec)\n",
            "global_step/sec: 31.5548\n",
            "loss = 0.017179728, step = 19800 (3.168 sec)\n",
            "global_step/sec: 30.0232\n",
            "loss = 0.0125429565, step = 19900 (3.333 sec)\n",
            "global_step/sec: 32.0926\n",
            "loss = 0.0355294, step = 20000 (3.115 sec)\n",
            "global_step/sec: 30.0215\n",
            "loss = 0.028146654, step = 20100 (3.333 sec)\n",
            "global_step/sec: 29.6871\n",
            "loss = 0.030860607, step = 20200 (3.366 sec)\n",
            "global_step/sec: 29.5307\n",
            "loss = 0.02842965, step = 20300 (3.387 sec)\n",
            "global_step/sec: 29.5268\n",
            "loss = 0.014518904, step = 20400 (3.386 sec)\n",
            "global_step/sec: 29.3306\n",
            "loss = 0.030806907, step = 20500 (3.411 sec)\n",
            "global_step/sec: 28.678\n",
            "loss = 0.024017219, step = 20600 (3.485 sec)\n",
            "global_step/sec: 29.9719\n",
            "loss = 0.022524657, step = 20700 (3.337 sec)\n",
            "Saving checkpoints for 20759 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:23:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-20759\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:23:03\n",
            "Saving dict for global step 20759: acc = 0.9700848, f1 = 0.9343818, global_step = 20759, loss = 0.04174023, precision = 0.9314998, recall = 0.9372818\n",
            "Saving 'checkpoint_path' summary for global step 20759: models/model.ckpt-20759\n",
            "global_step/sec: 15.1308\n",
            "loss = 0.027281499, step = 20800 (6.609 sec)\n",
            "global_step/sec: 27.6383\n",
            "loss = 0.016548358, step = 20900 (3.619 sec)\n",
            "global_step/sec: 28.9515\n",
            "loss = 0.020859474, step = 21000 (3.453 sec)\n",
            "global_step/sec: 31.2684\n",
            "loss = 0.030097533, step = 21100 (3.198 sec)\n",
            "global_step/sec: 32.0448\n",
            "loss = 0.034747858, step = 21200 (3.121 sec)\n",
            "global_step/sec: 35.3531\n",
            "loss = 0.015627757, step = 21300 (2.828 sec)\n",
            "global_step/sec: 30.7603\n",
            "loss = 0.015244587, step = 21400 (3.251 sec)\n",
            "global_step/sec: 29.8893\n",
            "loss = 0.031834364, step = 21500 (3.346 sec)\n",
            "global_step/sec: 28.6045\n",
            "loss = 0.016396096, step = 21600 (3.496 sec)\n",
            "global_step/sec: 28.3601\n",
            "loss = 0.011083602, step = 21700 (3.528 sec)\n",
            "global_step/sec: 29.6881\n",
            "loss = 0.03032297, step = 21800 (3.366 sec)\n",
            "global_step/sec: 29.5439\n",
            "loss = 0.010395959, step = 21900 (3.387 sec)\n",
            "global_step/sec: 30.7762\n",
            "loss = 0.036215525, step = 22000 (3.247 sec)\n",
            "global_step/sec: 30.6999\n",
            "loss = 0.030675134, step = 22100 (3.258 sec)\n",
            "global_step/sec: 28.8958\n",
            "loss = 0.019642213, step = 22200 (3.461 sec)\n",
            "global_step/sec: 30.4627\n",
            "loss = 0.017738268, step = 22300 (3.282 sec)\n",
            "global_step/sec: 30.4392\n",
            "loss = 0.016575782, step = 22400 (3.285 sec)\n",
            "Saving checkpoints for 22483 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:24:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-22483\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:24:03\n",
            "Saving dict for global step 22483: acc = 0.96910495, f1 = 0.9320936, global_step = 22483, loss = 0.04178744, precision = 0.9244467, recall = 0.9398681\n",
            "Saving 'checkpoint_path' summary for global step 22483: models/model.ckpt-22483\n",
            "global_step/sec: 16.1805\n",
            "loss = 0.025077756, step = 22500 (6.180 sec)\n",
            "global_step/sec: 29.9458\n",
            "loss = 0.01137724, step = 22600 (3.340 sec)\n",
            "global_step/sec: 29.6777\n",
            "loss = 0.012389234, step = 22700 (3.369 sec)\n",
            "global_step/sec: 28.8892\n",
            "loss = 0.043543313, step = 22800 (3.463 sec)\n",
            "global_step/sec: 30.9132\n",
            "loss = 0.021367593, step = 22900 (3.235 sec)\n",
            "global_step/sec: 30.0475\n",
            "loss = 0.021695903, step = 23000 (3.328 sec)\n",
            "global_step/sec: 29.0465\n",
            "loss = 0.01710543, step = 23100 (3.441 sec)\n",
            "global_step/sec: 30.0944\n",
            "loss = 0.015904788, step = 23200 (3.323 sec)\n",
            "global_step/sec: 31.6234\n",
            "loss = 0.030355873, step = 23300 (3.163 sec)\n",
            "global_step/sec: 29.1153\n",
            "loss = 0.016087225, step = 23400 (3.434 sec)\n",
            "global_step/sec: 27.9064\n",
            "loss = 0.038322248, step = 23500 (3.584 sec)\n",
            "global_step/sec: 28.539\n",
            "loss = 0.0307009, step = 23600 (3.503 sec)\n",
            "global_step/sec: 28.2665\n",
            "loss = 0.01922953, step = 23700 (3.538 sec)\n",
            "global_step/sec: 31.6597\n",
            "loss = 0.0152022615, step = 23800 (3.159 sec)\n",
            "global_step/sec: 32.865\n",
            "loss = 0.008113242, step = 23900 (3.042 sec)\n",
            "global_step/sec: 33.2082\n",
            "loss = 0.030999621, step = 24000 (3.012 sec)\n",
            "global_step/sec: 30.7405\n",
            "loss = 0.018145332, step = 24100 (3.253 sec)\n",
            "Saving checkpoints for 24195 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:25:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-24195\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:25:03\n",
            "Saving dict for global step 24195: acc = 0.9701248, f1 = 0.9346973, global_step = 24195, loss = 0.041392554, precision = 0.93008965, recall = 0.93935084\n",
            "Saving 'checkpoint_path' summary for global step 24195: models/model.ckpt-24195\n",
            "global_step/sec: 15.5469\n",
            "loss = 0.016594596, step = 24200 (6.432 sec)\n",
            "global_step/sec: 28.4986\n",
            "loss = 0.013539992, step = 24300 (3.509 sec)\n",
            "global_step/sec: 29.5779\n",
            "loss = 0.02622296, step = 24400 (3.382 sec)\n",
            "global_step/sec: 30.5074\n",
            "loss = 0.017738352, step = 24500 (3.279 sec)\n",
            "global_step/sec: 31.1218\n",
            "loss = 0.017407909, step = 24600 (3.211 sec)\n",
            "global_step/sec: 28.1033\n",
            "loss = 0.028404167, step = 24700 (3.559 sec)\n",
            "global_step/sec: 29.326\n",
            "loss = 0.0045392266, step = 24800 (3.409 sec)\n",
            "global_step/sec: 30.1281\n",
            "loss = 0.01937526, step = 24900 (3.320 sec)\n",
            "global_step/sec: 30.2948\n",
            "loss = 0.01569945, step = 25000 (3.301 sec)\n",
            "global_step/sec: 32.0382\n",
            "loss = 0.017593544, step = 25100 (3.121 sec)\n",
            "global_step/sec: 30.2986\n",
            "loss = 0.007997605, step = 25200 (3.301 sec)\n",
            "global_step/sec: 31.6906\n",
            "loss = 0.009153405, step = 25300 (3.155 sec)\n",
            "global_step/sec: 31.1351\n",
            "loss = 0.030699603, step = 25400 (3.213 sec)\n",
            "global_step/sec: 29.1402\n",
            "loss = 0.016348705, step = 25500 (3.432 sec)\n",
            "global_step/sec: 29.0375\n",
            "loss = 0.010942414, step = 25600 (3.444 sec)\n",
            "global_step/sec: 29.4507\n",
            "loss = 0.025351444, step = 25700 (3.395 sec)\n",
            "global_step/sec: 28.4064\n",
            "loss = 0.013081122, step = 25800 (3.521 sec)\n",
            "Saving checkpoints for 25898 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:26:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-25898\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:26:03\n",
            "Saving dict for global step 25898: acc = 0.968785, f1 = 0.9327537, global_step = 25898, loss = 0.043038722, precision = 0.9504698, recall = 0.915686\n",
            "Saving 'checkpoint_path' summary for global step 25898: models/model.ckpt-25898\n",
            "global_step/sec: 15.7684\n",
            "loss = 0.017922882, step = 25900 (6.342 sec)\n",
            "global_step/sec: 28.8811\n",
            "loss = 0.029306207, step = 26000 (3.462 sec)\n",
            "global_step/sec: 29.4158\n",
            "loss = 0.009765889, step = 26100 (3.400 sec)\n",
            "global_step/sec: 31.055\n",
            "loss = 0.017617662, step = 26200 (3.219 sec)\n",
            "global_step/sec: 29.8746\n",
            "loss = 0.022530578, step = 26300 (3.347 sec)\n",
            "global_step/sec: 30.0748\n",
            "loss = 0.015560012, step = 26400 (3.325 sec)\n",
            "global_step/sec: 30.3574\n",
            "loss = 0.005625619, step = 26500 (3.294 sec)\n",
            "global_step/sec: 33.4187\n",
            "loss = 0.026259549, step = 26600 (2.993 sec)\n",
            "global_step/sec: 30.1125\n",
            "loss = 0.014956976, step = 26700 (3.322 sec)\n",
            "global_step/sec: 31.4327\n",
            "loss = 0.0076624947, step = 26800 (3.180 sec)\n",
            "global_step/sec: 30.4198\n",
            "loss = 0.010232033, step = 26900 (3.288 sec)\n",
            "global_step/sec: 29.6169\n",
            "loss = 0.01109944, step = 27000 (3.379 sec)\n",
            "global_step/sec: 31.391\n",
            "loss = 0.03453396, step = 27100 (3.185 sec)\n",
            "global_step/sec: 30.0277\n",
            "loss = 0.009034067, step = 27200 (3.330 sec)\n",
            "global_step/sec: 31.0437\n",
            "loss = 0.0142003745, step = 27300 (3.221 sec)\n",
            "global_step/sec: 29.4395\n",
            "loss = 0.009521196, step = 27400 (3.397 sec)\n",
            "global_step/sec: 29.6649\n",
            "loss = 0.020907944, step = 27500 (3.371 sec)\n",
            "global_step/sec: 29.3997\n",
            "loss = 0.005864171, step = 27600 (3.401 sec)\n",
            "Saving checkpoints for 27622 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:27:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-27622\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:27:03\n",
            "Saving dict for global step 27622: acc = 0.9700848, f1 = 0.9354944, global_step = 27622, loss = 0.043078627, precision = 0.94180864, recall = 0.9292642\n",
            "Saving 'checkpoint_path' summary for global step 27622: models/model.ckpt-27622\n",
            "global_step/sec: 15.3534\n",
            "loss = 0.012616067, step = 27700 (6.513 sec)\n",
            "global_step/sec: 31.141\n",
            "loss = 0.006715544, step = 27800 (3.211 sec)\n",
            "global_step/sec: 30.4915\n",
            "loss = 0.021096092, step = 27900 (3.279 sec)\n",
            "global_step/sec: 29.5637\n",
            "loss = 0.0077834614, step = 28000 (3.383 sec)\n",
            "global_step/sec: 30.9475\n",
            "loss = 0.020301556, step = 28100 (3.231 sec)\n",
            "global_step/sec: 30.179\n",
            "loss = 0.018453535, step = 28200 (3.313 sec)\n",
            "global_step/sec: 30.5957\n",
            "loss = 0.011183367, step = 28300 (3.269 sec)\n",
            "global_step/sec: 29.7478\n",
            "loss = 0.021114187, step = 28400 (3.364 sec)\n",
            "global_step/sec: 30.4246\n",
            "loss = 0.016093466, step = 28500 (3.284 sec)\n",
            "global_step/sec: 30.3357\n",
            "loss = 0.03179884, step = 28600 (3.299 sec)\n",
            "global_step/sec: 28.6847\n",
            "loss = 0.016609738, step = 28700 (3.484 sec)\n",
            "global_step/sec: 29.5241\n",
            "loss = 0.013570921, step = 28800 (3.387 sec)\n",
            "global_step/sec: 29.967\n",
            "loss = 0.023791019, step = 28900 (3.337 sec)\n",
            "global_step/sec: 29.1137\n",
            "loss = 0.008945034, step = 29000 (3.434 sec)\n",
            "global_step/sec: 28.9054\n",
            "loss = 0.014323219, step = 29100 (3.460 sec)\n",
            "global_step/sec: 31.9568\n",
            "loss = 0.018746583, step = 29200 (3.129 sec)\n",
            "global_step/sec: 32.4639\n",
            "loss = 0.041515455, step = 29300 (3.081 sec)\n",
            "Saving checkpoints for 29340 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:28:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-29340\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:28:03\n",
            "Saving dict for global step 29340: acc = 0.9702048, f1 = 0.9349709, global_step = 29340, loss = 0.042693343, precision = 0.9347292, recall = 0.93521273\n",
            "Saving 'checkpoint_path' summary for global step 29340: models/model.ckpt-29340\n",
            "global_step/sec: 15.3757\n",
            "loss = 0.013707487, step = 29400 (6.504 sec)\n",
            "global_step/sec: 28.9725\n",
            "loss = 0.015590363, step = 29500 (3.452 sec)\n",
            "global_step/sec: 29.6739\n",
            "loss = 0.0064167404, step = 29600 (3.370 sec)\n",
            "global_step/sec: 28.8183\n",
            "loss = 0.014983145, step = 29700 (3.469 sec)\n",
            "global_step/sec: 30.5616\n",
            "loss = 0.011771707, step = 29800 (3.272 sec)\n",
            "global_step/sec: 31.0127\n",
            "loss = 0.020269051, step = 29900 (3.224 sec)\n",
            "global_step/sec: 29.4689\n",
            "loss = 0.013859666, step = 30000 (3.395 sec)\n",
            "global_step/sec: 29.2466\n",
            "loss = 0.01837678, step = 30100 (3.418 sec)\n",
            "global_step/sec: 28.7715\n",
            "loss = 0.014728151, step = 30200 (3.476 sec)\n",
            "global_step/sec: 29.8231\n",
            "loss = 0.0095603485, step = 30300 (3.353 sec)\n",
            "global_step/sec: 31.4356\n",
            "loss = 0.011620441, step = 30400 (3.182 sec)\n",
            "global_step/sec: 31.5782\n",
            "loss = 0.016112031, step = 30500 (3.166 sec)\n",
            "global_step/sec: 31.0039\n",
            "loss = 0.010714727, step = 30600 (3.225 sec)\n",
            "global_step/sec: 30.5516\n",
            "loss = 0.010847549, step = 30700 (3.273 sec)\n",
            "global_step/sec: 29.6787\n",
            "loss = 0.01134831, step = 30800 (3.371 sec)\n",
            "global_step/sec: 30.3314\n",
            "loss = 0.012243623, step = 30900 (3.295 sec)\n",
            "global_step/sec: 31.4452\n",
            "loss = 0.020029578, step = 31000 (3.181 sec)\n",
            "Saving checkpoints for 31050 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:29:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-31050\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:29:03\n",
            "Saving dict for global step 31050: acc = 0.97018474, f1 = 0.9355255, global_step = 31050, loss = 0.044645738, precision = 0.93287903, recall = 0.938187\n",
            "Saving 'checkpoint_path' summary for global step 31050: models/model.ckpt-31050\n",
            "global_step/sec: 15.2799\n",
            "loss = 0.016330285, step = 31100 (6.544 sec)\n",
            "global_step/sec: 29.9535\n",
            "loss = 0.013218831, step = 31200 (3.338 sec)\n",
            "global_step/sec: 30.9493\n",
            "loss = 0.009196757, step = 31300 (3.231 sec)\n",
            "global_step/sec: 30.2439\n",
            "loss = 0.03272892, step = 31400 (3.307 sec)\n",
            "global_step/sec: 30.5321\n",
            "loss = 0.008608868, step = 31500 (3.277 sec)\n",
            "global_step/sec: 30.4097\n",
            "loss = 0.025221359, step = 31600 (3.286 sec)\n",
            "global_step/sec: 29.4501\n",
            "loss = 0.013496365, step = 31700 (3.396 sec)\n",
            "global_step/sec: 30.8687\n",
            "loss = 0.033327762, step = 31800 (3.240 sec)\n",
            "global_step/sec: 33.1031\n",
            "loss = 0.009049243, step = 31900 (3.021 sec)\n",
            "global_step/sec: 33.1178\n",
            "loss = 0.021634247, step = 32000 (3.020 sec)\n",
            "global_step/sec: 29.049\n",
            "loss = 0.0057053543, step = 32100 (3.442 sec)\n",
            "global_step/sec: 30.7122\n",
            "loss = 0.017317224, step = 32200 (3.256 sec)\n",
            "global_step/sec: 29.5424\n",
            "loss = 0.012743857, step = 32300 (3.386 sec)\n",
            "global_step/sec: 29.1498\n",
            "loss = 0.013865213, step = 32400 (3.430 sec)\n",
            "global_step/sec: 29.8973\n",
            "loss = 0.01309324, step = 32500 (3.345 sec)\n",
            "global_step/sec: 30.8297\n",
            "loss = 0.021492459, step = 32600 (3.245 sec)\n",
            "global_step/sec: 29.8131\n",
            "loss = 0.011480714, step = 32700 (3.353 sec)\n",
            "Saving checkpoints for 32783 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:30:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-32783\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:30:03\n",
            "Saving dict for global step 32783: acc = 0.9698048, f1 = 0.9356173, global_step = 32783, loss = 0.045997385, precision = 0.93537545, recall = 0.9358593\n",
            "Saving 'checkpoint_path' summary for global step 32783: models/model.ckpt-32783\n",
            "global_step/sec: 15.6379\n",
            "loss = 0.01217747, step = 32800 (6.394 sec)\n",
            "global_step/sec: 31.9682\n",
            "loss = 0.009476327, step = 32900 (3.129 sec)\n",
            "global_step/sec: 31.1455\n",
            "loss = 0.008336013, step = 33000 (3.210 sec)\n",
            "global_step/sec: 33.2163\n",
            "loss = 0.006523206, step = 33100 (3.011 sec)\n",
            "global_step/sec: 31.5319\n",
            "loss = 0.015981063, step = 33200 (3.172 sec)\n",
            "global_step/sec: 30.23\n",
            "loss = 0.015430586, step = 33300 (3.307 sec)\n",
            "global_step/sec: 31.0674\n",
            "loss = 0.0058583575, step = 33400 (3.220 sec)\n",
            "global_step/sec: 30.0331\n",
            "loss = 0.012391958, step = 33500 (3.328 sec)\n",
            "global_step/sec: 29.7351\n",
            "loss = 0.014108835, step = 33600 (3.365 sec)\n",
            "global_step/sec: 28.8985\n",
            "loss = 0.012993939, step = 33700 (3.458 sec)\n",
            "global_step/sec: 27.7692\n",
            "loss = 0.012453152, step = 33800 (3.601 sec)\n",
            "global_step/sec: 28.4369\n",
            "loss = 0.010842745, step = 33900 (3.517 sec)\n",
            "global_step/sec: 29.1845\n",
            "loss = 0.02129731, step = 34000 (3.426 sec)\n",
            "global_step/sec: 29.7892\n",
            "loss = 0.010441666, step = 34100 (3.358 sec)\n",
            "global_step/sec: 30.752\n",
            "loss = 0.013966043, step = 34200 (3.252 sec)\n",
            "global_step/sec: 30.0563\n",
            "loss = 0.008116156, step = 34300 (3.327 sec)\n",
            "global_step/sec: 28.7646\n",
            "loss = 0.011862771, step = 34400 (3.478 sec)\n",
            "Saving checkpoints for 34493 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:31:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-34493\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:31:03\n",
            "Saving dict for global step 34493: acc = 0.968965, f1 = 0.9343674, global_step = 34493, loss = 0.04643177, precision = 0.9262931, recall = 0.94258374\n",
            "Saving 'checkpoint_path' summary for global step 34493: models/model.ckpt-34493\n",
            "global_step/sec: 15.4317\n",
            "loss = 0.010125305, step = 34500 (6.480 sec)\n",
            "global_step/sec: 32.9125\n",
            "loss = 0.0327838, step = 34600 (3.037 sec)\n",
            "global_step/sec: 33.2806\n",
            "loss = 0.012574783, step = 34700 (3.007 sec)\n",
            "global_step/sec: 31.1703\n",
            "loss = 0.0073467623, step = 34800 (3.207 sec)\n",
            "global_step/sec: 30.375\n",
            "loss = 0.007301972, step = 34900 (3.292 sec)\n",
            "global_step/sec: 28.3298\n",
            "loss = 0.010034935, step = 35000 (3.529 sec)\n",
            "global_step/sec: 31.3396\n",
            "loss = 0.013110052, step = 35100 (3.191 sec)\n",
            "global_step/sec: 31.3636\n",
            "loss = 0.011059909, step = 35200 (3.188 sec)\n",
            "global_step/sec: 30.1591\n",
            "loss = 0.0031557435, step = 35300 (3.316 sec)\n",
            "global_step/sec: 30.8772\n",
            "loss = 0.029753927, step = 35400 (3.239 sec)\n",
            "global_step/sec: 30.3121\n",
            "loss = 0.007799233, step = 35500 (3.299 sec)\n",
            "global_step/sec: 30.2941\n",
            "loss = 0.00756169, step = 35600 (3.301 sec)\n",
            "global_step/sec: 30.9714\n",
            "loss = 0.010735882, step = 35700 (3.229 sec)\n",
            "global_step/sec: 33.058\n",
            "loss = 0.011664287, step = 35800 (3.025 sec)\n",
            "global_step/sec: 30.7337\n",
            "loss = 0.0145684555, step = 35900 (3.254 sec)\n",
            "global_step/sec: 30.8619\n",
            "loss = 0.012608213, step = 36000 (3.241 sec)\n",
            "global_step/sec: 30.9852\n",
            "loss = 0.01766494, step = 36100 (3.228 sec)\n",
            "global_step/sec: 28.2174\n",
            "loss = 0.017802497, step = 36200 (3.542 sec)\n",
            "Saving checkpoints for 36243 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:32:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-36243\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:32:03\n",
            "Saving dict for global step 36243: acc = 0.9693049, f1 = 0.9343969, global_step = 36243, loss = 0.04945003, precision = 0.9223888, recall = 0.94672185\n",
            "Saving 'checkpoint_path' summary for global step 36243: models/model.ckpt-36243\n",
            "global_step/sec: 15.19\n",
            "loss = 0.013523495, step = 36300 (6.584 sec)\n",
            "global_step/sec: 30.857\n",
            "loss = 0.009810239, step = 36400 (3.241 sec)\n",
            "global_step/sec: 29.1039\n",
            "loss = 0.0134010315, step = 36500 (3.439 sec)\n",
            "global_step/sec: 28.3352\n",
            "loss = 0.013899304, step = 36600 (3.527 sec)\n",
            "global_step/sec: 30.1769\n",
            "loss = 0.011571258, step = 36700 (3.312 sec)\n",
            "global_step/sec: 29.3583\n",
            "loss = 0.014640021, step = 36800 (3.408 sec)\n",
            "global_step/sec: 29.0168\n",
            "loss = 0.013053752, step = 36900 (3.446 sec)\n",
            "global_step/sec: 28.1584\n",
            "loss = 0.011425338, step = 37000 (3.552 sec)\n",
            "global_step/sec: 29.6225\n",
            "loss = 0.010230053, step = 37100 (3.376 sec)\n",
            "global_step/sec: 33.0995\n",
            "loss = 0.00957033, step = 37200 (3.020 sec)\n",
            "global_step/sec: 32.6127\n",
            "loss = 0.017941503, step = 37300 (3.066 sec)\n",
            "global_step/sec: 33.8122\n",
            "loss = 0.0058275945, step = 37400 (2.960 sec)\n",
            "global_step/sec: 30.873\n",
            "loss = 0.0060056937, step = 37500 (3.237 sec)\n",
            "global_step/sec: 31.1117\n",
            "loss = 0.004784115, step = 37600 (3.215 sec)\n",
            "global_step/sec: 29.3224\n",
            "loss = 0.00548795, step = 37700 (3.410 sec)\n",
            "global_step/sec: 29.272\n",
            "loss = 0.0044527645, step = 37800 (3.417 sec)\n",
            "global_step/sec: 31.7786\n",
            "loss = 0.0042663077, step = 37900 (3.146 sec)\n",
            "Saving checkpoints for 37964 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:33:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-37964\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:33:03\n",
            "Saving dict for global step 37964: acc = 0.96906495, f1 = 0.93277746, global_step = 37964, loss = 0.050976824, precision = 0.93975586, recall = 0.92590195\n",
            "Saving 'checkpoint_path' summary for global step 37964: models/model.ckpt-37964\n",
            "global_step/sec: 15.17\n",
            "loss = 0.009627285, step = 38000 (6.592 sec)\n",
            "global_step/sec: 29.9915\n",
            "loss = 0.005292117, step = 38100 (3.334 sec)\n",
            "global_step/sec: 30.2559\n",
            "loss = 0.007611681, step = 38200 (3.305 sec)\n",
            "global_step/sec: 29.1656\n",
            "loss = 0.0064309845, step = 38300 (3.429 sec)\n",
            "global_step/sec: 31.3139\n",
            "loss = 0.008502985, step = 38400 (3.195 sec)\n",
            "global_step/sec: 33.3347\n",
            "loss = 0.008120672, step = 38500 (2.999 sec)\n",
            "global_step/sec: 30.4451\n",
            "loss = 0.021708542, step = 38600 (3.284 sec)\n",
            "global_step/sec: 31.1512\n",
            "loss = 0.008812689, step = 38700 (3.210 sec)\n",
            "global_step/sec: 30.2375\n",
            "loss = 0.008842949, step = 38800 (3.307 sec)\n",
            "global_step/sec: 31.5731\n",
            "loss = 0.013746271, step = 38900 (3.167 sec)\n",
            "global_step/sec: 30.3698\n",
            "loss = 0.0077081257, step = 39000 (3.295 sec)\n",
            "global_step/sec: 30.2073\n",
            "loss = 0.006524796, step = 39100 (3.309 sec)\n",
            "global_step/sec: 30.6524\n",
            "loss = 0.01265279, step = 39200 (3.262 sec)\n",
            "global_step/sec: 30.103\n",
            "loss = 0.0075418875, step = 39300 (3.322 sec)\n",
            "global_step/sec: 31.2497\n",
            "loss = 0.005294627, step = 39400 (3.201 sec)\n",
            "global_step/sec: 29.4421\n",
            "loss = 0.011846415, step = 39500 (3.395 sec)\n",
            "global_step/sec: 31.0245\n",
            "loss = 0.016736751, step = 39600 (3.223 sec)\n",
            "Saving checkpoints for 39699 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:34:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-39699\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:34:03\n",
            "Saving dict for global step 39699: acc = 0.96982485, f1 = 0.93525827, global_step = 39699, loss = 0.050621137, precision = 0.93647087, recall = 0.9340489\n",
            "Saving 'checkpoint_path' summary for global step 39699: models/model.ckpt-39699\n",
            "global_step/sec: 15.401\n",
            "loss = 0.009680317, step = 39700 (6.495 sec)\n",
            "global_step/sec: 30.4108\n",
            "loss = 0.011134163, step = 39800 (3.287 sec)\n",
            "global_step/sec: 32.7499\n",
            "loss = 0.010271197, step = 39900 (3.053 sec)\n",
            "global_step/sec: 34.118\n",
            "loss = 0.009213264, step = 40000 (2.932 sec)\n",
            "global_step/sec: 31.3341\n",
            "loss = 0.0063601523, step = 40100 (3.191 sec)\n",
            "global_step/sec: 31.8633\n",
            "loss = 0.0054922323, step = 40200 (3.138 sec)\n",
            "global_step/sec: 30.6152\n",
            "loss = 0.008325701, step = 40300 (3.266 sec)\n",
            "global_step/sec: 31.0321\n",
            "loss = 0.006978794, step = 40400 (3.223 sec)\n",
            "global_step/sec: 29.8512\n",
            "loss = 0.0055040857, step = 40500 (3.350 sec)\n",
            "global_step/sec: 32.1992\n",
            "loss = 0.0080988025, step = 40600 (3.108 sec)\n",
            "global_step/sec: 27.9634\n",
            "loss = 0.0032699346, step = 40700 (3.574 sec)\n",
            "global_step/sec: 30.1942\n",
            "loss = 0.022051895, step = 40800 (3.313 sec)\n",
            "global_step/sec: 28.7371\n",
            "loss = 0.0050076866, step = 40900 (3.479 sec)\n",
            "global_step/sec: 31.7465\n",
            "loss = 0.010964655, step = 41000 (3.150 sec)\n",
            "global_step/sec: 31.1792\n",
            "loss = 0.007305497, step = 41100 (3.207 sec)\n",
            "global_step/sec: 32.821\n",
            "loss = 0.013448967, step = 41200 (3.047 sec)\n",
            "global_step/sec: 31.0469\n",
            "loss = 0.0040313033, step = 41300 (3.221 sec)\n",
            "global_step/sec: 30.3431\n",
            "loss = 0.005093637, step = 41400 (3.295 sec)\n",
            "Saving checkpoints for 41462 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:35:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-41462\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:35:03\n",
            "Saving dict for global step 41462: acc = 0.9695049, f1 = 0.93554443, global_step = 41462, loss = 0.05278514, precision = 0.9373053, recall = 0.93379027\n",
            "Saving 'checkpoint_path' summary for global step 41462: models/model.ckpt-41462\n",
            "global_step/sec: 15.4894\n",
            "loss = 0.012105679, step = 41500 (6.457 sec)\n",
            "global_step/sec: 29.7278\n",
            "loss = 0.009190599, step = 41600 (3.363 sec)\n",
            "global_step/sec: 30.9034\n",
            "loss = 0.022278333, step = 41700 (3.236 sec)\n",
            "global_step/sec: 28.7622\n",
            "loss = 0.007315475, step = 41800 (3.477 sec)\n",
            "global_step/sec: 30.4795\n",
            "loss = 0.005900412, step = 41900 (3.281 sec)\n",
            "global_step/sec: 30.8083\n",
            "loss = 0.009862358, step = 42000 (3.246 sec)\n",
            "global_step/sec: 30.7813\n",
            "loss = 0.0051084617, step = 42100 (3.249 sec)\n",
            "global_step/sec: 30.4941\n",
            "loss = 0.009006073, step = 42200 (3.280 sec)\n",
            "global_step/sec: 29.8773\n",
            "loss = 0.003719846, step = 42300 (3.347 sec)\n",
            "global_step/sec: 29.1911\n",
            "loss = 0.0150219705, step = 42400 (3.425 sec)\n",
            "global_step/sec: 29.3556\n",
            "loss = 0.0029063837, step = 42500 (3.407 sec)\n",
            "global_step/sec: 33.9647\n",
            "loss = 0.00485076, step = 42600 (2.944 sec)\n",
            "global_step/sec: 33.4239\n",
            "loss = 0.0075223916, step = 42700 (2.992 sec)\n",
            "global_step/sec: 31.0753\n",
            "loss = 0.005337802, step = 42800 (3.218 sec)\n",
            "global_step/sec: 29.6068\n",
            "loss = 0.0014260069, step = 42900 (3.378 sec)\n",
            "global_step/sec: 30.5269\n",
            "loss = 0.0072721434, step = 43000 (3.275 sec)\n",
            "global_step/sec: 30.6116\n",
            "loss = 0.00753514, step = 43100 (3.267 sec)\n",
            "Saving checkpoints for 43199 into models/model.ckpt.\n",
            "Skip the current checkpoint eval due to throttle secs (60 secs).\n",
            "global_step/sec: 29.5939\n",
            "loss = 0.004687747, step = 43200 (3.380 sec)\n",
            "global_step/sec: 32.4416\n",
            "loss = 0.008452042, step = 43300 (3.081 sec)\n",
            "global_step/sec: 30.6727\n",
            "loss = 0.005357592, step = 43400 (3.260 sec)\n",
            "global_step/sec: 30.7129\n",
            "loss = 0.005259872, step = 43500 (3.256 sec)\n",
            "global_step/sec: 29.7862\n",
            "loss = 0.015144484, step = 43600 (3.358 sec)\n",
            "global_step/sec: 29.6547\n",
            "loss = 0.008296253, step = 43700 (3.371 sec)\n",
            "global_step/sec: 32.1655\n",
            "loss = 0.005213794, step = 43800 (3.109 sec)\n",
            "global_step/sec: 29.7649\n",
            "loss = 0.0063867616, step = 43900 (3.360 sec)\n",
            "global_step/sec: 32.4425\n",
            "loss = 0.006514827, step = 44000 (3.083 sec)\n",
            "global_step/sec: 32.2396\n",
            "loss = 0.016288493, step = 44100 (3.103 sec)\n",
            "global_step/sec: 28.3744\n",
            "loss = 0.011516628, step = 44200 (3.522 sec)\n",
            "global_step/sec: 29.9198\n",
            "loss = 0.009044886, step = 44300 (3.342 sec)\n",
            "global_step/sec: 31.2622\n",
            "loss = 0.008641986, step = 44400 (3.198 sec)\n",
            "global_step/sec: 29.5838\n",
            "loss = 0.022201892, step = 44500 (3.381 sec)\n",
            "global_step/sec: 30.0277\n",
            "loss = 0.012472978, step = 44600 (3.331 sec)\n",
            "global_step/sec: 28.945\n",
            "loss = 0.012032811, step = 44700 (3.457 sec)\n",
            "global_step/sec: 29.333\n",
            "loss = 0.0061377557, step = 44800 (3.406 sec)\n",
            "global_step/sec: 31.9585\n",
            "loss = 0.009678082, step = 44900 (3.130 sec)\n",
            "global_step/sec: 31.0708\n",
            "loss = 0.0067876023, step = 45000 (3.217 sec)\n",
            "Saving checkpoints for 45027 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:37:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-45027\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:37:03\n",
            "Saving dict for global step 45027: acc = 0.96906495, f1 = 0.9326059, global_step = 45027, loss = 0.057406187, precision = 0.92583156, recall = 0.9394801\n",
            "Saving 'checkpoint_path' summary for global step 45027: models/model.ckpt-45027\n",
            "global_step/sec: 15.391\n",
            "loss = 0.010418343, step = 45100 (6.500 sec)\n",
            "global_step/sec: 29.4909\n",
            "loss = 0.00763952, step = 45200 (3.389 sec)\n",
            "global_step/sec: 32.3745\n",
            "loss = 0.012693726, step = 45300 (3.089 sec)\n",
            "global_step/sec: 30.8372\n",
            "loss = 0.008450977, step = 45400 (3.242 sec)\n",
            "global_step/sec: 30.9331\n",
            "loss = 0.0070172353, step = 45500 (3.234 sec)\n",
            "global_step/sec: 27.8609\n",
            "loss = 0.003952885, step = 45600 (3.589 sec)\n",
            "global_step/sec: 28.813\n",
            "loss = 0.0047996696, step = 45700 (3.470 sec)\n",
            "global_step/sec: 30.9817\n",
            "loss = 0.0031898157, step = 45800 (3.229 sec)\n",
            "global_step/sec: 31.4419\n",
            "loss = 0.004603898, step = 45900 (3.182 sec)\n",
            "global_step/sec: 31.6655\n",
            "loss = 0.012252882, step = 46000 (3.156 sec)\n",
            "global_step/sec: 30.2582\n",
            "loss = 0.0047008875, step = 46100 (3.305 sec)\n",
            "global_step/sec: 30.8063\n",
            "loss = 0.0037047355, step = 46200 (3.246 sec)\n",
            "global_step/sec: 31.9233\n",
            "loss = 0.008857963, step = 46300 (3.134 sec)\n",
            "global_step/sec: 31.8096\n",
            "loss = 0.0074147144, step = 46400 (3.143 sec)\n",
            "global_step/sec: 32.213\n",
            "loss = 0.0029230278, step = 46500 (3.105 sec)\n",
            "global_step/sec: 31.5548\n",
            "loss = 0.0057956786, step = 46600 (3.170 sec)\n",
            "global_step/sec: 30.8994\n",
            "loss = 0.008276279, step = 46700 (3.234 sec)\n",
            "Saving checkpoints for 46778 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:38:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-46778\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:38:03\n",
            "Saving dict for global step 46778: acc = 0.968885, f1 = 0.93227553, global_step = 46778, loss = 0.060272947, precision = 0.92999613, recall = 0.93456614\n",
            "Saving 'checkpoint_path' summary for global step 46778: models/model.ckpt-46778\n",
            "global_step/sec: 15.3775\n",
            "loss = 0.0061491826, step = 46800 (6.504 sec)\n",
            "global_step/sec: 29.6671\n",
            "loss = 0.00336814, step = 46900 (3.370 sec)\n",
            "global_step/sec: 29.7869\n",
            "loss = 0.016615767, step = 47000 (3.357 sec)\n",
            "global_step/sec: 31.5149\n",
            "loss = 0.015651304, step = 47100 (3.174 sec)\n",
            "global_step/sec: 31.2991\n",
            "loss = 0.00529874, step = 47200 (3.194 sec)\n",
            "global_step/sec: 29.4325\n",
            "loss = 0.0052985223, step = 47300 (3.398 sec)\n",
            "global_step/sec: 30.5694\n",
            "loss = 0.001916565, step = 47400 (3.271 sec)\n",
            "global_step/sec: 29.102\n",
            "loss = 0.0029270074, step = 47500 (3.436 sec)\n",
            "global_step/sec: 29.8918\n",
            "loss = 0.012279463, step = 47600 (3.345 sec)\n",
            "global_step/sec: 29.6403\n",
            "loss = 0.008042496, step = 47700 (3.374 sec)\n",
            "global_step/sec: 31.3091\n",
            "loss = 0.012252352, step = 47800 (3.195 sec)\n",
            "global_step/sec: 31.9433\n",
            "loss = 0.008290927, step = 47900 (3.130 sec)\n",
            "global_step/sec: 35.322\n",
            "loss = 0.0042084157, step = 48000 (2.831 sec)\n",
            "global_step/sec: 31.2549\n",
            "loss = 0.004480754, step = 48100 (3.199 sec)\n",
            "global_step/sec: 30.2546\n",
            "loss = 0.0042388444, step = 48200 (3.307 sec)\n",
            "global_step/sec: 30.335\n",
            "loss = 0.0049447133, step = 48300 (3.295 sec)\n",
            "global_step/sec: 29.4012\n",
            "loss = 0.006500457, step = 48400 (3.400 sec)\n",
            "global_step/sec: 31.7628\n",
            "loss = 0.0037193734, step = 48500 (3.149 sec)\n",
            "Saving checkpoints for 48519 into models/model.ckpt.\n",
            "Skip the current checkpoint eval due to throttle secs (60 secs).\n",
            "global_step/sec: 30.4767\n",
            "loss = 0.0049965926, step = 48600 (3.281 sec)\n",
            "global_step/sec: 29.6587\n",
            "loss = 0.0054808264, step = 48700 (3.372 sec)\n",
            "global_step/sec: 30.3655\n",
            "loss = 0.006295644, step = 48800 (3.294 sec)\n",
            "global_step/sec: 29.6999\n",
            "loss = 0.006062718, step = 48900 (3.366 sec)\n",
            "global_step/sec: 30.7497\n",
            "loss = 0.0019448762, step = 49000 (3.252 sec)\n",
            "global_step/sec: 32.0478\n",
            "loss = 0.010541656, step = 49100 (3.122 sec)\n",
            "global_step/sec: 32.5636\n",
            "loss = 0.0067573106, step = 49200 (3.070 sec)\n",
            "global_step/sec: 31.2876\n",
            "loss = 0.0051561603, step = 49300 (3.197 sec)\n",
            "global_step/sec: 31.9905\n",
            "loss = 0.01127878, step = 49400 (3.126 sec)\n",
            "global_step/sec: 29.0709\n",
            "loss = 0.007114473, step = 49500 (3.439 sec)\n",
            "global_step/sec: 30.5847\n",
            "loss = 0.0049580694, step = 49600 (3.269 sec)\n",
            "global_step/sec: 32.2746\n",
            "loss = 0.004584158, step = 49700 (3.098 sec)\n",
            "global_step/sec: 28.5326\n",
            "loss = 0.0041874987, step = 49800 (3.506 sec)\n",
            "global_step/sec: 30.3573\n",
            "loss = 0.008417604, step = 49900 (3.294 sec)\n",
            "global_step/sec: 29.3043\n",
            "loss = 0.005801701, step = 50000 (3.413 sec)\n",
            "global_step/sec: 31.2264\n",
            "loss = 0.006234358, step = 50100 (3.202 sec)\n",
            "global_step/sec: 30.2404\n",
            "loss = 0.0046794266, step = 50200 (3.307 sec)\n",
            "global_step/sec: 30.8577\n",
            "loss = 0.007698653, step = 50300 (3.241 sec)\n",
            "Saving checkpoints for 50349 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:40:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-50349\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:40:03\n",
            "Saving dict for global step 50349: acc = 0.9692849, f1 = 0.93341094, global_step = 50349, loss = 0.05959381, precision = 0.93329024, recall = 0.93353164\n",
            "Saving 'checkpoint_path' summary for global step 50349: models/model.ckpt-50349\n",
            "global_step/sec: 14.9566\n",
            "loss = 0.0038459394, step = 50400 (6.687 sec)\n",
            "global_step/sec: 32.358\n",
            "loss = 0.0057111816, step = 50500 (3.090 sec)\n",
            "global_step/sec: 33.4591\n",
            "loss = 0.012242787, step = 50600 (2.989 sec)\n",
            "global_step/sec: 32.1952\n",
            "loss = 0.009419658, step = 50700 (3.106 sec)\n",
            "global_step/sec: 30.7592\n",
            "loss = 0.0058641355, step = 50800 (3.250 sec)\n",
            "global_step/sec: 31.3316\n",
            "loss = 0.006146195, step = 50900 (3.192 sec)\n",
            "global_step/sec: 30.2712\n",
            "loss = 0.0015254202, step = 51000 (3.303 sec)\n",
            "global_step/sec: 31.4402\n",
            "loss = 0.002985727, step = 51100 (3.182 sec)\n",
            "global_step/sec: 30.9987\n",
            "loss = 0.0015686067, step = 51200 (3.225 sec)\n",
            "global_step/sec: 31.625\n",
            "loss = 0.009184341, step = 51300 (3.163 sec)\n",
            "global_step/sec: 30.0257\n",
            "loss = 0.0053561204, step = 51400 (3.330 sec)\n",
            "global_step/sec: 31.3093\n",
            "loss = 0.010800964, step = 51500 (3.194 sec)\n",
            "global_step/sec: 29.948\n",
            "loss = 0.0086809965, step = 51600 (3.339 sec)\n",
            "global_step/sec: 31.4782\n",
            "loss = 0.0020328707, step = 51700 (3.178 sec)\n",
            "global_step/sec: 31.4801\n",
            "loss = 0.005787322, step = 51800 (3.175 sec)\n",
            "global_step/sec: 32.06\n",
            "loss = 0.008230183, step = 51900 (3.119 sec)\n",
            "global_step/sec: 29.9402\n",
            "loss = 0.001965701, step = 52000 (3.345 sec)\n",
            "global_step/sec: 32.8436\n",
            "loss = 0.0042513655, step = 52100 (3.041 sec)\n",
            "Saving checkpoints for 52123 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:41:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-52123\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:41:04\n",
            "Saving dict for global step 52123: acc = 0.9692849, f1 = 0.9328498, global_step = 52123, loss = 0.06236329, precision = 0.93424124, recall = 0.9314626\n",
            "Saving 'checkpoint_path' summary for global step 52123: models/model.ckpt-52123\n",
            "global_step/sec: 14.7636\n",
            "loss = 0.0050549237, step = 52200 (6.773 sec)\n",
            "global_step/sec: 31.4126\n",
            "loss = 0.0018289504, step = 52300 (3.183 sec)\n",
            "global_step/sec: 30.1808\n",
            "loss = 0.0024919384, step = 52400 (3.315 sec)\n",
            "global_step/sec: 30.1867\n",
            "loss = 0.01077006, step = 52500 (3.311 sec)\n",
            "global_step/sec: 29.095\n",
            "loss = 0.01034762, step = 52600 (3.437 sec)\n",
            "global_step/sec: 31.075\n",
            "loss = 0.0050980295, step = 52700 (3.217 sec)\n",
            "global_step/sec: 29.2161\n",
            "loss = 0.009076382, step = 52800 (3.424 sec)\n",
            "global_step/sec: 30.062\n",
            "loss = 0.008418308, step = 52900 (3.326 sec)\n",
            "global_step/sec: 30.2766\n",
            "loss = 0.0048272023, step = 53000 (3.303 sec)\n",
            "global_step/sec: 29.0586\n",
            "loss = 0.0021638854, step = 53100 (3.443 sec)\n",
            "global_step/sec: 31.251\n",
            "loss = 0.0129182255, step = 53200 (3.199 sec)\n",
            "global_step/sec: 32.41\n",
            "loss = 0.0018449019, step = 53300 (3.087 sec)\n",
            "global_step/sec: 32.9652\n",
            "loss = 0.0019057633, step = 53400 (3.032 sec)\n",
            "global_step/sec: 31.4488\n",
            "loss = 0.009922263, step = 53500 (3.181 sec)\n",
            "global_step/sec: 30.1276\n",
            "loss = 0.00437128, step = 53600 (3.318 sec)\n",
            "global_step/sec: 30.6288\n",
            "loss = 0.0038936825, step = 53700 (3.265 sec)\n",
            "global_step/sec: 30.0031\n",
            "loss = 0.006616351, step = 53800 (3.334 sec)\n",
            "Saving checkpoints for 53853 into models/model.ckpt.\n",
            "Skip the current checkpoint eval due to throttle secs (60 secs).\n",
            "global_step/sec: 30.9592\n",
            "loss = 0.01098563, step = 53900 (3.229 sec)\n",
            "global_step/sec: 32.008\n",
            "loss = 0.0096367225, step = 54000 (3.124 sec)\n",
            "global_step/sec: 29.7026\n",
            "loss = 0.0027332657, step = 54100 (3.368 sec)\n",
            "global_step/sec: 30.4354\n",
            "loss = 0.007060519, step = 54200 (3.284 sec)\n",
            "global_step/sec: 31.6245\n",
            "loss = 0.003700031, step = 54300 (3.162 sec)\n",
            "global_step/sec: 30.1336\n",
            "loss = 0.0024666095, step = 54400 (3.319 sec)\n",
            "global_step/sec: 30.2517\n",
            "loss = 0.0041351253, step = 54500 (3.306 sec)\n",
            "global_step/sec: 30.7474\n",
            "loss = 0.00825727, step = 54600 (3.253 sec)\n",
            "global_step/sec: 30.5521\n",
            "loss = 0.004453885, step = 54700 (3.272 sec)\n",
            "global_step/sec: 30.6498\n",
            "loss = 0.0073125255, step = 54800 (3.262 sec)\n",
            "global_step/sec: 30.6719\n",
            "loss = 0.013817723, step = 54900 (3.261 sec)\n",
            "global_step/sec: 29.5616\n",
            "loss = 0.009429082, step = 55000 (3.383 sec)\n",
            "global_step/sec: 29.9673\n",
            "loss = 0.006350763, step = 55100 (3.337 sec)\n",
            "global_step/sec: 28.2013\n",
            "loss = 0.002051186, step = 55200 (3.545 sec)\n",
            "global_step/sec: 30.5394\n",
            "loss = 0.011644021, step = 55300 (3.274 sec)\n",
            "global_step/sec: 30.5942\n",
            "loss = 0.0027316173, step = 55400 (3.268 sec)\n",
            "global_step/sec: 30.0416\n",
            "loss = 0.0030522004, step = 55500 (3.329 sec)\n",
            "global_step/sec: 30.4299\n",
            "loss = 0.006951999, step = 55600 (3.287 sec)\n",
            "Saving checkpoints for 55678 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:43:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-55678\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:43:03\n",
            "Saving dict for global step 55678: acc = 0.9682451, f1 = 0.9319473, global_step = 55678, loss = 0.0658474, precision = 0.9306254, recall = 0.93327296\n",
            "Saving 'checkpoint_path' summary for global step 55678: models/model.ckpt-55678\n",
            "global_step/sec: 15.9581\n",
            "loss = 0.007809871, step = 55700 (6.265 sec)\n",
            "global_step/sec: 29.3429\n",
            "loss = 0.007838386, step = 55800 (3.408 sec)\n",
            "global_step/sec: 31.5313\n",
            "loss = 0.005623575, step = 55900 (3.172 sec)\n",
            "global_step/sec: 34.2215\n",
            "loss = 0.0014556616, step = 56000 (2.922 sec)\n",
            "global_step/sec: 31.7799\n",
            "loss = 0.006787912, step = 56100 (3.147 sec)\n",
            "global_step/sec: 29.0635\n",
            "loss = 0.0046604224, step = 56200 (3.441 sec)\n",
            "global_step/sec: 31.1102\n",
            "loss = 0.0041665486, step = 56300 (3.214 sec)\n",
            "global_step/sec: 29.3265\n",
            "loss = 0.0013167358, step = 56400 (3.410 sec)\n",
            "global_step/sec: 31.1041\n",
            "loss = 0.0033966997, step = 56500 (3.215 sec)\n",
            "global_step/sec: 30.4374\n",
            "loss = 0.0022702012, step = 56600 (3.285 sec)\n",
            "global_step/sec: 31.6742\n",
            "loss = 0.0040363627, step = 56700 (3.158 sec)\n",
            "global_step/sec: 29.6047\n",
            "loss = 0.0025850888, step = 56800 (3.380 sec)\n",
            "global_step/sec: 31.8272\n",
            "loss = 0.0044544064, step = 56900 (3.140 sec)\n",
            "global_step/sec: 30.4039\n",
            "loss = 0.0074072485, step = 57000 (3.289 sec)\n",
            "global_step/sec: 31.2876\n",
            "loss = 0.0049299723, step = 57100 (3.196 sec)\n",
            "global_step/sec: 32.909\n",
            "loss = 0.003151401, step = 57200 (3.040 sec)\n",
            "global_step/sec: 31.9165\n",
            "loss = 0.0016949741, step = 57300 (3.131 sec)\n",
            "global_step/sec: 33.7974\n",
            "loss = 0.004840998, step = 57400 (2.959 sec)\n",
            "Saving checkpoints for 57451 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:44:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-57451\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:44:03\n",
            "Saving dict for global step 57451: acc = 0.9679651, f1 = 0.9322977, global_step = 57451, loss = 0.06959835, precision = 0.9332642, recall = 0.93133324\n",
            "Saving 'checkpoint_path' summary for global step 57451: models/model.ckpt-57451\n",
            "global_step/sec: 15.0847\n",
            "loss = 0.0017230727, step = 57500 (6.629 sec)\n",
            "global_step/sec: 30.2452\n",
            "loss = 0.0022241496, step = 57600 (3.307 sec)\n",
            "global_step/sec: 32.6659\n",
            "loss = 0.003026422, step = 57700 (3.061 sec)\n",
            "global_step/sec: 28.543\n",
            "loss = 0.00830549, step = 57800 (3.504 sec)\n",
            "global_step/sec: 29.1274\n",
            "loss = 0.005141469, step = 57900 (3.432 sec)\n",
            "global_step/sec: 31.2301\n",
            "loss = 0.0040211384, step = 58000 (3.203 sec)\n",
            "global_step/sec: 30.7154\n",
            "loss = 0.007830681, step = 58100 (3.255 sec)\n",
            "global_step/sec: 30.5386\n",
            "loss = 0.007365398, step = 58200 (3.275 sec)\n",
            "global_step/sec: 30.6932\n",
            "loss = 0.004465394, step = 58300 (3.257 sec)\n",
            "global_step/sec: 30.0617\n",
            "loss = 0.007484253, step = 58400 (3.329 sec)\n",
            "global_step/sec: 29.7286\n",
            "loss = 0.002691534, step = 58500 (3.362 sec)\n",
            "global_step/sec: 34.1585\n",
            "loss = 0.0034917437, step = 58600 (2.927 sec)\n",
            "global_step/sec: 33.7298\n",
            "loss = 0.0020615733, step = 58700 (2.965 sec)\n",
            "global_step/sec: 35.1434\n",
            "loss = 0.0017595178, step = 58800 (2.845 sec)\n",
            "global_step/sec: 46.1117\n",
            "loss = 0.0013465749, step = 58900 (2.168 sec)\n",
            "global_step/sec: 40.5185\n",
            "loss = 0.0061843274, step = 59000 (2.468 sec)\n",
            "global_step/sec: 41.9919\n",
            "loss = 0.0039477856, step = 59100 (2.383 sec)\n",
            "global_step/sec: 42.2335\n",
            "loss = 0.0018692809, step = 59200 (2.367 sec)\n",
            "global_step/sec: 43.4551\n",
            "loss = 0.00929958, step = 59300 (2.301 sec)\n",
            "Saving checkpoints for 59371 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:45:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-59371\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:45:03\n",
            "Saving dict for global step 59371: acc = 0.968905, f1 = 0.93354964, global_step = 59371, loss = 0.07242294, precision = 0.93695456, recall = 0.9301694\n",
            "Saving 'checkpoint_path' summary for global step 59371: models/model.ckpt-59371\n",
            "global_step/sec: 18.0095\n",
            "loss = 0.0022445116, step = 59400 (5.553 sec)\n",
            "global_step/sec: 41.3778\n",
            "loss = 0.0024659026, step = 59500 (2.416 sec)\n",
            "global_step/sec: 42.5891\n",
            "loss = 0.0055170953, step = 59600 (2.350 sec)\n",
            "global_step/sec: 40.7607\n",
            "loss = 0.0103867445, step = 59700 (2.451 sec)\n",
            "global_step/sec: 45.2315\n",
            "loss = 0.0036417872, step = 59800 (2.211 sec)\n",
            "global_step/sec: 41.8933\n",
            "loss = 0.008045732, step = 59900 (2.387 sec)\n",
            "global_step/sec: 39.8591\n",
            "loss = 0.0026709011, step = 60000 (2.509 sec)\n",
            "global_step/sec: 41.0376\n",
            "loss = 0.0024331647, step = 60100 (2.438 sec)\n",
            "global_step/sec: 42.0918\n",
            "loss = 0.0020236943, step = 60200 (2.377 sec)\n",
            "global_step/sec: 45.0428\n",
            "loss = 0.0044482504, step = 60300 (2.218 sec)\n",
            "global_step/sec: 42.6552\n",
            "loss = 0.0026388678, step = 60400 (2.345 sec)\n",
            "global_step/sec: 41.0513\n",
            "loss = 0.0039539714, step = 60500 (2.440 sec)\n",
            "global_step/sec: 37.2052\n",
            "loss = 0.0057039387, step = 60600 (2.683 sec)\n",
            "global_step/sec: 44.4199\n",
            "loss = 0.011199411, step = 60700 (2.251 sec)\n",
            "global_step/sec: 41.911\n",
            "loss = 0.0018022949, step = 60800 (2.387 sec)\n",
            "global_step/sec: 41.4875\n",
            "loss = 0.0036791041, step = 60900 (2.411 sec)\n",
            "global_step/sec: 41.0552\n",
            "loss = 0.0036949073, step = 61000 (2.435 sec)\n",
            "global_step/sec: 42.6482\n",
            "loss = 0.009435324, step = 61100 (2.344 sec)\n",
            "global_step/sec: 40.6795\n",
            "loss = 0.0012735021, step = 61200 (2.460 sec)\n",
            "global_step/sec: 43.2155\n",
            "loss = 0.0012104905, step = 61300 (2.312 sec)\n",
            "global_step/sec: 41.2449\n",
            "loss = 0.006837813, step = 61400 (2.425 sec)\n",
            "global_step/sec: 41.2968\n",
            "loss = 0.0020320204, step = 61500 (2.421 sec)\n",
            "global_step/sec: 43.5253\n",
            "loss = 0.0013696048, step = 61600 (2.298 sec)\n",
            "global_step/sec: 42.2005\n",
            "loss = 0.0031224436, step = 61700 (2.371 sec)\n",
            "Saving checkpoints for 61751 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:46:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-61751\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:46:03\n",
            "Saving dict for global step 61751: acc = 0.9694249, f1 = 0.9344168, global_step = 61751, loss = 0.07050952, precision = 0.93195266, recall = 0.9368938\n",
            "Saving 'checkpoint_path' summary for global step 61751: models/model.ckpt-61751\n",
            "global_step/sec: 18.1955\n",
            "loss = 0.0016963205, step = 61800 (5.494 sec)\n",
            "global_step/sec: 39.7219\n",
            "loss = 0.0037918978, step = 61900 (2.517 sec)\n",
            "global_step/sec: 40.4852\n",
            "loss = 0.0015167423, step = 62000 (2.470 sec)\n",
            "global_step/sec: 44.6881\n",
            "loss = 0.0043838453, step = 62100 (2.237 sec)\n",
            "global_step/sec: 40.2556\n",
            "loss = 0.0031855318, step = 62200 (2.484 sec)\n",
            "global_step/sec: 44.7072\n",
            "loss = 0.0018610308, step = 62300 (2.239 sec)\n",
            "global_step/sec: 41.616\n",
            "loss = 0.0019822854, step = 62400 (2.403 sec)\n",
            "global_step/sec: 40.9847\n",
            "loss = 0.0031000872, step = 62500 (2.439 sec)\n",
            "global_step/sec: 42.8357\n",
            "loss = 0.0036710172, step = 62600 (2.333 sec)\n",
            "global_step/sec: 42.0201\n",
            "loss = 0.0030267911, step = 62700 (2.381 sec)\n",
            "global_step/sec: 41.4737\n",
            "loss = 0.0016324682, step = 62800 (2.411 sec)\n",
            "global_step/sec: 40.9881\n",
            "loss = 0.010493365, step = 62900 (2.439 sec)\n",
            "global_step/sec: 41.6592\n",
            "loss = 0.0010544633, step = 63000 (2.401 sec)\n",
            "global_step/sec: 39.6211\n",
            "loss = 0.0030449955, step = 63100 (2.524 sec)\n",
            "global_step/sec: 43.0931\n",
            "loss = 0.007298366, step = 63200 (2.320 sec)\n",
            "global_step/sec: 41.8464\n",
            "loss = 0.0004427154, step = 63300 (2.389 sec)\n",
            "global_step/sec: 38.9712\n",
            "loss = 0.00735927, step = 63400 (2.567 sec)\n",
            "global_step/sec: 41.5635\n",
            "loss = 0.0020507849, step = 63500 (2.406 sec)\n",
            "global_step/sec: 41.8807\n",
            "loss = 0.008191165, step = 63600 (2.389 sec)\n",
            "global_step/sec: 41.218\n",
            "loss = 0.0024741576, step = 63700 (2.425 sec)\n",
            "global_step/sec: 44.0584\n",
            "loss = 0.0045554475, step = 63800 (2.268 sec)\n",
            "global_step/sec: 44.9348\n",
            "loss = 0.008046118, step = 63900 (2.225 sec)\n",
            "global_step/sec: 43.0986\n",
            "loss = 0.0014062875, step = 64000 (2.323 sec)\n",
            "global_step/sec: 38.9877\n",
            "loss = 0.0032557778, step = 64100 (2.563 sec)\n",
            "Saving checkpoints for 64122 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:47:01Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-64122\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:47:03\n",
            "Saving dict for global step 64122: acc = 0.96982485, f1 = 0.93571246, global_step = 64122, loss = 0.07167908, precision = 0.9322295, recall = 0.9392215\n",
            "Saving 'checkpoint_path' summary for global step 64122: models/model.ckpt-64122\n",
            "global_step/sec: 18.041\n",
            "loss = 0.0008660076, step = 64200 (5.543 sec)\n",
            "global_step/sec: 41.9463\n",
            "loss = 0.004082938, step = 64300 (2.384 sec)\n",
            "global_step/sec: 39.7948\n",
            "loss = 0.0026529646, step = 64400 (2.514 sec)\n",
            "global_step/sec: 44.0056\n",
            "loss = 0.0018666711, step = 64500 (2.271 sec)\n",
            "global_step/sec: 44.7302\n",
            "loss = 0.007258724, step = 64600 (2.235 sec)\n",
            "global_step/sec: 40.8324\n",
            "loss = 0.0017114596, step = 64700 (2.451 sec)\n",
            "global_step/sec: 45.2481\n",
            "loss = 0.0010436301, step = 64800 (2.208 sec)\n",
            "global_step/sec: 41.4054\n",
            "loss = 0.0048563504, step = 64900 (2.416 sec)\n",
            "global_step/sec: 43.3612\n",
            "loss = 0.0029973218, step = 65000 (2.305 sec)\n",
            "global_step/sec: 42.8214\n",
            "loss = 0.0031094581, step = 65100 (2.335 sec)\n",
            "global_step/sec: 43.3844\n",
            "loss = 0.0027650709, step = 65200 (2.305 sec)\n",
            "global_step/sec: 42.4573\n",
            "loss = 0.0026557883, step = 65300 (2.356 sec)\n",
            "global_step/sec: 42.0558\n",
            "loss = 0.0023684972, step = 65400 (2.377 sec)\n",
            "global_step/sec: 41.6959\n",
            "loss = 0.0071916105, step = 65500 (2.399 sec)\n",
            "global_step/sec: 41.1689\n",
            "loss = 0.0011877314, step = 65600 (2.429 sec)\n",
            "global_step/sec: 39.142\n",
            "loss = 0.0032154883, step = 65700 (2.554 sec)\n",
            "global_step/sec: 39.6478\n",
            "loss = 0.0021383383, step = 65800 (2.522 sec)\n",
            "global_step/sec: 40.4383\n",
            "loss = 0.0012102828, step = 65900 (2.474 sec)\n",
            "global_step/sec: 44.1815\n",
            "loss = 0.004437923, step = 66000 (2.262 sec)\n",
            "global_step/sec: 43.0018\n",
            "loss = 0.0005700635, step = 66100 (2.326 sec)\n",
            "global_step/sec: 41.1992\n",
            "loss = 0.0021623985, step = 66200 (2.427 sec)\n",
            "global_step/sec: 42.02\n",
            "loss = 0.008056955, step = 66300 (2.380 sec)\n",
            "global_step/sec: 39.0579\n",
            "loss = 0.00071492326, step = 66400 (2.560 sec)\n",
            "global_step/sec: 41.8785\n",
            "loss = 0.0028389955, step = 66500 (2.391 sec)\n",
            "Saving checkpoints for 66508 into models/model.ckpt.\n",
            "Skip the current checkpoint eval due to throttle secs (60 secs).\n",
            "global_step/sec: 39.7147\n",
            "loss = 0.00398373, step = 66600 (2.515 sec)\n",
            "global_step/sec: 39.9285\n",
            "loss = 0.0025631005, step = 66700 (2.505 sec)\n",
            "Saving checkpoints for 66766 into models/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2022-04-13T14:48:07Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from models/model.ckpt-66766\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Evaluation [20/100]\n",
            "Evaluation [30/100]\n",
            "Evaluation [40/100]\n",
            "Evaluation [50/100]\n",
            "Evaluation [60/100]\n",
            "Evaluation [70/100]\n",
            "Evaluation [80/100]\n",
            "Evaluation [90/100]\n",
            "Evaluation [100/100]\n",
            "Finished evaluation at 2022-04-13-14:48:10\n",
            "Saving dict for global step 66766: acc = 0.9696249, f1 = 0.9348192, global_step = 66766, loss = 0.07144306, precision = 0.93676144, recall = 0.93288505\n",
            "Saving 'checkpoint_path' summary for global step 66766: models/model.ckpt-66766\n",
            "Loss for final step: 0.007730644.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Sj1ipmAkADqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}