{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ezafe_blstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be0a60c81f894a98987181ea6d8095cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a72ef3d68f644a63b7fb989d88e3c3d2",
              "IPY_MODEL_cb12d94ff36f4b6c9d62257246828e04",
              "IPY_MODEL_1160a2a5baab449fae76eb29afde9ccc"
            ],
            "layout": "IPY_MODEL_c32b0158f28b4e5c8225f8edc5ec18b2"
          }
        },
        "a72ef3d68f644a63b7fb989d88e3c3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea7e81567824fc3b057b4f3f35f8b31",
            "placeholder": "​",
            "style": "IPY_MODEL_821a97809f8c4c7595aecd31ce8747a0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
          }
        },
        "cb12d94ff36f4b6c9d62257246828e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318bbd3392b44a499f4caf5a8b7d741a",
            "max": 24459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffa20969f94e4738b148e157dff44704",
            "value": 24459
          }
        },
        "1160a2a5baab449fae76eb29afde9ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601034ae625f4e43892e96a1a93d152d",
            "placeholder": "​",
            "style": "IPY_MODEL_7c0a5c5146f84fbd8804ae2caa2d8001",
            "value": " 142k/? [00:00&lt;00:00, 4.63MB/s]"
          }
        },
        "c32b0158f28b4e5c8225f8edc5ec18b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea7e81567824fc3b057b4f3f35f8b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821a97809f8c4c7595aecd31ce8747a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "318bbd3392b44a499f4caf5a8b7d741a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa20969f94e4738b148e157dff44704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "601034ae625f4e43892e96a1a93d152d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0a5c5146f84fbd8804ae2caa2d8001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c065435e23d946f5ba9eb80c22750488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b05314fd88641b58dbe635e3c751a53",
              "IPY_MODEL_40ad4cfa05784792b37bdac15c4b08ef",
              "IPY_MODEL_e591f53774ad44c2b78c5aa8bf82d832"
            ],
            "layout": "IPY_MODEL_b1bad41310ed420ca2df8e6064786c52"
          }
        },
        "1b05314fd88641b58dbe635e3c751a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ddd1660ea95406281382648693ade40",
            "placeholder": "​",
            "style": "IPY_MODEL_a4938d2b0c7b47e5b841b1acf68358ab",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.3.0/models/default.zip: 100%"
          }
        },
        "40ad4cfa05784792b37bdac15c4b08ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a800787bdc3647b7aae3a5e110248388",
            "max": 210965214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94161024a65d4226bd898eda9b6bb222",
            "value": 210965214
          }
        },
        "e591f53774ad44c2b78c5aa8bf82d832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafa789a1ccd4e3395d4200a4fccd90e",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd689492a8947f58bd89b2379550d44",
            "value": " 211M/211M [00:06&lt;00:00, 42.0MB/s]"
          }
        },
        "b1bad41310ed420ca2df8e6064786c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ddd1660ea95406281382648693ade40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4938d2b0c7b47e5b841b1acf68358ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a800787bdc3647b7aae3a5e110248388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94161024a65d4226bd898eda9b6bb222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dafa789a1ccd4e3395d4200a4fccd90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd689492a8947f58bd89b2379550d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VcXqIsFR4kjb",
        "outputId": "efa972e1-a4c4-423d-a107-9f83f211aeec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHI_vtGDuKt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df648847-195a-4e36-af77-389e9196a3d1"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.15\n",
        "\n",
        "!pip install git+https://github.com/guillaumegenthial/tf_metrics.git\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.8.0\n",
            "Collecting tensorflow-gpu==1.15\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.21.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.44.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.0.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 75.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=7efc94725f0f2e2f8d2061587f5b361398b900c3c6528068500fa8d486e495bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Collecting git+https://github.com/guillaumegenthial/tf_metrics.git\n",
            "  Cloning https://github.com/guillaumegenthial/tf_metrics.git to /tmp/pip-req-build-soqru3ol\n",
            "  Running command git clone -q https://github.com/guillaumegenthial/tf_metrics.git /tmp/pip-req-build-soqru3ol\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tf-metrics==0.0.1) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-gpu>=1.6 in /usr/local/lib/python3.7/dist-packages (from tf-metrics==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.44.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu>=1.6->tf-metrics==0.0.1) (1.5.2)\n",
            "Building wheels for collected packages: tf-metrics\n",
            "  Building wheel for tf-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-metrics: filename=tf_metrics-0.0.1-py3-none-any.whl size=7704 sha256=9bb48cfb73f9d31b86489caaef3288768ff11f5d5cece5d22f137c695de6831b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zvhao1hh/wheels/cd/99/60/5a21f2d1b0d0ce16599235e678a1687791243b7752abfb61cd\n",
            "Successfully built tf-metrics\n",
            "Installing collected packages: tf-metrics\n",
            "Successfully installed tf-metrics-0.0.1\n",
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "l6Uf-8u27dnb",
        "outputId": "bfee6e03-6415-4b89-bca4-de993cd47d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[K     |████████████████████████████████| 432 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.63.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.5)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 74.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=0f5bc5167eaa0422e57af6323a49595088f87221eb15102db77bf2905018e56e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.download('fa')"
      ],
      "metadata": {
        "id": "5uiJKFFb7kgQ",
        "outputId": "7e0a8341-a45e-4abd-95dd-fd91c8778ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "be0a60c81f894a98987181ea6d8095cf",
            "a72ef3d68f644a63b7fb989d88e3c3d2",
            "cb12d94ff36f4b6c9d62257246828e04",
            "1160a2a5baab449fae76eb29afde9ccc",
            "c32b0158f28b4e5c8225f8edc5ec18b2",
            "9ea7e81567824fc3b057b4f3f35f8b31",
            "821a97809f8c4c7595aecd31ce8747a0",
            "318bbd3392b44a499f4caf5a8b7d741a",
            "ffa20969f94e4738b148e157dff44704",
            "601034ae625f4e43892e96a1a93d152d",
            "7c0a5c5146f84fbd8804ae2caa2d8001",
            "c065435e23d946f5ba9eb80c22750488",
            "1b05314fd88641b58dbe635e3c751a53",
            "40ad4cfa05784792b37bdac15c4b08ef",
            "e591f53774ad44c2b78c5aa8bf82d832",
            "b1bad41310ed420ca2df8e6064786c52",
            "0ddd1660ea95406281382648693ade40",
            "a4938d2b0c7b47e5b841b1acf68358ab",
            "a800787bdc3647b7aae3a5e110248388",
            "94161024a65d4226bd898eda9b6bb222",
            "dafa789a1ccd4e3395d4200a4fccd90e",
            "fbd689492a8947f58bd89b2379550d44"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be0a60c81f894a98987181ea6d8095cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-12 14:04:46 INFO: Downloading default packages for language: fa (Persian)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c065435e23d946f5ba9eb80c22750488"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-12 14:04:55 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')"
      ],
      "metadata": {
        "id": "3g4pAEec7ux5",
        "outputId": "094317ca-3fdf-44c4-bf64-af853da60090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-12 14:04:55 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-12 14:04:55 INFO: Use device: gpu\n",
            "2022-04-12 14:04:55 INFO: Loading: tokenize\n",
            "2022-04-12 14:05:07 INFO: Loading: mwt\n",
            "2022-04-12 14:05:07 INFO: Loading: pos\n",
            "2022-04-12 14:05:08 INFO: Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "% cd fastText\n",
        "!  pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "id": "VpY9zQDp8Jux",
        "outputId": "2f920e8f-95fa-481c-89ba-019190dc33a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3930, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 3930 (delta 28), reused 42 (delta 11), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3930/3930), 8.33 MiB | 12.76 MiB/s, done.\n",
            "Resolving deltas: 100% (2445/2445), done.\n",
            "/content/fastText\n",
            "Processing /content/fastText\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3134485 sha256=38488eac227b44c86005ddc02980b6aca9bc09a71c076d5f753d9e954b554667\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e66jcuuo/wheels/22/04/6e/b3aba25c1a5845898b5871a0df37c2126cb0cc9326ad0c08e7\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd fastText\n",
        "!./download_model.py fa\n",
        "% cd .."
      ],
      "metadata": {
        "id": "DoKi4iNn8ZUH",
        "outputId": "76438e24-8c72-4f4a-874e-1307164247b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastText\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            " (100.00%) [==================================================>]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "t42lvGmI4_9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/test_data.zip -d data"
      ],
      "metadata": {
        "id": "Dnz8jjIu5cXG",
        "outputId": "f28d0757-605f-492a-b989-2fc78b3f00b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/دیتاست بیجن خان/test_data.zip\n",
            "  inflating: data/test_data.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/دیتاست\\ بیجن\\ خان/train_data.zip -d data"
      ],
      "metadata": {
        "id": "tWHVk-7Y5pSN",
        "outputId": "126a8b88-976e-4e25-a01f-a9b93282262a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/دیتاست بیجن خان/train_data.zip\n",
            "  inflating: data/train_data.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gJNO0vEv5tTF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/test_data.txt', sep='\\t', header=None)\n",
        "df.rename(columns={0:'word', 1:'tag'}, inplace=True)"
      ],
      "metadata": {
        "id": "XlzUtvkA5wB9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "agWAZ_MS52rO",
        "outputId": "8387ed44-862b-4f5a-c984-0a6a1398a95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      word tag\n",
              "0        #   O\n",
              "1    سلسله  ye\n",
              "2  صفاریان   O\n",
              "3        #   O\n",
              "4     طاهر   e"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff07b540-e979-4188-a528-3ad4368606fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلسله</td>\n",
              "      <td>ye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>صفاریان</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>طاهر</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff07b540-e979-4188-a528-3ad4368606fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff07b540-e979-4188-a528-3ad4368606fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff07b540-e979-4188-a528-3ad4368606fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pos = stanza.Pipeline(lang='fa', processors='tokenize,mwt,pos')\n",
        "def pos_tager(text):\n",
        "  doc = nlp_pos(text)\n",
        "  pos = [word.xpos for sent in doc.sentences for word in sent.words]\n",
        "  return pos"
      ],
      "metadata": {
        "id": "ysPjTc9uJQrn",
        "outputId": "9ab3815c-729a-4382-9e5d-b38f4e546bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-12 14:20:58 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-04-12 14:20:58 INFO: Use device: gpu\n",
            "2022-04-12 14:20:58 INFO: Loading: tokenize\n",
            "2022-04-12 14:20:58 INFO: Loading: mwt\n",
            "2022-04-12 14:20:58 INFO: Loading: pos\n",
            "2022-04-12 14:20:59 INFO: Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tager('. سلسله ی صفاریان')"
      ],
      "metadata": {
        "id": "vzsYDdS0JgbH",
        "outputId": "dccf122d-9240-41ce-dcb3-c4fa2c0a7056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PUNC', 'N_IANM', 'AUX', 'N_ANM']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/test_data.txt', encoding='utf-8') as f:\n",
        "    data = f.readlines()\n",
        "sents = list()\n",
        "kasre_tags = list()\n",
        "temp_sent = ''\n",
        "temp_tags = list()\n",
        "pos_tags = list()\n",
        "for i, line in enumerate(data):\n",
        "    try:\n",
        "        word, ez = line.split()\n",
        "        if ez == 'e':\n",
        "            word += 'ِ'\n",
        "        elif ez == 'ye':\n",
        "            word += '‌یِ'\n",
        "        word += ' '\n",
        "        temp_sent += word\n",
        "        temp_tags.append(ez)\n",
        "        if word in ['. ', '# ']:\n",
        "            sents.append(temp_sent) \n",
        "            kasre_tags.append(temp_tags)\n",
        "            pos_tag = pos_tager(temp_sent)\n",
        "            pos_tags.append(pos_tag)\n",
        "            temp_sent = ''\n",
        "            temp_tags = list()\n",
        "    except:\n",
        "        sents.append(temp_sent) \n",
        "        kasre_tags.append(temp_tags)\n",
        "        pos_tag = pos_tager(temp_sent)\n",
        "        pos_tags.append(pos_tag)\n",
        "        temp_sent = ''\n",
        "        temp_tags = list()    "
      ],
      "metadata": {
        "id": "CczRNmjYHMeo",
        "outputId": "a7491f90-4300-4c73-ac70-180d56e0fc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sents), len(kasre_tags), len(pos_tags)"
      ],
      "metadata": {
        "id": "ngwYljnqJKJO",
        "outputId": "f37aa7c1-d1e7-4aa1-eeac-1b0d93d71651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56974, 56974, 56974)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents[:3]"
      ],
      "metadata": {
        "id": "poX2HNrwHu8G",
        "outputId": "66ec2c3d-fd31-4282-b232-9f34be79263c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# ',\n",
              " 'سلسله\\u200cیِ صفاریان # ',\n",
              " 'طاهرِ ذوالیمینین مؤسسِ این سلسله در خراسان بود . ']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kasre_tags[:3]"
      ],
      "metadata": {
        "id": "cEHuThJ3IzOS",
        "outputId": "7942be88-f4ef-48d1-b8f5-1c42e103dfd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['O'], ['ye', 'O', 'O'], ['e', 'O', 'e', 'O', 'O', 'O', 'O', 'O', 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags[:3]"
      ],
      "metadata": {
        "id": "wW6h8l0JRR35",
        "outputId": "52bdc8d4-6c59-4740-be72-30a254821097",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['PSUS'],\n",
              " ['N_IANM', 'N_ANM', 'PUNC'],\n",
              " ['N_ANM',\n",
              "  'N_ANM',\n",
              "  'N_ANM',\n",
              "  'PREM_DEMAJ',\n",
              "  'N_IANM',\n",
              "  'PREP',\n",
              "  'N_IANM',\n",
              "  'AUX',\n",
              "  'PUNC']]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sents[56876]), len(kasre_tags[56876]), len(pos_tags[56876])"
      ],
      "metadata": {
        "id": "byJ_XyJ7SIG9",
        "outputId": "8dffde2f-629b-494d-b441-cf69e023e186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78, 16, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents[56876]"
      ],
      "metadata": {
        "id": "UwwsY3_SSoEO",
        "outputId": "766c0c6d-2e36-42eb-d24e-d2be0b2f3248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'رئیسِ این اتحادیه گفت که سازمانش قصد دارد کار را در نیمه\\u200cشبِ امشب متوقف کند . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags[56876]"
      ],
      "metadata": {
        "id": "dMzFAZV3SmdT",
        "outputId": "a07ed79c-bfed-4c83-93b9-88b4580f6c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['N_ANM',\n",
              " 'PREM_DEMAJ',\n",
              " 'N_IANM',\n",
              " 'V_ACT',\n",
              " 'SUBR',\n",
              " 'N_IANM',\n",
              " 'PR_JOPER',\n",
              " 'N_IANM',\n",
              " 'V_ACT',\n",
              " 'N_IANM',\n",
              " 'POSTP',\n",
              " 'PREP',\n",
              " 'N_IANM',\n",
              " 'N_IANM',\n",
              " 'ADJ_AJP',\n",
              " 'V_ACT',\n",
              " 'PUNC']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kasre_tags[56876]"
      ],
      "metadata": {
        "id": "yXlCtyAxSkbN",
        "outputId": "58e58b78-3006-45e2-ec49-dbcda41810e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'e',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents[2]"
      ],
      "metadata": {
        "id": "chE8WH_YSOdE",
        "outputId": "de19459e-bebe-4dc5-a23f-a74cc2270bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'طاهرِ ذوالیمینین مؤسسِ این سلسله در خراسان بود . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pos_tags)):\n",
        "  l1 = len(pos_tags[i])\n",
        "  l2 = len(kasre_tags[i])\n",
        "  l3 = len(sents[i].split())\n",
        "  if l1!=l2:\n",
        "    print(f'type1 {i}')\n",
        "  if l1!=l3:\n",
        "    print(f'type2 {i}')\n",
        "  if l3!=l2:\n",
        "    print(f'type3 {i}')"
      ],
      "metadata": {
        "id": "2O-AWsTiRYz_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "3K9fl9H075NQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "1ZCu237t79ne",
        "outputId": "f7bdd217-d8ca-43dd-8294-37f4e39d499b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fasttext import load_model\n",
        "\n",
        "# original BIN model loading\n",
        "f = load_model('fastText/cc.fa.300.bin')\n",
        "lines=[]\n",
        "\n",
        "# get all words from model\n",
        "words = f.get_words()\n",
        "\n",
        "with open('fastText/cc.fa.300.vec','w') as file_out:\n",
        "    \n",
        "    # the first line must contain number of total words and vector dimension\n",
        "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
        "\n",
        "    # line by line, you append vectors to VEC file\n",
        "    for w in words:\n",
        "        v = f.get_word_vector(w)\n",
        "        vstr = \"\"\n",
        "        for vi in v:\n",
        "            vstr += \" \" + str(vi)\n",
        "        try:\n",
        "            file_out.write(w + vstr+'\\n')\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "jGbN7OqcBSGS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ7tDnc7s76q"
      },
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        # directories\n",
        "        self.train_data_dir = 'data/train_data.txt'\n",
        "        self.model_dir = 'models'\n",
        "        self.we_model_dir = 'fastText/cc.fa.300.vec'\n",
        "        self.we_pickled_model_dir = 'fastText/cc.fa.300.pickle'\n",
        "\n",
        "        # general\n",
        "        self.data_split = .1\n",
        "        self.num_epochs = 25\n",
        "        self.batch_size = 16\n",
        "        self.shuffle_buffer = 320000\n",
        "        self.num_tags = 2\n",
        "        self.num_pos_tags = 14\n",
        "        self.word_max_len = 30\n",
        "        self.learning_rate = 1e-3\n",
        "        self.max_len = 1276\n",
        "\n",
        "        # embeddings\n",
        "        self.num_words = 100000\n",
        "        self.word_embed_dim = 300\n",
        "        self.num_chars = 256  # number of most frequent characters to be kept\n",
        "        self.char_embed_dim = 32\n",
        "        self.pos_embed_dim = 16\n",
        "\n",
        "        # lstm variables\n",
        "        self.lstm_units = 256  # number of hidden units in the RNN\n",
        "        self.dropout = .5  # keeping probability"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GarAaRl8lvft"
      },
      "source": [
        "import re\n",
        "import random\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        # loading word embedding model\n",
        "        try:\n",
        "            handle = open(cfg.we_pickled_model_dir, 'rb') \n",
        "            self.word_embedding_model = pickle.load(handle)\n",
        "        except FileNotFoundError:\n",
        "            self.word_embedding_model = KeyedVectors.load_word2vec_format(cfg.we_model_dir, binary=False)\n",
        "            with open(cfg.we_pickled_model_dir, 'wb') as handle:\n",
        "                pickle.dump(self.word_embedding_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        sents, all_pos_tags, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "\n",
        "        sents_shuf = []\n",
        "        all_pos_tags_shuf = []\n",
        "        all_ezafe_tags_shuf = []\n",
        "        index_shuf = list(range(len(sents)))\n",
        "\n",
        "        for i in index_shuf:\n",
        "            sents_shuf.append(sents[i])\n",
        "            all_pos_tags_shuf.append(all_pos_tags[i])\n",
        "            all_ezafe_tags_shuf.append(all_ezafe_tags[i])\n",
        "\n",
        "        random.seed(17)\n",
        "        random.shuffle(index_shuf)\n",
        "        data_split_1 = int(len(sents_shuf) * .1)\n",
        "        data_split_2 = int(len(sents_shuf) * .2)\n",
        "        \n",
        "        self.test_data = sents_shuf[:data_split_1], all_pos_tags_shuf[:data_split_1], all_ezafe_tags_shuf[:data_split_1]\n",
        "        self.valid_data = sents_shuf[data_split_1:data_split_2], all_pos_tags_shuf[data_split_1:data_split_2], all_ezafe_tags_shuf[data_split_1:data_split_2]\n",
        "        self.train_data = sents_shuf[data_split_2:], all_pos_tags_shuf[data_split_2:], all_ezafe_tags_shuf[data_split_2:]            \n",
        "        \n",
        "        print('train data:', len(self.train_data[0]))\n",
        "        print('validation data:', len(self.valid_data[0]))\n",
        "        print('test data:', len(self.test_data[0]))\n",
        "        \n",
        "        try:\n",
        "            with open('indices.pickle', 'rb') as handle:\n",
        "                self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index = pickle.load(handle)\n",
        "            \n",
        "            print(self.pos_tag_to_index)\n",
        "\n",
        "            self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "            self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "        \n",
        "            sents, all_pos_tags, all_ezafe_tags = self._data_reader(cfg.train_data_dir)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print('Building vocabulary...')\n",
        "\n",
        "            vocab_list = []\n",
        "            char_list = []\n",
        "            for sent in self.train_data[0]:\n",
        "                for word in sent:\n",
        "                    vocab_list.append(word)\n",
        "                    for char in word:\n",
        "                        char_list.append(char)\n",
        "            \n",
        "            most_common_words = Counter(vocab_list).most_common(cfg.num_words)\n",
        "            most_common_chars = Counter(char_list).most_common(cfg.num_chars)\n",
        "            \n",
        "            self.word_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0)] + most_common_words):\n",
        "                self.word_to_index[pair[0]] = i + 1\n",
        "\n",
        "            self.char_to_index = {}\n",
        "            for i, pair in enumerate([('<PAD>', 0), ('<UNK>', 1)] + most_common_chars):\n",
        "                self.char_to_index[pair[0]] = i + 1\n",
        "            \n",
        "            self.pos_tag_to_index = {}\n",
        "            for i, tag in enumerate(set(x for y in self.train_data[1] for x in y)):\n",
        "                self.pos_tag_to_index[tag] = i + 1\n",
        "\n",
        "            self.ezafe_tag_to_index = {'0': 0, '1': 1}\n",
        "\n",
        "            self.index_to_word = {i: key for key, i in self.word_to_index.items()}\n",
        "            self.index_to_ezafe_tag = {i: key for key, i in self.ezafe_tag_to_index.items()}\n",
        "\n",
        "            # saving the tokenizers\n",
        "            with open('indices.pickle', 'wb') as handle:\n",
        "                indices = self.char_to_index, self.word_to_index, self.pos_tag_to_index, self.ezafe_tag_to_index\n",
        "                pickle.dump(indices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "    def _data_reader(self, directory):\n",
        "        sents, sent = [], []\n",
        "        all_ezafe_tags, ezafe_tags = [], []\n",
        "        all_pos_tags, pos_tags = [], []\n",
        "        with open(directory) as bijankhan_corpus:\n",
        "            for line in bijankhan_corpus:\n",
        "                if line != '.':\n",
        "                    word, pos_tag, ezafe_tag = line.strip().split('\\t')\n",
        "                    sent.append(word.replace('ي', 'ی').replace('ك', 'ک').replace('ة', 'ه'))\n",
        "                    pos_tags.append(pos_tag)\n",
        "                    ezafe_tags.append(ezafe_tag)\n",
        "                else:\n",
        "                    sents.append(sent)\n",
        "                    all_pos_tags.append(pos_tags)\n",
        "                    all_ezafe_tags.append(ezafe_tags)\n",
        "                     \n",
        "                    sent = []\n",
        "                    pos_tags = []\n",
        "                    ezafe_tags = []\n",
        "\n",
        "        return sents, all_pos_tags, all_ezafe_tags\n",
        "\t\n",
        "\n",
        "    def _pad(self, word):\n",
        "        for _ in range(cfg.word_max_len - len(word)):\n",
        "            word.append(0)\n",
        "        return word\n",
        "    \n",
        "\n",
        "    def _sent_to_index(self, sentence, mode='word'):\n",
        "        if mode is 'word':\n",
        "            return [self.word_to_index.get(word, 1) for word in sentence]\n",
        "        elif mode is 'char':\n",
        "            indexed_sentence = []\n",
        "            for word in sentence:\n",
        "                indexed_word = []\n",
        "                for char in word:\n",
        "                    indexed_word.append(self.char_to_index.get(word, 1))\n",
        "                indexed_sentence.append(self._pad(indexed_word))\n",
        "            return indexed_sentence\n",
        "\n",
        "\n",
        "    def _sent_to_embed(self, sentence):\n",
        "        embed_sent = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                embed_sent.append(self.word_embedding_model[word])\n",
        "            except KeyError:\n",
        "                embed_sent.append([0 for _ in range(cfg.word_embed_dim)])\n",
        "        return embed_sent\n",
        "\n",
        "    \n",
        "    def _pos_tags_to_index(self, tags):\n",
        "        return [self.pos_tag_to_index[tag] for tag in tags]\n",
        "\n",
        "    \n",
        "    def _ezafe_tags_to_index(self, tags):\n",
        "        return [self.ezafe_tag_to_index[tag] for tag in tags]\n",
        "\n",
        "\n",
        "    def data_generator(self, mode=None, char=False, pos=None):\n",
        "        if mode is 'train':\n",
        "            sents, pos_tags, ezafe_tags = self.train_data\n",
        "        elif mode is 'eval': \n",
        "            sents, pos_tags, ezafe_tags = self.valid_data\n",
        "        else:\n",
        "            raise ArgumentError(\"Invalid argument. 'mode' must be either 'train', 'eval', or 'pred'.\")\n",
        "    \n",
        "        for sent, pos_tag, ezafe_tag in zip(sents, pos_tags, ezafe_tags):\n",
        "            sent_char = self._sent_to_index(sent, mode='char')\n",
        "            # sent_word = self._sent_to_index(sent)\n",
        "            sent_word = self._sent_to_embed(sent)\n",
        "            length = [1 for _ in range(len(sent))]\n",
        "            pos_tag = self._pos_tags_to_index(pos_tag)\n",
        "            tag = self._ezafe_tags_to_index(ezafe_tag)\n",
        "            weights = [1. if x == 0 else 1.5 for x in tag]\n",
        "            \n",
        "            if char:\n",
        "                yield (np.array(sent_word), np.array(sent_char), np.array(length)), np.array(tag)\n",
        "            elif pos is 'cposi':\n",
        "                yield (np.array(sent_word), np.array(sent_char), np.array(pos_tag), np.array(length), np.array(weights)), np.array(ezafe_tag)\n",
        "            else:\n",
        "                yield np.array(sent_word), np.array(tag)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmuk5Gc9lyrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "8dde23ec-15de-430a-cf8c-9719a0116580"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.contrib import layers\n",
        "from tf_metrics import precision, recall, f1\n",
        "\n",
        "\n",
        "data_loader = DataLoader()\n",
        "\n",
        "\n",
        "def model_fn(mode, features, labels):\n",
        "    # Logging\n",
        "    Path('results').mkdir(exist_ok=True)\n",
        "    tf.logging.set_verbosity(logging.INFO)\n",
        "    handlers = [logging.FileHandler('results/main.log'),\n",
        "                logging.StreamHandler(sys.stdout)]\n",
        "    logging.getLogger('tensorflow').handlers = handlers\n",
        "    \n",
        "    word_inputs, char_inputs, length = features\n",
        "\n",
        "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    batch_size = tf.shape(word_inputs)[0]\n",
        "    # input_lengths = tf.count_nonzero(word_inputs, 1, dtype=tf.int32)\n",
        "    input_lengths = tf.count_nonzero(length, 1, dtype=tf.int32)\n",
        "\n",
        "    \n",
        "    # Char Embeddings\n",
        "    # char_embeddings = tf.get_variable('char_embeddings', [cfg.num_chars + 2, cfg.char_embed_dim])\n",
        "    # embedded_chars = tf.nn.embedding_lookup(char_embeddings, char_inputs)\n",
        "    # embedded_chars = tf.layers.dropout(embedded_chars, rate=.5, training=training)\n",
        "    \n",
        "    # Reshaping for CNN\n",
        "    # output = tf.reshape(embedded_chars, [-1, tf.shape(char_inputs)[2], cfg.char_embed_dim])\n",
        "\n",
        "    # CNN\n",
        "    # output = tf.layers.conv1d(output, filters=64, kernel_size=2, strides=1, padding=\"same\", activation=tf.nn.relu)\n",
        "    # output = tf.layers.max_pooling1d(output, pool_size=2, strides=2)\n",
        "    # output = tf.layers.conv1d(output, filters=128, kernel_size=2, strides=1, padding=\"same\", activation=tf.nn.relu)\n",
        "    # output = tf.layers.max_pooling1d(output, pool_size=2, strides=2)\n",
        "\n",
        "    # cnn_output = tf.layers.dropout(output, rate=.5, training=training)\n",
        "    # cnn_output = tf.layers.flatten(cnn_output)\n",
        "\n",
        "    # Word Embeddings\n",
        "    # word_embeddings = tf.get_variable('word_embeddings', [cfg.num_words + 2, cfg.word_embed_dim])\n",
        "    # embedded_words = tf.nn.embedding_lookup(word_embeddings, word_inputs)\n",
        "    # word_inputs = tf.layers.dropout(word_inputs, rate=.5, training=training)\n",
        "    \n",
        "    # Reshaping CNN and concatenating for LSTM\n",
        "    # cnn_output = tf.reshape(cnn_output, [-1, tf.shape(char_inputs)[1], 128 * int(cfg.word_max_len / 4)])\n",
        "    # lstm_inputs = tf.concat([word_inputs, cnn_output], axis=-1) \n",
        "\n",
        "    # LSTM\n",
        "    transposed_emb = tf.transpose(word_inputs, perm=[1, 0, 2])\n",
        "    fw_cell = tf.contrib.rnn.LSTMBlockFusedCell(cfg.lstm_units)\n",
        "    bw_cell = tf.contrib.rnn.TimeReversedFusedRNN(tf.contrib.rnn.LSTMBlockFusedCell(cfg.lstm_units))\n",
        "    output_fw, _ = fw_cell(transposed_emb, dtype=tf.float32, sequence_length=input_lengths)\n",
        "    output_bw, _ = bw_cell(transposed_emb, dtype=tf.float32, sequence_length=input_lengths)\n",
        "    output = tf.concat([output_fw, output_bw], axis=-1)\n",
        "    output = tf.transpose(output, perm=[1, 0, 2])\n",
        "    lstm_output = tf.layers.dropout(output, rate=.5, training=training)\n",
        "\n",
        "    # Dense\n",
        "    output = tf.reshape(lstm_output, [-1, 2 * cfg.lstm_units])\n",
        "    logits = tf.layers.dense(output, cfg.num_tags)\n",
        "    pred = tf.reshape(logits, [-1, tf.shape(word_inputs)[1], cfg.num_tags])\n",
        "    pred_ids = tf.cast(tf.argmax(pred, axis=-1), tf.int32)\n",
        "    \n",
        "    # Loss\n",
        "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=pred))\n",
        "\n",
        "    # Metrics\n",
        "    weights = tf.to_float(tf.sign(length))\n",
        "    indices = [1]\n",
        "    metrics = {'acc': tf.metrics.accuracy(labels, pred_ids, weights),\n",
        "               'precision': precision(labels, pred_ids, cfg.num_tags, indices, weights),\n",
        "               'recall': recall(labels, pred_ids, cfg.num_tags, indices, weights),\n",
        "               'f1': f1(labels, pred_ids, cfg.num_tags, indices, weights)}\n",
        "    \n",
        "    for metric_name, op in metrics.items():\n",
        "        tf.summary.scalar(metric_name, op[1])\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        return tf.estimator.EstimatorSpec(mode, loss=loss, \n",
        "                                          eval_metric_ops=metrics)\n",
        "\n",
        "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        train_op = tf.train.AdamOptimizer().minimize(loss, \n",
        "                                                     global_step=tf.train.get_or_create_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode, \n",
        "                                          loss=loss, \n",
        "                                          train_op=train_op)\n",
        "\n",
        "def input_fn(mode=None):\n",
        "    data_generator = lambda: data_loader.data_generator(mode=mode, char=True)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(data_generator, \n",
        "                                             output_types=((tf.float32, tf.int32, tf.int32), tf.int32),\n",
        "                                             output_shapes=(([None, cfg.word_embed_dim], [None, None], [None]), [None]))\n",
        "\n",
        "    if mode is 'train':\n",
        "        dataset = dataset.shuffle(cfg.shuffle_buffer).repeat(cfg.num_epochs)\n",
        "        \n",
        "    dataset = dataset.padded_batch(cfg.batch_size, padded_shapes=(([None, cfg.word_embed_dim], [None, None], [None]), [None]))\n",
        "        \n",
        "    return dataset\n",
        "\n",
        "\n",
        "def train():\n",
        "    train_input_func = lambda: input_fn(mode='train')\n",
        "    eval_input_func = lambda: input_fn(mode='eval')\n",
        "    \n",
        "    est_conf = tf.estimator.RunConfig(cfg.model_dir, save_checkpoints_secs=60)\n",
        "    estimator = tf.estimator.Estimator(model_fn, cfg.model_dir, est_conf)\n",
        "    \n",
        "    Path(estimator.eval_dir()).mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_func)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_func, throttle_secs=60)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-65dd75c4c02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-3f477efd17ce>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embedding_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pos_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_ezafe_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msents_shuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-3f477efd17ce>\u001b[0m in \u001b[0;36m_data_reader\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbijankhan_corpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mezafe_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                     \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ي'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ی'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ك'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ک'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ة'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ه'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mpos_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Sj1ipmAkADqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}